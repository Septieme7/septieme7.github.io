<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BlueDaydream</title>
  
  <subtitle>C‘est la vie.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-03-03T08:05:42.527Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Septieme7</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pytorch学习笔记1</title>
    <link href="http://yoursite.com/2021/03/03/Pytorch%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"/>
    <id>http://yoursite.com/2021/03/03/Pytorch 学习笔记1/</id>
    <published>2021-03-03T08:03:00.000Z</published>
    <updated>2021-03-03T08:05:42.527Z</updated>
    
    <content type="html"><![CDATA[<h2 id="torch-Tensor"><a href="#torch-Tensor" class="headerlink" title="torch.Tensor"></a>torch.Tensor</h2><h3 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h3><p><code>torch.Tensor</code>是一种包含单一数据类型元素的多维矩阵，在Pytorch中</p><p>Torch一共定义了10种tensor类型：</p><div class="table-container"><table><thead><tr><th>Data type</th><th>dtype</th><th>CPU tensor</th><th>GPU tensor</th></tr></thead><tbody><tr><td>32-bit floating point</td><td><code>torch.float32</code> or <code>torch.float</code></td><td><code>torch.FloatTensor</code></td><td><code>torch.cuda.FloatTensor</code></td></tr><tr><td>64-bit floating point</td><td><code>torch.float64</code> or <code>torch.double</code></td><td><code>torch.DoubleTensor</code></td><td><code>torch.cuda.DoubleTensor</code></td></tr><tr><td>16-bit floating point</td><td><code>torch.float16</code> or <code>torch.half</code></td><td><code>torch.HalfTensor</code></td><td><code>torch.cuda.HalfTensor</code></td></tr><tr><td>16-bit floating point</td><td><code>torch.bfloat16</code></td><td><code>torch.BFloat16Tensor</code></td><td><code>torch.cuda.BFloat16Tensor</code></td></tr><tr><td>32-bit complex</td><td><code>torch.complex32</code></td><td></td><td></td></tr><tr><td>64-bit complex</td><td><code>torch.complex64</code></td><td></td><td></td></tr><tr><td>128-bit complex</td><td><code>torch.complex128</code> or <code>torch.cdouble</code></td><td></td><td></td></tr><tr><td>8-bit integer (unsigned)</td><td><code>torch.uint8</code></td><td><code>torch.ByteTensor</code></td><td><code>torch.cuda.ByteTensor</code></td></tr><tr><td>8-bit integer (signed)</td><td><code>torch.int8</code></td><td><code>torch.CharTensor</code></td><td><code>torch.cuda.CharTensor</code></td></tr><tr><td>16-bit integer (signed)</td><td><code>torch.int16</code> or <code>torch.short</code></td><td><code>torch.ShortTensor</code></td><td><code>torch.cuda.ShortTensor</code></td></tr><tr><td>32-bit integer (signed)</td><td><code>torch.int32</code> or <code>torch.int</code></td><td><code>torch.IntTensor</code></td><td><code>torch.cuda.IntTensor</code></td></tr><tr><td>64-bit integer (signed)</td><td><code>torch.int64</code> or <code>torch.long</code></td><td><code>torch.LongTensor</code></td><td><code>torch.cuda.LongTensor</code></td></tr><tr><td>Boolean</td><td><code>torch.bool</code></td><td><a href="https://pytorch.org/docs/stable/tensors.html#torch.BoolTensor" target="_blank" rel="noopener"><code>torch.BoolTensor</code></a></td><td><code>torch.cuda.BoolTensor</code></td></tr></tbody></table></div><p><code>torch.Tensor</code>是默认的tensor类型（<code>torch.FlaotTensor</code>）的简称</p><p>一个张量tensor可以从Python的<code>list</code>或序列构建：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.tensor([[<span class="number">1.</span>, <span class="number">-1.</span>], [<span class="number">1.</span>, <span class="number">-1.</span>]])</span><br><span class="line">tensor([[ <span class="number">1.0000</span>, <span class="number">-1.0000</span>],</span><br><span class="line">        [ <span class="number">1.0000</span>, <span class="number">-1.0000</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.tensor(np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]))</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">        [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>]])</span><br></pre></td></tr></table></figure><blockquote><p><strong>警告：</strong><code>torch.tensor()</code> 操作会对 <code>data</code>进行复制，如果只想更改tensor的 <code>requires_grad</code>属性, 使用<code>requires_grad_()</code> 或者 <code>detach()</code> 来避免进行拷贝，如果使用的是一个numpy数组<code>torch.as_tensor()</code>。</p></blockquote><p>tensor同样可以进行索引和切片操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(x[<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line"><span class="number">6.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>][:<span class="number">1</span>]</span><br><span class="line">tensor([<span class="number">4.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>][:]</span><br><span class="line">tensor([<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>])</span><br></pre></td></tr></table></figure><p>特定类型的tensor可以通过在构造是传入<code>torch.dtype</code>和<code>torch.device</code>信息来进行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.zeros([<span class="number">2</span>, <span class="number">4</span>], dtype=torch.int32)</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>]], dtype=torch.int32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cuda0 = torch.device(<span class="string">'cuda:0'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.ones([<span class="number">2</span>, <span class="number">4</span>], dtype=torch.float64, device=cuda0)</span><br><span class="line">tensor([[ <span class="number">1.0000</span>,  <span class="number">1.0000</span>,  <span class="number">1.0000</span>,  <span class="number">1.0000</span>],</span><br><span class="line">        [ <span class="number">1.0000</span>,  <span class="number">1.0000</span>,  <span class="number">1.0000</span>,  <span class="number">1.0000</span>]], dtype=torch.float64, device=<span class="string">'cuda:0'</span>)</span><br></pre></td></tr></table></figure><p>可以使用<code>torch.Tensor.item()</code>来获取单值tensor的数值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor(<span class="number">2.5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor(<span class="number">2.5000</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.item()</span><br><span class="line"><span class="number">2.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多值是不可以的</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.item()</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">ValueError: only one element tensors can be converted to Python scalars</span><br></pre></td></tr></table></figure><p>在创建时属性<code>requires_grad=True</code>的tensor可以使用<code>torch.autograd</code>记录其进行的操作，以便于进行自动微分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor([[<span class="number">1.</span>, <span class="number">-1.</span>], [<span class="number">1.</span>, <span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>out = x.pow(<span class="number">2</span>).sum()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>out.backward()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.grad</span><br><span class="line">tensor([[ <span class="number">2.0000</span>, <span class="number">-2.0000</span>],</span><br><span class="line">        [ <span class="number">2.0000</span>,  <span class="number">2.0000</span>]])</span><br></pre></td></tr></table></figure><p>每一个tensor都有一个相应的<code>torch.Storage</code>用来保存其数据。tensor类提供了一个存储的多维的、横向视图，并且定义了在其上的数值运算</p><blockquote><p><strong>注意：</strong>会改变tensor的函数操作会用一个下划线后缀来标示。比如，<code>torch.FloatTensor.abs_()</code>会在原地计算绝对值，并返回改变后的tensor，而<code>tensor.FloatTensor.abs()</code>将会在一个新的tensor中计算结果。</p><p><strong>注意：</strong>如果要更改一个tensor的<code>torch.device</code> 或者 <code>torch.dtype</code>属性, 可以考虑对tensor使用 <code>to()</code>方法。</p></blockquote><h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><p><code>Torch.device</code> 是表现 <code>torch.Tensor</code>被分配的设备类型的类，其中分为’cpu’和’cuda’两种，如果设备序号没有显示则表示此 tensor 被分配到当前设备, 比如: ‘cuda’ 等同于’cuda: X’ ,  X为<code>torch.cuda.current_device()</code> 返回值。</p><p>我们可以通过<code>tensor.device</code>来获取其属性，同时可以利用字符或字符+序号的方式来分配设备:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过字符串</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.device(<span class="string">'cuda:0'</span>)</span><br><span class="line">device(type=<span class="string">'cuda'</span>, index=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.device(<span class="string">'cpu'</span>)</span><br><span class="line">device(type=<span class="string">'cpu'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.device(<span class="string">'cuda'</span>) <span class="comment"># 当前设备</span></span><br><span class="line">device(type=<span class="string">'cuda'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过字符串和设备序号</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.device(<span class="string">'cuda'</span>, <span class="number">0</span>)</span><br><span class="line">device(type=<span class="string">'cuda'</span>, index=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.device(<span class="string">'cpu'</span>, <span class="number">0</span>)</span><br><span class="line">device(type=<span class="string">'cpu'</span>, index=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><h4 id="连接操作"><a href="#连接操作" class="headerlink" title="连接操作"></a>连接操作</h4><ul><li><h5 id="torch-cat-torch-stack"><a href="#torch-cat-torch-stack" class="headerlink" title="torch.cat torch.stack"></a><code>torch.cat</code> <code>torch.stack</code></h5></li></ul><p>沿着dim连接seq中的tensor, 所有的tensor必须有相同的size或为empty，其相反的操作为 <code>torch.split()</code> 和<code>torch.chunk()</code></p><p>注: <code>.cat</code> 和 <code>.stack</code>的区别在于<code>cat</code>会增加现有维度的值,可以理解为续接，<code>stack</code>会新加增加一个维度，可以理解为叠加</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(seq,dim=<span class="number">0</span>,out=<span class="literal">None</span>)</span><br><span class="line">torch.stack(seq, dim=<span class="number">0</span>, out=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.stack((a,a)).size()</span><br><span class="line">torch.size(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cat((a,a)).size()</span><br><span class="line">torch.size(<span class="number">6</span>)</span><br></pre></td></tr></table></figure><ul><li><h5 id="torch-gather"><a href="#torch-gather" class="headerlink" title="torch.gather"></a><code>torch.gather</code></h5></li></ul><p>核心操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">out[i][j][k] = input[index[i][j][k]] [j][k]  # if dim == 0</span><br><span class="line"></span><br><span class="line">out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1</span><br><span class="line"></span><br><span class="line">out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2</span><br></pre></td></tr></table></figure><p><strong>是对于out指定位置上的值，去寻找input里面对应的索引位置，根据是index</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.Tensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.gather(t, <span class="number">1</span>, torch.LongTensor([[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">0</span>]]))</span><br><span class="line"> <span class="number">1</span>  <span class="number">1</span></span><br><span class="line"> <span class="number">4</span>  <span class="number">3</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">2</span>x2]</span><br></pre></td></tr></table></figure><ul><li><h5 id="torch-scatter"><a href="#torch-scatter" class="headerlink" title="torch.scatter"></a><code>torch.scatter</code></h5></li></ul><p>核心操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0</span><br><span class="line"></span><br><span class="line">self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1</span><br><span class="line"></span><br><span class="line">self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2</span><br></pre></td></tr></table></figure><p><strong>对于input指定位置上的值，去分配给output对应索引位置</strong>，根据是index</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = torch.rand(<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line"> </span><br><span class="line"> <span class="number">0.4319</span>  <span class="number">0.6500</span>  <span class="number">0.4080</span>  <span class="number">0.8760</span>  <span class="number">0.2355</span></span><br><span class="line"> <span class="number">0.2609</span>  <span class="number">0.4711</span>  <span class="number">0.8486</span>  <span class="number">0.8573</span>  <span class="number">0.1029</span></span><br><span class="line">[torch.FloatTensor of size <span class="number">2</span>x5]</span><br><span class="line"> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.zeros(<span class="number">3</span>, <span class="number">5</span>).scatter_(<span class="number">0</span>, torch.LongTensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]]), x)</span><br><span class="line"> </span><br><span class="line"> <span class="number">0.4319</span>  <span class="number">0.4711</span>  <span class="number">0.8486</span>  <span class="number">0.8760</span>  <span class="number">0.2355</span></span><br><span class="line"> <span class="number">0.0000</span>  <span class="number">0.6500</span>  <span class="number">0.0000</span>  <span class="number">0.8573</span>  <span class="number">0.0000</span></span><br></pre></td></tr></table></figure><h4 id="拆分操作"><a href="#拆分操作" class="headerlink" title="拆分操作"></a>拆分操作</h4><ul><li><h5 id="torch-split-torch-chunk"><a href="#torch-split-torch-chunk" class="headerlink" title="torch.split torch.chunk"></a><code>torch.split</code> <code>torch.chunk</code></h5></li></ul><p>将tensor拆分成相应的组块，<code>split</code>和<code>chunk</code>的区别在于：<code>split</code>的split_size_or_sections 表示每一个组块中的数据大小，<code>chunks</code>表示组块的数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.split(tensor, split_size_or_sections, dim=<span class="number">0</span>)</span><br><span class="line">torch.chunk(tensor, chunks, dim=<span class="number">0</span>) <span class="comment">#如果不能整除的话，最后一块会小一些</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.split(a,<span class="number">1</span>)</span><br><span class="line">(tensor([<span class="number">1.</span>]), tensor([<span class="number">2.</span>]), tensor([<span class="number">3.</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.chunk(a,<span class="number">1</span>)</span><br><span class="line">(tensor([ <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]),)</span><br></pre></td></tr></table></figure><h4 id="索引操作"><a href="#索引操作" class="headerlink" title="索引操作"></a>索引操作</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">torch.index_select(input, dim, index, out=<span class="literal">None</span>) <span class="comment"># 返回沿着dim的指定tensor, index需为longTensor类型，不共用内存</span></span><br><span class="line"></span><br><span class="line">torch.masked_select(input, mask, out=<span class="literal">None</span>) <span class="comment"># 根据mask来返回input的值其为1-D tensor. Mask为ByteTensor, true返回，false不返回，返回值不共用内存</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[ <span class="number">0.3552</span>, <span class="number">-2.3825</span>, <span class="number">-0.8297</span>,  <span class="number">0.3477</span>],</span><br><span class="line">        [<span class="number">-1.2035</span>,  <span class="number">1.2252</span>,  <span class="number">0.5002</span>,  <span class="number">0.6248</span>],</span><br><span class="line">        [ <span class="number">0.1307</span>, <span class="number">-2.0608</span>,  <span class="number">0.1244</span>,  <span class="number">2.0139</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask = x.ge(<span class="number">0.5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mask</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>]], dtype=torch.uint8)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.masked_select(x, mask)</span><br><span class="line">tensor([ <span class="number">1.2252</span>,  <span class="number">0.5002</span>,  <span class="number">0.6248</span>,  <span class="number">2.0139</span>])</span><br></pre></td></tr></table></figure><h4 id="变形"><a href="#变形" class="headerlink" title="变形"></a>变形</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">torch.transpose(input, dim0, dim1, out=<span class="literal">None</span>) <span class="comment">#返回dim0和dim1交换后的tensor</span></span><br><span class="line">torch.t(input, out=<span class="literal">None</span>) <span class="comment">#专为2D矩阵的转置，是transpose的便捷函数</span></span><br><span class="line"></span><br><span class="line">torch.squeeze(input, dim, out=<span class="literal">None</span>)  <span class="comment">#默认移除所有size为1的维度，当dim指定时，移除指定size为1的维度. 返回的tensor会和input共享存储空间，所以任何一个的改变都会影响另一个</span></span><br><span class="line">torch.unsqueeze(input, dim, out=<span class="literal">None</span>) <span class="comment">#扩展input的size, 如 A x B 变为 1 x A x B </span></span><br><span class="line"></span><br><span class="line">torch.reshape(input, shape) <span class="comment">#返回size为shape具有相同数值的tensor, 注意 shape=(-1,)这种表述，-1表示任意的。</span></span><br><span class="line"><span class="comment">#注 reshape(-1,)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]) <span class="comment">#a.size 是 torch.size(5)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b=a.reshape(<span class="number">1</span>,<span class="number">-1</span>)  <span class="comment">#表示第一维度是1，第二维度按a的size填充满</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.size()</span><br><span class="line">torch.size([<span class="number">1</span>,<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">torch.where(condition,x,y) <span class="comment">#根据condition的值来相应x,y的值，true返回x的值，false返回y的值，形成新的tensor</span></span><br><span class="line"></span><br><span class="line">torch.unbind(tensor, dim=<span class="number">0</span>) <span class="comment">#返回tuple 解除指定的dim的绑定,相当于按指定dim拆分</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=torch.Tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.unbind(a,dim=<span class="number">0</span>)</span><br><span class="line">(torch([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]),torch([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])) <span class="comment"># 将一个(2,3) 分为两个(3)</span></span><br><span class="line"></span><br><span class="line">torch.nonzero(input, out=<span class="literal">None</span>) <span class="comment"># 返回非零值的索引， 每一行都是一个非零值的索引值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.nonzero(torch.tensor([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]))</span><br><span class="line">tensor([[ <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.nonzero(torch.tensor([[<span class="number">0.6</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">                                [<span class="number">0.0</span>, <span class="number">0.4</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">                                [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.2</span>, <span class="number">0.0</span>],</span><br><span class="line">                                [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>,<span class="number">-0.4</span>]]))</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">1</span>,  <span class="number">1</span>],</span><br><span class="line">        [ <span class="number">2</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">3</span>]])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Pytorch中的tensor
    
    </summary>
    
      <category term="人工智能" scheme="http://yoursite.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Pytorch" scheme="http://yoursite.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>变分自编码器</title>
    <link href="http://yoursite.com/2020/08/10/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/"/>
    <id>http://yoursite.com/2020/08/10/变分自编码器/</id>
    <published>2020-08-10T12:15:00.000Z</published>
    <updated>2020-08-11T12:11:13.785Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>变分自解码器（VAE，Variational Auto-Encoder）的基本思路是将真实样本通过神经网络（编码器）转换为一个理想的数据分布，再将这个数据分布输入到另一个神经网络（解码器）中，最终得到生成样本。如果生成样本与真实样本足够接近的话，就训练出了一个自编码器模型；而VAE主要是在自编码器模型的基础上进行了进一步的变分处理，使得编码器的输出结果可以对应到目标分布的均值于方差。</p><p>VAE以概率的方式描述潜在空间观察，并不是输出单个值来描述每个潜在状态属性的编码器，而是用编码器来描述每个潜在属性的概率分布。</p><p><img src="/images/image-20200810212131678.png" alt="单值描述潜在属性" style="zoom:33%;"></p><p>VAE将每个潜在属性表示为可能值的范围，用概率术语来描述潜在属性：</p><p><img src="/images/image-20200810212338409.png" alt="潜在属性表示为高斯分布" style="zoom:30%;"></p><p>当从潜在状态解码时，我们将从每个潜在状态分布中随机采样，生成一个向量作为解码器模型的输入：</p><p><img src="/images/image-20200810212453321.png" alt="对属性解码" style="zoom:33%;"></p><p><img src="/images/image-20200810212625262.png" alt="解码器取样举例" style="zoom:33%;"></p><h2 id="从PCA到Variational-Auto-Encoder"><a href="#从PCA到Variational-Auto-Encoder" class="headerlink" title="从PCA到Variational Auto-Encoder"></a>从PCA到Variational Auto-Encoder</h2><p>VAE最主要实现的功能就是构造编码器和解码器，是图片可以编码为一个易于表示的形态并能从这一形态尽可能无损地解码会原真实图像。</p><p>听起来是不是和PCA很相似：</p><p><img src="/images/image-20200811092357016.png" alt="PCA主成分分析" style="zoom:16%;"></p><p>将输入图形 $x$ 视为一个矩阵，经过一个变换$W$变成了一个低维矩阵 $c$ ，因为$W$是一个线性转换的过程，所以可以再经过一个$W^T$变换就可以还原出一个 $\hat{x}$ ，PCA所做的事情就是让 $x$ 和 $\hat{x}$ 尽可能地一致。在PCA中寻找变换$W$使用的方法是SVD（奇异值分解）算法，这是一种纯数学的方法。这样的仅仅通过线性变换的转换方法的能力显然是受限的，所以在后续的Auto-Encoder模型中SVD部分被神经网络所代替。</p><p>如果把矩阵 $x$ 视作输入图像，$W$视作一个编码器，低维矩阵 $c$ 视作图像的编码，然后将$W^T$和 $\hat{x}$ 视作解码器和生成图像，PCA俨然就是一个自编码器网络模型的雏形：</p><p><img src="/images/image-20200811091454639.png" alt="PCA自编码器" style="zoom:25%;"></p><p>所以我们考虑使用神经网络来进行encode和decode，最终就得到了Deep Auto-Encoder模型：</p><p><img src="/images/image-20200811093554509.png" alt="Deep Auto-Encoder" style="zoom:25%;"></p><p>这一替换的明显好处是：引入了神经网络强大的拟合能力，使得编码（Code）的维度能够比原始图像（X）的维度低非常多。在一个手写数字图像的生成模型中，Deep Auto-Encoder能够把一个784维的向量（28*28图像）压缩到只有30维，并且解码回的图像具备清楚的辨认度（如下图）：</p><p><img src="/images/image-20200811093825917.png" alt="Deep Auto-Encoder效果" style="zoom:30%;"></p><p>利用可视化查看一下PCA和Deep Auto-Encoder压缩的效果：</p><p><img src="/images/image-20200811094002173.png" alt="Deep Auto-Encoder和PCA压缩效果对比" style="zoom:33%;"></p><p>但Deep Auto-Encoder同样存在着自己的问题，相对而言他是比较难以训练的，需要对神经网络进行适当的初始化。不过，至此我们已经构造出了一个重构图像比较清晰的自编码模型，但是这并没有达到我们真正想要构造的生成模型的标准。因为，对于一个生成模型而言，解码器部分应该是单独能够提取出来的，并且对于在规定维度下任意采样的一个编码，都应该能通过解码器产生一张清晰且真实的图片。</p><p>而现有的生成模型为什么无法做到这一点呢？</p><p><img src="/images/image-20200811102832258.png" alt="一个编码还原的例子" style="zoom:40%;"></p><p>如上图所示，假设有两张训练图片，一张是全月图，一张是半月图，经过训练我们的自编码器模型已经能无损地还原这两张图片。接下来，我们在code空间上，两张图片的编码点中间处取一点，然后将这一点交给解码器，我们希望新的生成图片是一张清晰的图片（类似3/4全月的样子）。但是，实际的结果是，生成图片是模糊且无法辨认的乱码图。一个比较合理的解释是，因为编码和解码的过程使用了深度神经网络，这是一个非线性的变换过程，所以在code空间上点与点之间的迁移是非常没有规律的。</p><p>那我们如何解决这个问题呢？</p><p>可以考虑引入噪声，使得图片的编码区域得到扩大，从而掩盖掉失真的空白编码点。我们需要在给图片编码的时候加上一点噪音（也相当于是增强鲁棒性），使得每张图片的编码点出现在绿色箭头所示范围内，这个范围内的每一个点都有可能被采样到，所以解码器在训练时会把绿色范围内的点都尽可能还原成和原图相似的图片。</p><p><img src="/images/image-20200811102904356.png" alt="引入噪声" style="zoom:35%;"></p><p>然后我们可以关注之前那个失真点，现在它处于全月图和半月图编码的交界上，于是解码器希望它既要尽量相似于全月图，又要尽量相似于半月图，于是它的还原结果就是两种图的折中（3/4全月图）。也就是说，经过这样的训练，模型习得了一定的连续性。</p><p>我们已经发现，给编码器增添一些噪音，可以有效覆盖失真区域，缓解生成不连续的问题。不过这还并不充分，因为在上图的距离训练区域很远的黄色点处，它依然不会被覆盖到，仍是个失真点。为了解决这个问题，我们可以试图把噪音无限拉长，使得对于每一个样本，它的编码会覆盖整个编码空间.不过我们得保证，在原编码附近编码的概率最高，离原编码点越远，编码概率越低。在这种情况下，图像的编码就由原先离散的编码点变成了一条连续的编码分布曲线，如下图所示：</p><p><img src="/images/image-20200811102606191.png" alt="编码为正态分布" style="zoom:33%;"></p><p>上述的这种将图像编码由离散变为连续的方法，就是变分自编码的核心思想。</p><h2 id="VAE的模型架构"><a href="#VAE的模型架构" class="headerlink" title="VAE的模型架构"></a>VAE的模型架构</h2><p><img src="/images/image-20200811103920776.png" alt="VAE的模型架构" style="zoom:33%;"></p><p>上面这张图就是VAE的模型架构，我们先粗略地领会一下这个模型的设计思想。</p><p>在auto-encoder中，编码器是直接产生一个编码的，但是在VAE中，为了给编码添加合适的噪音，编码器会输出两个编码，一个是原有编码$(m_1,m_2,m_3)$，另外一个是控制噪音干扰程度的编码$(\sigma_1,\sigma_2,\sigma_3)$，第二个编码其实很好理解，就是为随机噪音码$(e_1,e_2,e_3)$分配权重，然后加上$exp(\sigma_i)$的目的是为了保证这个分配的权重是个正值，最后将原编码与噪音编码相加，就得到了VAE在code层的输出结果$(c_1,c_2,c_3)$。其它网络架构都与Deep Auto-encoder无异。</p><p>损失函数方面，除了必要的重构损失外，VAE还增添了一个损失函数：$\sum^3_{i=1}(\exp(\sigma_i)-(1+\sigma_i)+(m_i)^2)$</p><p>这同样是必要的部分，因为如果不加的话，整个模型就会出现问题：为了保证生成图片的质量越高，编码器肯定希望噪音对自身生成图片的干扰越小，于是分配给噪音的权重越小，这样只需要将$(\sigma_1,\sigma_2,\sigma_3)$赋为接近负无穷大的值就好了。所以，第二个损失函数就有限制编码器走这样极端路径的作用，这也从直观上就能看出来，在$\exp(\sigma_i)-(1+\sigma_i)$在$\sigma_i$=0处取得最小值，于是$(\sigma_1,\sigma_2,\sigma_3)$就会避免被赋值为负无穷大。</p><p>上述我们只是粗略地理解了VAE的构造机理，但是还有一些更深的原理需要挖掘，例如第二个损失函数为何选用这样的表达式，以及VAE是否真的能实现我们的预期设想，即“图片能够编码成易于表示的形态，并且这一形态能够尽可能无损地解码回原真实图像”，是否有相应的理论依据。</p><p>下面就是理论部分的证明。</p><h2 id="VAE的原理"><a href="#VAE的原理" class="headerlink" title="VAE的原理"></a>VAE的原理</h2><p>对于生成模型而言，主流的理论模型可以分为隐马尔可夫模型(HMM)、朴素贝叶斯模型(NB)和高斯混合模型(GMM)，而VAE的理论基础就是高斯混合模型。</p><p>所谓的高斯混合模型就是说，任何一个数据的分布，都可以看作是若干高斯分布的叠加：</p><p><img src="/images/image-20200811105729544.png" alt="高斯混合模型" style="zoom:15%;"></p><p>如图所示，如果P(X)代表一种分布的话，存在一种拆分方法能让它表示成图中若干浅蓝色曲线对应的高斯分布的叠加。有意思的是，这种拆分方法已经证明出，当拆分的数量达到512时，其叠加的分布相对于原始分布而言，误差是非常非常小的了。</p><p>于是我们可以利用这一理论模型去考虑如何给数据进行编码。一种最直接的思路是，直接用每一组高斯分布的参数作为一个编码值实现编码。</p><p><img src="/images/image-20200811105849610.png" alt="参数编码" style="zoom:15%;"></p><p>如上图所示，$m$ 代表着编码维度上的编号，譬如实现一个512维的编码，$m$ 的取值范围就是$1,2,3……512$。$m$ 会服从于一个概率分布$P(m)$（多项式分布）。现在编码的对应关系是，每采样一个$m$，其对应到一个小的高斯分布$N(\mu^m, \sigma^m)$，$P(X)$就可以等价为所有的这些高斯分布的叠加，即：</p><script type="math/tex; mode=display">P(x) = \sum_mP(m)P(x|m) \\ 其中 \space m\thicksim P(m),\space x|m \thicksim N(\mu^m, \sigma^m)</script><p>上述的这种编码方式是非常简单粗暴的，它对应的是我们之前提到的离散的、有大量失真区域的编码方式。于是我们需要对目前的编码方式进行改进，使得它成为连续有效的编码：</p><p><img src="/images/image-20200811110944801.png" alt="连续编码" style="zoom:15%;"></p><p>现在我们的编码换成一个连续变量z，我们规定z服从正态分布$N(0,1)$（实际上并不一定要选用$N(0,1)$，其他的连续分布都是可行的)。每对于一个采样 $z$ ，会有两个函数 $\mu$ 和 $\sigma$ ，分别决定 $z$ 对应到的高斯分布的均值和方差，然后在积分域上所有的高斯分布的累加就成为了原始分布$P(X)$ ,即：</p><script type="math/tex; mode=display">P(x) = \int_z P(z)P(x|z)dz \\ 其中\space z\thicksim N(0,1),\space x|z \thicksim N(\mu(z), \sigma(z))</script><p>接下来就可以求解这个式子。由于$P(z)$是已知的，$P(x|z)$未知，而$ x|z \thicksim N(\mu(z), \sigma(z))$，于是我们真正需要求解的，是 $\mu$ 和 $\sigma$ 两个函数的表达式。又因为$P(x)$通常非常复杂，导致 $\mu$ 和 $\sigma$ 难以计算，所以我们需要引入两个神经网络来帮助我们求解。</p><p>一个神经网络是Decoder，他求解的是 $\mu$ 和 $\sigma$ 两个函数，等价于求解$P(x|z)$</p><p><img src="/images/image-20200811133518026.png" alt="Decoder" style="zoom:50%;"></p><p>另一个神经网络是Encoder，他求解的结果是$q(z|x)$，它可以代表任何分布</p><p><img src="/images/image-20200811133539702.png" alt="Encoder" style="zoom:50%;"></p><p>值得注意的是，这儿引入第二个神经网路Encoder的目的是，辅助第一个Decoder求解$P(x|z)$，后面将解释为什么这是整个VAE理论中最精妙的部分</p><h3 id="数学证明"><a href="#数学证明" class="headerlink" title="数学证明"></a>数学证明</h3><p>先回到要求解的目标式：</p><script type="math/tex; mode=display">P(x) = \int_z P(z)P(x|z)dz</script><p>显然，我们需要对其求最大似然估计，这等价于求解：</p><script type="math/tex; mode=display">Maximum L = \sum_x logP(x)</script><p>进一步推导：</p><script type="math/tex; mode=display">\log P(x) = \int_z q(z|x)logP(x)dz \space\space\space\space (q(x|z)可以是任何分布)\\= \int_z q(z|x)log(\frac{P(z,x)}{P(z|x)})dz\\= \int_z q(z|x)log(\frac{P(z,x)}{q(z|x)}\frac{q(z|x)}{P(z|x)})dz\\= \int_z q(z|x)log(\frac{P(z,x)}{q(z|x)})dz + \int_z q(z|x)log(\frac{q(z|x)}{P(z|x)})dz\\= \int_z q(z|x)log(\frac{P(z,x)}{q(z|x)}) + KL(q(z|x) || P(z|x))</script><p>上式的第二项$KL(q(z|x) || P(z|x))$是KL散度，也叫相对熵，用于度量两种概率分布之间的差异，是一个大于0的值，所以我们找到了一个$\log P(x)$的下界：</p><script type="math/tex; mode=display">\log P(x) \geq \int_z q(z|x) \log(\frac{P(x|z)P(z)}{q(z|x)})dz</script><p>我们将这份下界记做</p><script type="math/tex; mode=display">L_b = \int_z q(z|x)log(\frac{P(x|z)P(z)}{q(z|x)})dz</script><p>原式就变为：</p><script type="math/tex; mode=display">\log P(x) = L_b + KL(q(z|x) || P(z|x))</script><p>接下来就是VAE的巧妙之处了，最早我们求解的问题是要求出合适的$P(x|z)$使得$logP(x)$最大，现在我们引入了一个新的分布$ q(z|x)$，变成了同时求解$P(x|z)$和$q(z|x)$使得$\log P(x)$最大。</p><p>这时候我们需要关注一下$\log P(x)$和$L_b$的关系：</p><p><img src="/images/image-20200811141018641.png" alt="求解函数和Lb的关系" style="zoom:40%;"></p><p>一个有趣的现象是，当我们固定住$P(x|z)$时，因为$\log P(x)$只与$P(x|z)$有关，所以$\log P(x)$的值是会不变的，此时我们去调节$q(z|x)$，使得$L_b$越来越高，同时KL散度越来越小，当我们调节到$q(z|x)$与$P(x|z)$完全一致时，KL散度就消失为0，$L_b$与$\log P(x)$完全一致。由此可以得出，不论$\log P(x)$的值如何，我们总能够通过调节使得$L_b$等于$\log P(x)$，又因为$L_b$是$\log P(x)$的下界，所以求解$Maximum \space\log P(x)$等价为求解$Maximun \space L_b$。</p><p>这个现象从宏观上来看也是很有意思，调节$P(x|z)$就是在调节Decoder，调节$q(z|x)$就是在调节Encoder。于是，VAE的训练逻辑就变成了，每Decoder前进一步，Encoder就调节成与其一致的样子，并且顶住Decoder，这样Decoder在下次训练的时候就只能前进，不能退步。</p><p>上述便是VAE设计的巧妙之处，下面我们来继续求解$Maximum \space L_b$：</p><p>注意到：</p><script type="math/tex; mode=display">L_b = \int_z q(z|x)log(\frac{P(x|z)P(z)}{q(z|x)})dz\\= \int_z q(z|x)log(\frac{P(z)}{q(z|x)})dz + \int_z q(z|x)logP(x|z)dz\\= -KL(q(z|x)||P(z)) + \int_z q(z|x)logP(x|z)dz</script><p>所以，求解$Maximum \space L_b$等价于求解$KL(q(z|x)||P(z))$的最小值和$\int_z q(z|x)logP(x|z)dz$的最大值。</p><p>先来求解第一项，$-KL(q(z|x)||P(z))$的展开式是：</p><script type="math/tex; mode=display">\sum^N_{i=1}(\exp(\sigma_i)-(1+\sigma_i)+(m_i)^2)</script><p>具体计算有些复杂，不过多展开。</p><p>求解第二项</p><script type="math/tex; mode=display">Maximum\space \int_z q(z|x)logP(x|z)dz\\= Maximum E_{q(z|x)}[logP(x|z)]</script><p>就还是类似于Auto-Encoder的一个损失函数，在给定$q(z|x)$（编码器输出）的情况下求$P(x|z)$（解码器输出）的值尽可能和原输入接近，也就是架构模型中第一个损失函数的由来。</p><p><img src="/images/image-20200811143347017.png" alt="第一个损失函数" style="zoom:40%;"></p>]]></content>
    
    <summary type="html">
    
      一种深度生成模型
    
    </summary>
    
      <category term="人工智能" scheme="http://yoursite.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="神经网络" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>迁移学习简介</title>
    <link href="http://yoursite.com/2020/04/05/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/04/05/迁移学习/</id>
    <published>2020-04-05T12:15:00.000Z</published>
    <updated>2020-08-12T01:55:20.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>比如我们已经会编写Java程序，就可以类比着来学习C++，都是面向对象的语言，就很快学会了，或者在学会骑自行车之后，骑摩托车也自己比较容易了，因为这两种交通工具有许多相似之处。迁移学习，总结起来就是说我们要帮助机器获得举一反三的能力。</p><h5 id="几种分类"><a href="#几种分类" class="headerlink" title="几种分类"></a>几种分类</h5><ul><li><p>基于实例的迁移：</p><ul><li>通过权重的分配，来分别作用到源域和目标域来进行迁移，关于什么是源域，什么是目标域，这里可以先不用细究，你就明白是两个不同的空间就行了，具体的概念，后面的部分会详细的进行概述<ul><li>举例：比如说在源域中有一个样本和目标域中的一个样本非常的相似，那么我们就可以加大此样本对应的权重。</li></ul></li></ul></li><li><p>基于特征的迁移：</p><ul><li>将源域和目标域的特征变换到同一个空间。<ul><li>举例：比如说在两个域上的feature具有很大的区别，那么我们就可以通过将这两个域的feature变换到同样的空间，这个时候我们就可以很方便的研究这两个域上的相关内容和性质了。</li></ul></li></ul></li><li><p>基于模型的迁移：</p><ul><li>通过源域和目标域的参数共享机制<ul><li>举例：这也是我们在做DL中用到最多的一个方法了，比如说，将pre-trained的模型拿过来，通过固定一些layer的parameters，修改部分layer的parameters得到最终的非常好的结果。</li></ul></li></ul></li><li><p>基于关系的迁移：</p><ul><li>利用源域中某种一般性的逻辑关系进行迁移</li></ul></li></ul><h2 id="几种具体迁移方法"><a href="#几种具体迁移方法" class="headerlink" title="几种具体迁移方法"></a>几种具体迁移方法</h2><p>介绍主要侧重于训练集有标记的方法，训练集无标记的方法仍需进一步学习</p><h3 id="训练集目标集均有标记"><a href="#训练集目标集均有标记" class="headerlink" title="训练集目标集均有标记"></a>训练集目标集均有标记</h3><h4 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h4><ol><li><h5 id="conservative-training"><a href="#conservative-training" class="headerlink" title="conservative training"></a>conservative training</h5><p><img src="/images/image-20200405123157673.png" style="zoom:33%;"></p><p>此处的关键是确保参数变化不大，避免过拟合</p></li><li><h5 id="Layer-transfer"><a href="#Layer-transfer" class="headerlink" title="Layer transfer"></a>Layer transfer</h5><p><img src="/images/image-20200405123255920.png" style="zoom:33%;"></p><p>copy几层layer到新的模型，只训练没有被copy的层</p><p>几种策略</p><ul><li>语音：往往copy最后几层，前几层从声音讯号到发音方式（主要需要迁移的部分），后几层与说话者无关系。</li><li>图片：前面copy前面几层，前几层是检测最简单的特征（例如直线、曲线），泛用性较强，后几层往往包含更多抽象特征，需要迁移。</li></ul></li></ol><h4 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h4><ul><li><p>可以共用输入：主要用于多层结构的学习共用前几层，后几层分别处理：</p><p>  <img src="/images/image-20200405145832729.png" style="zoom:40%;"></p></li><li><p>不可共用输入：共用中间几个layer</p><p><img src="/images/image-20200405145943153.png" style="zoom:42%;"></p></li></ul><p>常见的使用：</p><p><img src="/images/image-20200405150130296.png" style="zoom:33%;"></p><p>例如单语言翻译为多种语言，在训练中文时即便借鉴英文（或其他语言）的知识，也可带来训练速度的提升：</p><p><img src="/images/image-20200405150507018.png" style="zoom:33%;"></p><h4 id="渐进式神经网络（仍待提升）"><a href="#渐进式神经网络（仍待提升）" class="headerlink" title="渐进式神经网络（仍待提升）"></a>渐进式神经网络（仍待提升）</h4><p>所有的之前任务的网络，保留并且fix，每次有一个新任务就新建一个网络（一列）。而为了能使用过去的经验，他们同样也会将这个任务的输入输入进所有之前的网络，并且将之前网络的每一层的输出，与当前任务的网络每一层的输出一起输入下一层。</p><p><img src="/images/image-20200405151227996.png" style="zoom: 50%;"></p><p>目前看来仍有较大的局限性，需要有相同的input feature</p><h3 id="目标集无标记"><a href="#目标集无标记" class="headerlink" title="目标集无标记"></a>目标集无标记</h3><h4 id="Domain-adversarial-learning"><a href="#Domain-adversarial-learning" class="headerlink" title="Domain-adversarial learning"></a>Domain-adversarial learning</h4><p>可以消除掉domain之间的区别</p><p>方法：在提取完Feature之后，增加一个domain classifier，再交给最后的classifier</p><p>我们希望特征可以尽可能的混合在一起</p><p><img src="/images/111.jpg" style="zoom:50%;"></p><p>此处和GAN有关（不太了解）</p><p>结构大致如下：</p><p><img src="/images/image-20200405153326556.png" style="zoom:40%;"></p><p>feature extractor不仅要尝试骗过domain classifier，还要（保留足够特征）满足label predictor的需要。它要提取一个供B和P共享的feature，这个feature有两个目标：最小化目标loss（帮助B）；最大化二分类误差（对抗P）。Why？</p><p>所谓的domain adaption，其实也就是feature对于两个不同的域是自适应的，所以我们的这个feature尽可能让两个域区分不开，feature自己不就渐渐趋于域自适应了吗？</p><p>feature extractor希望将两个domain提取出来的feature尽可能的混合在一起。但是domain classifier却希望他能够尽可能的把从feature extractor中提取出来的feature划分到两个domain中。所以增加一个负向梯度优化提供给domain classifier，DC必须努力不能被骗过，否则就无法优化FE的特征提取能力。</p><p><img src="/images/image-20200405153656635.png" style="zoom:40%;"></p><h4 id="zero-shot-learning（零次学习）"><a href="#zero-shot-learning（零次学习）" class="headerlink" title="zero-shot learning（零次学习）"></a>zero-shot learning（零次学习）</h4><p>希望模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智能。其中零次（Zero-shot）是指对于要分类的类别对象，一次也不学习。</p><p>用attributes表示每一个类，标记每种类型有哪些特性，需要有足够的attributes，它的维度是固定的，它包含了能够较充分描述数据集中类别的属性。</p><p>经过神经网络之后，输出对应的特征，然后进行查表。</p><p>假设我们的模型已经能够识别马，老虎和熊猫了，现在需要该模型也识别斑马，那么我们需要告诉模型，怎样的对象才是斑马，但是并不能直接让模型看见斑马。所以模型需要知道的信息是马的样本、老虎的样本、熊猫的样本和样本的标签，以及关于前三种动物和斑马的描述。</p><h5 id="attribute-embedding"><a href="#attribute-embedding" class="headerlink" title="attribute embedding"></a>attribute embedding</h5><p><img src="/images/image-20200405192216950.png" style="zoom:40%;"></p><p>让attribute embedding和word embedding尽可能的接近</p><p>假设目标函数是这个：</p><script type="math/tex; mode=display">f*,g*=arg\min_{f,g}\sum_{n}||f(x^n) - g(y^n)||_2</script><p>不妨思考一下，这个公式合理吗？</p><p>显然是不合理的，因为这样可能会导致所有的向量都聚在一起，所以应该还要考虑和其他向量的距离：</p><script type="math/tex; mode=display">f*,g*=arg\min_f,g\sum_n\max(0,k-f(x^n)g(y^n)+max_{m\neq n}f(x^n)g(y^m))</script><p>（k是自己定义的一个常量）</p><p>zero loss：</p><script type="math/tex; mode=display">k-f(x^n)g(y^n)+min_{m\neq n}f(x^n)g(y^m) < 0</script><script type="math/tex; mode=display">(x^n)g(y^n)-max_{m\neq n}f(x^n)g(y^m)>k</script><p>既要保证同类相近，又要保证不同的类尽可能的远</p><h5 id="convex-combination-of-semantic-embedding"><a href="#convex-combination-of-semantic-embedding" class="headerlink" title="convex combination of semantic embedding"></a>convex combination of semantic embedding</h5><p><img src="/images/image-20200405194508467.png" style="zoom:40%;"></p><p>lion和tiger概率相近，则将这两个的向量混合，查看他更接近哪一个word embedding</p><h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h4><p>测试图片    卷积神经网络    Domain-adversarial    zero-shot</p><p><img src="/images/image-20200405195117715.png" style="zoom:35%;"></p><h4 id="翻译的zero-shot-learning"><a href="#翻译的zero-shot-learning" class="headerlink" title="翻译的zero-shot learning"></a>翻译的zero-shot learning</h4><p>已知英文&lt;-&gt;韩文，英文&lt;-&gt;日文</p><p>可以做到韩文&lt;-&gt;日文</p><p>语言encode进向量空间再decode：</p><p><img src="/images/image-20200405195818132.png" style="zoom:40%;"></p><p>可以发现多个语言的同一种意思会在同一块空间，也可以理解为机器“发明”了自己的语言</p><h3 id="训练集无标记目标集有标记"><a href="#训练集无标记目标集有标记" class="headerlink" title="训练集无标记目标集有标记"></a>训练集无标记目标集有标记</h3><p>self-taught learning</p><p>和半监督学习不同（但可以说相似）</p><p>学习如何提取源数据的更好的表示（无监督方法）</p><p>获取目标数据的更好表示</p><h3 id="均无标记"><a href="#均无标记" class="headerlink" title="均无标记"></a>均无标记</h3><p>self-taught Clustering</p><p>和普通的transfer learning不同</p><p>以后有机会学习一下</p>]]></content>
    
    <summary type="html">
    
      迁移学习，个人的理解是通过对于源域的学习来帮助我们进行对于目标域的学习
    
    </summary>
    
      <category term="人工智能" scheme="http://yoursite.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="神经网络" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Yolo_v1学习</title>
    <link href="http://yoursite.com/2020/04/02/Yolo%20v1%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/04/02/Yolo v1学习/</id>
    <published>2020-04-02T07:30:00.000Z</published>
    <updated>2021-03-03T11:58:32.992Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote><p>Current detection systems repurpose classifiers to per- form detection. To detect an object, these systems take a classifier for that object and evaluate it at various locations and scales in a test image. Systems like deformable parts models (DPM) use a sliding window approach where the classifier is run at evenly spaced locations over the entire image </p></blockquote><p>在yolo之前的物体检测系统使用分类器来完成物体检测任务：为了检测一个物体，这些物体检测系统要在一张测试图的不同位置和不同尺寸的bounding box上使用该物体的分类器去评估是否有该物体。例如DPM系统，要使用一个滑窗（sliding window）在整张图像上均匀滑动，用分类器评估是否有物体。</p><p>在DPM之后提出的其他方法，如R-CNN方法使用region proposal来生成整张图像中可能包含待检测物体的potential bounding boxes，然后用分类器来评估这些boxes，接着通过post-processing来改善bounding boxes，消除重复的检测目标，并基于整个场景中的其他物体重新对boxes进行打分。整个流程执行下来很慢，而且因为这些环节都是分开训练的，检测性能很难进行优化。</p><blockquote><p>We reframe object detection as a single regression prob- lem, straight from image pixels to bounding box coordi- nates and class probabilities. Using our system, you only look once (YOLO) at an image to predict what objects are present and where they are.</p></blockquote><p>yolo应该是第一个使用回归思想来处理物体检测问题的，直接通过整张图片的所有像素得到bounding box的坐标、box中包含物体的置信度和class probabilities。通过YOLO，每张图像只需要输入到神经网络就能得出图像中都有哪些物体和这些物体的位置。 </p><p>所以yolo有多个明显的优点：</p><ol><li>检测速度很快，没有复杂的流程，只需将图像输入神经网络就可以得到检测结果。</li><li>可以比较好地避免背景错误，相比较采用滑窗的物体检测系统，yolo可以更好的利用全局信息和上下文信息。</li><li>可以学习到物体的泛化特征，更有利于迁移。</li></ol><p>但yolo也存在一些缺点：</p><ol><li>检测精度和当下领先的的一些物体检测系统（如R-CNN）相比偏低。</li><li>更容易产生定位错误。</li><li>对小物体的检测效果不好（尤其是密集的小物体），每个栅格只有两个选框。</li></ol><h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h2><blockquote><p>We unify the separate components of object detection into a single neural network. Our network uses features from the entire image to predict each bounding box. It also predicts all bounding boxes across all classes for an im- age simultaneously. This means our network reasons glob- ally about the full image and all the objects in the image. The YOLO design enables end-to-end training and real- time speeds while maintaining high average precision.</p></blockquote><p>YOLO将输入图像划分为S*S的栅格，每个栅格负责检测中心落在该栅格中的物体。<br>每一个栅格预测B个(论文中默认为2个）bounding boxes，以及这些bounding boxes的confidence scores。这个 confidence scores反映了模型对于这个栅格的预测：该栅格是否含有物体，以及这个box的坐标预测的有多准。公式定义如下： </p><script type="math/tex; mode=display">confidence = Pr(Object) * IOU_{pred}^{truth}</script><p>如果这个栅格中不存在一个 object，则confidence score应该为0；否则的话，confidence score则为 predicted bounding box与 ground truth box之间的 IOU（intersection over union）。</p><p>同时，yolo对每个box还有五个预测值：x，y，w，h，confidence</p><ul><li>坐标x, y代表了预测的bounding box的中心与栅格边界的相对值。 </li><li>坐标w, h代表了预测的bounding box的width、height相对于整幅图像width,height的比例。 </li><li>confidence就是预测的bounding box和ground truth box的IOU值。 </li></ul><p>每一个栅格还要预测C个 conditional class probability（条件类别概率）：$Pr(Class_i|Object)$。即在一个栅格包含一个Object的前提下，它属于某个类的概率。 </p><p>对于每个栅格只预测一组（C个）类概率，而不考虑框B的数量，在测试阶段，将每个栅格的conditional class probabilities与每个 bounding box的 confidence相乘： </p><script type="math/tex; mode=display">Pr(Class_i|Object)*Pr(Object)*IOU_{pred}^{truth}=Pr(Class_i)*IOU_{pred}^{truth}</script><p>这样便得到了每个bounding box的具体类别的confidence score。 这乘积既包含了bounding box中预测的class的 probability信息，也反映了bounding box是否含有Object和bounding box坐标的准确度。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><blockquote><p>We implement this model as a convolutional neural net- work and evaluate it on the PASCAL VOC detection dataset [9]. The initial convolutional layers of the network extract features from the image while the fully connected layers predict the output probabilities and coordinates.</p><p>Our network architecture is inspired by the GoogLeNet model for image classification [34]. Our network has 24 convolutional layers followed by 2 fully connected layers. Instead of the inception modules used by GoogLeNet, we simply use 1 × 1 reduction layers followed by 3 × 3 convo- lutional layers, similar to Lin et al [22]. </p></blockquote><p>网络结构如下图：</p><p><img src="/images/image-20200402163413943.png" alt="image-20200402163413943" style="zoom:33%;"></p><p>输入图像大小为448 x 448，经过若干个卷积层与池化层，变为7 x 7 x 1024张量（图一中倒数第三个立方体），最后经过两层全连接层，输出张量维度为7 x 7 x 30。</p><p>这就是Yolo v1的整个神经网络结构，和一般的卷积物体分类网络没有太多区别，最大的不同就是：分类网络最后的全连接层，一般连接于一个一维向量，向量的不同位代表不同类别，而这里的输出向量是一个三维的张量（7 x 7 x 30）。</p><p>对于最后输出的张量是7 × 7 × 30，即 S x S x ( B x 5 + C)​（B为选框个数，C为类的数量）。</p><p>没有使用BN层，用了一层Dropout。除了最后一层的输出使用了线性激活函数，其他层全部使用Leaky Relu激活函数。</p><script type="math/tex; mode=display">f(x) = \begin{cases}  x, & x > 0 \\  0.1x, & otherwise\end{cases}</script><p>而对于选框个数B其实是可以调整的，每个方格产生B个选框，最后选定置信度更大的矩形框作为输出，也就是最终每个方格只输出一个预测矩形框，并且每个方格只能预测一个物体。虽然可以通过调整参数，产生不同的矩形框，但这只能提高矩形框的精度。所以当有很多个物体的中心点落在了同一个格子里，该格子只能预测一个物体。也就是格子数为7*7时，该网络最多预测49个物体。</p><blockquote><p>YOLO imposes strong spatial constraints on bounding box predictions since each grid cell only predicts two boxes and can only have one class. This spatial constraint limits the number of nearby objects that our model can predict. Our model struggles with small objects that appear in groups, such as flocks of birds.</p></blockquote><p>正如论文中所说，yolo在面对一些邻近的小物体识别效果不是很好。</p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><blockquote><p>Our final layer predicts both class probabilities and bounding box coordinates. We normalize the bounding box width and height by the image width and height so that they fall between 0 and 1. We parametrize the bounding box x and y coordinates to be offsets of a particular grid cell loca- tion so they are also bounded between 0 and 1.</p></blockquote><p>yolo将所有的预测结果都归一化到 0~1，对于offsets的处理有一点小技巧， yolo不直接回归中心点坐标数值，而是回归相对于格点左上角坐标的位移值。例如，第一个格点中物体坐标为 （1.3，3.5） ，另一个格点中的物体坐标为（4.8，6.7），这四个数值让神经网络暴力回归，有一定难度。</p><p>所以这里的offset是指，既然格点已知，那么物体中心点的坐标一定在格点正方形里，相对于格点左上角的位移值一定在区间[0, 1)中。让神经网络去预测 （0.3，0.5） 与（0.8，0.7）会更加容易，在使用时，加上格点左上角坐标（1，3）、（4，6）即可。</p><blockquote><p>At training time we only want one bounding box predictor to be responsible for each object. We assign one predictor to be “responsible” for predicting an object based on which prediction has the highest current IOU with the ground truth. This leads to specialization between the bounding box predictors. Each predictor gets better at predicting certain sizes, aspect ratios, or classes of object, improving overall recall.</p></blockquote><p>每个格点预测B个矩形，在损失函数计算中，只对和真实物体最接近的框计算损失，其余框不进行修正。因此，当前哪一个predictor预测的bounding box与ground truth box的IOU最大，这个 predictor就负责 predict object。</p><p>会使得每个predictor可以专门的负责特定的物体检测。随着训练的进行，每一个 predictor对特定的物体尺寸、长宽比的物体的类别的预测会越来越好。</p><p>这样操作之后发现，一个格点的B个框在尺寸、长宽比、或者某些类别上逐渐有所分工，总体的召回率有所提升。</p><blockquote><p>However, some large objects or objects near the border of multiple cells can be well localized by multiple cells. Non-maximal suppression can be used to fix these multiple detections. While not critical to performance as it is for R-CNN or DPM, non-maximal suppression adds 2 - 3% in mAP</p></blockquote><p>通常来说，在预测的时候，格点与格点并不会冲突，但是在预测一些大物体或者邻近物体时，会有多个格点预测了同一个物体。此时采用非极大抑制技巧，过滤掉一些重叠的矩形框。但是mAP提升并没有显著提升。</p><p>Yolo v1使用普通的梯度下降法作为优化器，Loss函数如下：</p><p><img src="/images/image-20200402170121811.png" alt="image-20200402170121811" style="zoom:40%;"></p><ul><li>预测框的中心点，如第一行其中$1_{ij}^{obj}$为控制函数，在标签中包含物体的那些格点处，该值为 1 ；若格点不含有物体，该值为 0。也就是只对那些有真实物体所属的格点进行损失计算，若该格点不包含物体，那么预测数值不对损失函数造成影响。(x,y)数值与标签用简单的平方和误差。</li><li>预测框的宽高(w,h)。如第二行，$1_{ij}^{obj}$的含义一样，也是使得只有真实物体所属的格点才会造成损失。这里对 (w,h)在损失函数中的处理分别取了根号，原因在于，如果不取根号，损失函数往往更倾向于调整尺寸比较大的预测框。例如，20个像素点的偏差，对于800 x 600​的预测框几乎没有影响，此时的IOU数值还是很大，但是对于​30 x 40​的预测框影响就很大。取根号是为了尽可能的消除大尺寸框与小尺寸框之间的差异。</li><li>预测框的置信度C。当该格点不含有物体时，该置信度的标签为0；若含有物体时，该置信度的标签为预测框与真实物体框的IOU数值（IOU计算公式为：两个框交集的面积除以并集的面积）。</li><li>物体类别概率P，对应的类别位置，该标签数值为1，其余位置为0，与分类网络相同。</li></ul><blockquote><p>To remedy this, we increase the loss from bounding box coordinate predictions and decrease the loss from confi- dence predictions for boxes that don’t contain objects. We use two parameters, λcoord and λnoobj to accomplish this. We set λcoord = 5 and λnoobj = .5.</p></blockquote><p>而$\lambda_{coord}$和$\lambda_{noobj}$是为了让模型更加“重视”含有物体的格点所造成的损失，在论文中分别取5和0.5。 </p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Yolo v1最大的贡献就是将物体检测作为一个回归问题进行求解，图像仅经过一次网络，便能得到图像中所有物体的位置和其所属类别及相应的置信概率。而其余常见的模型则主要分两部分求解：物体类别（分类问题），物体位置即bounding box（回归问题）。</p>]]></content>
    
    <summary type="html">
    
      Yolo(You only look once)创新性地将物体检测作为一个回归问题进行求解,解决了基于DL的物体检测中的一大痛点——速度问题
    
    </summary>
    
      <category term="人工智能" scheme="http://yoursite.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="计算机视觉" scheme="http://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="论文阅读" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>联邦学习论文阅读</title>
    <link href="http://yoursite.com/2020/03/30/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <id>http://yoursite.com/2020/03/30/联邦学习论文阅读/</id>
    <published>2020-03-30T09:45:58.000Z</published>
    <updated>2020-04-30T15:23:49.171Z</updated>
    
    <content type="html"><![CDATA[<p>最近阅读了两篇关于联邦学习的论文，《Communication-Efficient Learning of Deep Networks from Decentralized Data》和《FedMD Heterogenous Federated Learning via Model Distillation》，提出了两种算法FedAvg和FedMD。</p><h2 id="Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data"><a href="#Communication-Efficient-Learning-of-Deep-Networks-from-Decentralized-Data" class="headerlink" title="Communication-Efficient Learning of Deep Networks from Decentralized Data"></a>Communication-Efficient Learning of Deep Networks from Decentralized Data</h2><h3 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h3><blockquote><p>Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos.However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches.</p></blockquote><p>面对敏感或者很庞大的且不能直接上传到data center的数据，可能无法使用传统的方法集中训练模型。</p><h3 id="主要研究内容"><a href="#主要研究内容" class="headerlink" title="主要研究内容"></a>主要研究内容</h3><blockquote><p>We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning.</p></blockquote><p>提出了一种代替性的模型训练方法——<strong>Federated Learning</strong></p><blockquote><p>We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10–100× as compared to synchronized stochastic gradient descent.</p></blockquote><p>提出了基于迭代模型平均的算法，对于非独立同分布数据仍然有效，且相比同步随即梯度下降减少了10-100倍的通信成本</p><blockquote><p>More concretely, we introduce the FederatedAveraging algorithm, which combines local stochastic gradient descent (SGD) on each client with a server that performs model averaging. We perform extensive experiments on this algorithm, demonstrating it is robust to unbalanced and non-IID data distributions, and can reduce the rounds of communication needed to train a deep network on decentralized data by orders of magnitude.</p></blockquote><p>提出FedAvg算法，将每个客户端上的本地随机梯度下降（SGD）与执行模型平均的服务器相结合。 对不平衡和非IID数据分布有很好的鲁棒性，并且可以减少对分散数据进行深度网络训练所需的通信次数。</p><h3 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h3><blockquote><p>Federated Learning Ideal problems for federated learn- ing have the following properties: 1) Training on real-world data from mobile devices provides a distinct advantage over training on proxy data that is generally available in the data center. 2) This data is privacy sensitive or large in size (compared to the size of the model), so it is preferable not to log it to the data center purely for the purpose of model training (in service of the focused collection principle). 3) For supervised tasks, labels on the data can be inferred naturally from user interaction.</p></blockquote><p>联合学习联合学习的理想问题具有以下特性：</p><ol><li><p>训练来自移动设备的真实数据比训练数据中心通常提供的代理数据具有明显的优势。</p></li><li><p>此数据是隐私敏感的或较大的（与模型的大小相比），因此最好不要仅出于模型训练的目的（出于集中收集的原则）将其记录到数据中心。</p></li><li><p>对于监督任务，可以从用户交互中自然推断出数据上的标签。</p></li></ol><h3 id="隐私"><a href="#隐私" class="headerlink" title="隐私"></a>隐私</h3><blockquote><p>Privacy Federated learning has distinct privacy advantages compared to data center training on persisted data. Holding even an “anonymized” dataset can still put user privacy at risk via joins with other data (Sweeney, 2000). In contrast, the information transmitted for federated learning is the minimal update necessary to improve a particular model (naturally, the strength of the privacy benefit depends on the content of the updates.) The updates themselves can (and should) be ephemeral. They will never contain more information than the raw training data (by the data processing inequality), and will generally contain much less. Further, the source of the updates is not needed by the aggregation algorithm, so updates can be transmitted without identifying meta-data over a mix network such as Tor (Chaum, 1981) or via a trusted third party. We briefly discuss the possibility of combining federated learning with secure multiparty computation and differential privacy at the end of the paper.</p></blockquote><ol><li>FL 传输的信息是改进特定模型所必需的最小更新（隐私利益的强度取决于更新的内容）;</li><li>更新本身是短暂的，所包含的信息绝不会超过原始训练数据且通常会少得多；</li><li>聚合算法不需要更新源（不需要知道用户是谁？），因此，可以通过混合网络（例如Tor）或通过受信任的第三方传输更新而无需标识元数据。</li><li>将联合学习与安全的多方计算及差分隐私相结合</li></ol><h3 id="联邦优化"><a href="#联邦优化" class="headerlink" title="联邦优化"></a>联邦优化</h3><p>在联邦学习中的优化问题</p><p>几个关键属性：</p><blockquote><p>Non-IID The training data on a given client is typically based on the usage of the mobile device by a particular user, and hence any particular user’s local dataset will not be representative of the population distribution.<br>Unbalanced Similarly, some users will make much heavier use of the service or app than others, leading to varying amounts of local training data.<br>Massively distributed We expect the number of clients participating in an optimization to be much larger than the average number of examples per client.<br>Limited communication Mobile devices are frequently offline or on slow or expensive connections.</p></blockquote><ol><li>用户数据非独立同分布： 特定的用户数据不能代表用户的整体分布；</li><li>用户数据量不平衡： 数据量不均衡，因为有的用户使用多，有的用户使用少；</li><li>用户（分布）是大规模的： 参与优化的用户数大于平均每个用户的数据量；</li><li>用户端设备通信限制： 移动设备经常掉线、速度缓慢、费用昂贵。</li></ol><p>最重要的就是<strong>非独立同分布、不平衡的数据和面对的通信约束</strong></p><p>实践中面对的问题：</p><blockquote><p>A deployed federated optimization system must also address a myriad of practical issues: client datasets that change as data is added and deleted; client availability that correlates with the local data distribution in complex ways; and clients that never respond or send corrupted updates.</p></blockquote><ol><li>随着数据添加和删除而不断改变的客户端数据集；</li><li>客户端（更新）的可用性与其本地数据分布有着复杂的关系；</li><li>从来不响应或发送信息的客户端会损坏更新</li></ol><p>但在<strong>本文中不做考虑</strong></p><h3 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h3><h4 id="执行方法"><a href="#执行方法" class="headerlink" title="执行方法"></a>执行方法</h4><blockquote><p>We assume a synchronous update scheme that proceeds in rounds of communication. There is a fixed set of K clients, each with a fixed local dataset. At the beginning of each round, a random fraction C of clients is selected, and the server sends the current global algorithm state to each of these clients (e.g., the current model parameters). Each client then performs local computation based on the global state and its local dataset, and sends an update to the server. The server then applies these updates to its global state, and the process repeats.</p></blockquote><p>假设同步更新方案在各轮通信中进行；有一组固定的客户端集合，大小为K，每个客户端都有一个固定的本地数据集；</p><ol><li>在每轮更新开始时，随机选择部分客户端，比例为C（C≤1）；</li><li>服务器将当前的全局算法的状态发送给这些客户（例如，当前的模型参数）；</li><li>每个客户端都基于全局状态及其本地数据集执行本地计算，并将更新发送到服务器；</li><li>最后，服务器将这些更新应用于其全局状态，然后重复该过程。</li></ol><h4 id="非凸神经网络的目标函数"><a href="#非凸神经网络的目标函数" class="headerlink" title="非凸神经网络的目标函数"></a>非凸神经网络的目标函数</h4><blockquote><p>While we focus on non-convex neural network objectives, the algorithm we consider is applicable to any finite-sum objective of the form</p></blockquote><p><img src="/images/fd_al1.png" alt="image-20200330200506682"></p><blockquote><p>For a machine learning problem, we typically take fi(w) = l(xi, yi; w), that is, the loss of the prediction on example (xi, yi) made with model parameters w. We assume there are K clients over which the data is partitioned, with Pk the set of indexes of data points on client k, with nk = |Pk|.</p><p>Thus, we can re-write the objective (1) as</p></blockquote><p>对于机器学习问题，我们通常定义fi(w) = L(xi,yi;w)；假设数据分布在K个客户端，Dk代表客户端k数据点的集合，nk为Dk的大小，目标函数可以重写为：</p><p><img src="/images/fd_al2.png" alt="image-20200330201216427"></p><p>如果划分Dk是所有用户数据的随机取样，则目标函数f(w)就等价于损失函数关于Dk的期望：</p><p><img src="/images/fd_al3.png" alt="image-20200330201341489"></p><p>（这就是传统的分布式优化问题的独立同分布假设）</p><h3 id="通信成本和计算成本"><a href="#通信成本和计算成本" class="headerlink" title="通信成本和计算成本"></a>通信成本和计算成本</h3><blockquote><p><strong>Thus, our goal is to use additional computation in order to decrease the number of rounds of communication needed to train a model. </strong>There are two primary ways we can add computation: <strong>1) increased parallelism, </strong>where we use more clients working independently between each communication round; and, <strong>2) increased computation on each client,</strong> where rather than performing a simple computation like a gradient calculation, each client performs a more complex calculation between each communication round. We investigate both of these approaches, but the speedups we achieve are due primarily to adding more computation on each client, once a minimum level of parallelism over clients is used.</p></blockquote><ul><li><p>在data center的优化问题中，通信成本相对较小，而计算成本占主导地位，重点是可以使用GPU来降低这些成本；</p></li><li><p>在联合优化中，通信成本占主导地位：</p><ul><li><p>通常会受到1 MB/s或更小的上传带宽的限制；</p></li><li><p>并且客户通常只会在充电，插入电源和不计量的Wi-Fi连接时自愿参与优化；</p></li><li><p>希望每个客户每天只参加少量的更新回合</p></li></ul><p>而计算成本相对较小：</p><ul><li><p>任何单个设备上的数据集都比总数据集的大小小；</p></li><li><p>现代智能手机具有相对较快的处理器（包括GPU）</p></li></ul></li></ul><p>因此，我们的目标是使用额外的计算，以减少训练模型所需的通信次数。</p><p>考虑两种方法来添加计算量：</p><ul><li>提高并行性：在每个通信回合之间使用更多的客户端独立工作；</li><li>增加每个客户端的计算量： 不像梯度计算那样执行简单的计算，而是每个客户端在每个通信回合之间执行更复杂的计算。</li></ul><p>在最低级别的客户端并行性后，我们实现的加速主要是由于在每个客户端上添加了更多的计算。</p><blockquote><p>Asynchronous distributed forms of SGD have also been applied to training neural net- works, e.g., Dean et al. (2012), but these approaches require a prohibitive number of updates in the federated setting. One endpoint of the (parameterized) algorithm family we consider is simple one-shot averaging, where each client solves for the model that minimizes (possibly regularized) loss on their local data, and these models are averaged to produce the final global model. This approach has been studied extensively in the convex case with IID data, and it is known that in the worst-case, the global model produced is no better than training a model on a single client (Zhang et al., 2012; Arjevani and Shamir, 2015; Zinkevich et al., 2010).</p></blockquote><p>SGD的异步分布式形式也已用于训练神经网络</p><p>在众多（参数化）算法中，我们最终考虑的是简单一次平均（simple one-shot averaging），其中每个客户解决的模型将其本地数据的损失降到最低（可能是正则化的），然后将这些模型取平均值以生成最终的全局模型。这种方法已经在带有独立同分布数据的凸情况下进行了广泛的研究，在最坏的情况下，生成的全局模型并不比在单个客户端上训练模型更好。</p><h3 id="Federated-Averaging-Algorithm"><a href="#Federated-Averaging-Algorithm" class="headerlink" title="Federated Averaging Algorithm"></a>Federated Averaging Algorithm</h3><blockquote><p>The recent multitude of successful applications of deep learning have almost exclusively relied on variants of stochastic gradient descent (SGD) for optimization; in fact, many advances can be understood as adapting the structure of the model (and hence the loss function) to be more amenable to optimization by simple gradient-based methods (Goodfellow et al., 2016). Thus, it is natural that we build algorithms for federated optimization by starting from SGD.</p></blockquote><ol><li>深度学习的最新成功应用几乎都依赖于随机梯度下降（SGD）的变体进行优化；</li><li>实际上，许多进展可以理解为通过调整模型的结构（或者损失函数），使其更易于使用简单的gradient-based methods进行优化。</li></ol><h4 id="baseline算法——FederatedSGD"><a href="#baseline算法——FederatedSGD" class="headerlink" title="baseline算法——FederatedSGD"></a>baseline算法——FederatedSGD</h4><blockquote><p>SGD can be applied naively to the federated optimization problem, where a single batch gradient calculation (say on a randomly selected client) is done per round of communication. This approach is computationally efficient, but requires very large numbers of rounds of training to produce good models (e.g., even using an advanced approach like batch normalization, Ioffe and Szegedy (2015) trained MNIST for 50000 steps on minibatches of size 60). We consider this baseline in our CIFAR-10 experiments.</p></blockquote><p>问题：计算效率很高，但是需要大量（多轮）训练才能生成好的模型</p><blockquote><p>In the federated setting, there is little cost in wall-clock time to involving more clients, and so for our baseline we use large-batch synchronous SGD; experiments by Chen et al. (2016) show this approach is state-of-the-art in the data center setting, where it outperforms asynchronous approaches. To apply this approach in the federated setting, we select a C-fraction of clients on each round, and computes the gradient of the loss over all the data held by these clients. Thus, C controls the global batch size, with C = 1 corresponding to full-batch (non-stochastic) gradient descent. We refer to this baseline algorithm as FederatedSGD (or FedSGD).</p></blockquote><p>SGD可以直接应用于联邦优化，即每轮在随机选择的客户端上进行一次梯度计算</p><p>基线算法：大批量同步SGD（在data center中是最先进的，优于异步方法）</p><p>FL形式： 每轮在clients中选择C-fraction，计算这些clients的所有数据的损失函数梯度</p><p>参数C： 控制global batch size；C = 1即全批（非随机）梯度下降</p><h4 id="FedratedAveraging"><a href="#FedratedAveraging" class="headerlink" title="FedratedAveraging"></a>FedratedAveraging</h4><blockquote><p>The amount of computation is controlled by three key parameters: C, the fraction of clients that perform computation on each round; E, then number of training passes each client makes over its local dataset on each round; and B, the local minibatch size used for the client updates. We write B = ∞ to indicate that the full local dataset is treated as a single minibatch. Thus, at one endpoint of this algorithm family, we can take B = ∞ and E = 1 which corresponds exactly to FedSGD. Complete pseudo-code is given in Algorithm 1</p></blockquote><p>个人认为，FedAvg可以看作FedSGD在用户本地进行多次梯度更新</p><p>几个参数：C，B（本地batch），E（本地轮数）</p><p>B = INF &amp; E= 1    local_batchsize为全部数据，更新一轮</p><h4 id="模型的平均效果分析"><a href="#模型的平均效果分析" class="headerlink" title="模型的平均效果分析"></a>模型的平均效果分析</h4><p>对于一般的非凸目标函数，参数空间中的平均模型可能会产生任意不好的模型结果。当我们平均两个从不同初始条件训练的MNIST数字识别模型时，我们恰好看到了这种不良结果（图1，左）。</p><p><img src="/images/fd_char1.png" alt="image-20200330203909908"></p><p>目前的一些实验显示，从<strong>相同的随机初始化</strong>开始训练两个模型，然后在不同的数据子集上对每个模型进行独立训练，进行<strong>朴素的参数平均效果很好</strong>（图1，右）。</p><blockquote><p>The success of dropout training also provides some intuition for the success of our model averaging scheme; dropout training can be interpreted as averaging models of different architectures which share parameters, and the inference- time scaling of the model parameters is analogous to the model averaging used in FedAvg (Srivastava et al., 2014).</p></blockquote><p>Dropout training可以解释为共享参数的不同体系结构的平均模型，模型参数的推理时间缩放类似于FedAvg中使用的模型平均。</p><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>对图像分类和语言建模分别进行了试验，也对IID和non-IID进行了试验</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><blockquote><p>For all three model classes, FedAvg converges to a higher level of test-set accuracy than the baseline FedSGD models. This trend continues even if the lines are extended beyond the plotted ranges. For example, for the CNN the B = ∞, E = 1 FedSGD model eventually reaches 99.22% accuracy after 1200 rounds (and had not improved further after 6000 rounds), while the B = 10, E = 20 FedAvg model reaches an accuracy of 99.44% after 300 rounds. We conjecture that in addition to lowering communication costs, model averaging produces a regularization benefit similar to that achieved by dropout (Srivastava et al., 2014).<br>We are primarily concerned with generalization performance, but FedAvg is effective at optimizing the training loss as well, even beyond the point where test-set accuracy plateaus. We observed similar behavior for all three model classes, and present plots for the MNIST CNN in Figure 6 in Appendix A</p></blockquote><p>FedAvg收敛到比基准FedSGD模型更高的测试集准确性水平。（即使超出了绘制范围，这种趋势仍将继续。）例如，对于CNN，B =∞，E = 1 FedSGD模型最终在1200轮后达到了99.22％的准确度（并且在6000轮之后并没有进一步改善）；而B = 10，E = 20的FedAvg模型达到了300轮后达到99.44％。</p><p>因此推测，除了降低通信成本外，模型平均还产生了与dropout正则化相似的优化效果。</p><p>FedAvg具有一定的泛化能力，甚至可以优化训练损失（超出测试集精度的稳定水平）</p><blockquote><p>That is, we would expect that while one round of averaging might produce a reasonable model, additional rounds of communication (and averaging) would not produce further improvements.</p></blockquote><p>当前模型参数仅通过初始化影响每个Client Update中执行的优化。 当E→∞时，至少对于凸问题，并且无论初始化如何，都将达到全局最小值；对于非凸问题，只要初始化是在同一个”盆地“中，算法也会收敛到相同的局部最小值。</p><p><img src="/images/fed_char3.png" alt="image-20200330205221327"></p><p>对于某些模型，尤其是在收敛的后期阶段，以与降低学习率有用的相同方式来降低每轮的本地计算量（移动到较小的E或较大的B）可能是有用的，但对于很大的E值，我们看不到收敛速度的明显下降。</p><p><img src="/images/fd_char2.png" alt="image-20200330205102093"></p><h4 id="其他发现"><a href="#其他发现" class="headerlink" title="其他发现"></a>其他发现</h4><p>对SGD和FedAvg进行minibatch B = 50的实验，可以将精度视为进行minibatch gradient calculations次数的函数。 我们希望SGD能表现得更好，因为在每次minibatch computation之后都会采取一个顺序步骤。 但是，如图9，对于适当的C和E值，FedAvg在每次minibatch computation中取得相似的进度。 此外，当SGD和FedAvg每轮只有一个client时（绿），准确性显着波动，而对更多clients进行平均则可以解决这一问题（黄）。<br><img src="/images/fed_char4.png" alt="image-20200330205355840"></p><h4 id="FedAvg对比FedSGD"><a href="#FedAvg对比FedSGD" class="headerlink" title="FedAvg对比FedSGD"></a>FedAvg对比FedSGD</h4><p>显示了最佳学习率的单调学习曲线。 η= 0.4的FedSGD需要310轮才能达到8.1％的准确度，而η= 18.0的FedAvg仅在20轮就达到了8.5％的准确性（比FedSGD少15倍）。</p><p><img src="/images/fd_char5.png" alt="image-20200330205531333"></p><p>不同lr对于FedAvg的准确性影响也要小得多</p><p><img src="/images/fd_char6.png" alt="image-20200330205627239"></p><h4 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h4><p>FedAvg可以使用相对较少的轮次来训练高质量的模型，联邦学习是实际可行的</p><p>尽管联邦学习目前提供了许多隐私优势，但是通过差分隐私、多方安全计算及他们的组合是未来发展的方向</p><h2 id="FedMD-Heterogenous-Federated-Learning-via-Model-Distillation"><a href="#FedMD-Heterogenous-Federated-Learning-via-Model-Distillation" class="headerlink" title="FedMD Heterogenous Federated Learning via Model Distillation"></a>FedMD Heterogenous Federated Learning via Model Distillation</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>相比之下这个思路看起来比较简单，使用了Model DIstilation的思想</p><p>可以支持多个client使用不同的模型进行本地训练</p><p>其中关键是存在一个公共数据集</p><blockquote><p>Before a participant starts the collaboration phase, its model must first undergo the entire transfer learning process. It will be trained fully on the public dataset and then on its own private data. Therefore any future improvements are compared to this baseline.</p></blockquote><p>在正式训练开始前，所有client先要进行一轮预训练，预训练使用的数据集是公共数据集和各个client的本地数据集</p><blockquote><p>We re-purpose the public dataset D0 as the basis of communication between models, which is realized using knowledge distillation. Each learner fk expresses its knowledge by sharing the class scores, fk(x0i ), computed on the public dataset D0. The central server collects these class scores and computes an average f (xi ). Each party then trains fk to approach the consensus f (xi ). In this way, the knowledge of one participant can be understood by others without explicitly<br>sharing its private data or model architecture. Using the entire large public dataset can cause a large communication burden. In practice, the server may randomly select a much smaller subset dj ⊂ D0 at each round as the basis of communication. In this way, the cost is under control and does not scale with the complexity of participating models.</p></blockquote><p>预训练进行完成之后进行正式训练，在正式训练过程中，每一轮都从公共数据集中拿出一个small_batch进行训练</p><p>然后每个client都根据自己的模型计算出一个output（向量，未经过激活函数），并把他上传到server</p><p>server将对这些向量进行一个平均，作为所有client的一个consensus，然后server会将这个consensus传给每一个client，然后各个client需要调整权重，向着靠近consensus的方向调整。</p><h3 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/images/image-20200330212355474.png" alt="image-20200330212355474"></p><blockquote><p>Figure 2: FedMD improves the test accuracy of participating models beyond their baselines. A dashed line (on the left) represents the test accuracy of a model after full transfer learning with the public dataset and its own small private dataset. This baseline is our starting point and overlaps with the beginning of the corresponding learning curve. A dash-dot line (on the right) represents the would-be performance of a model if private datasets from all participants were declassified and made available to every participant of the group.</p></blockquote><p>FedMD提高了参与模型的测试精度，超出了其基线。 虚线（左侧）代表使用公共数据集和其自己的小型私有数据集进行完全转移学习后模型的测试准确性。 该基线是我们的起点，并且与相应的学习曲线的起点重叠。 点线（在右侧）表示如果将所有参与者的私人数据集解密并提供给组中的每个参与者，则模型的预期性能。</p>]]></content>
    
    <summary type="html">
    
      联邦学习的提出主要是为了解决数据孤岛问题，文中的两篇论文分别介绍了Federated Averaging算法和基于Model Distillation的Faderated Learning
    
    </summary>
    
      <category term="人工智能" scheme="http://yoursite.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="论文阅读" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Android View的绘制</title>
    <link href="http://yoursite.com/2020/03/16/Android%20View%E7%9A%84%E7%BB%98%E5%88%B6/"/>
    <id>http://yoursite.com/2020/03/16/Android View的绘制/</id>
    <published>2020-03-16T14:16:58.000Z</published>
    <updated>2020-08-12T02:02:42.292Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>我们在Android的开发工作中都在不停地跟View打交道，Android中的任何一个布局、控件其实都是直接或间接继承自View的，如TextView、Button、ImageView、ListView等。这些控件虽然是Android系统本身就提供好的，我们只需要拿过来使用就可以了，但多知道一些总是没有坏处的，接下来就将介绍View是如何被绘制到屏幕上的。</p><p>任何一个视图都不可能凭空突然出现在屏幕上，它们都是要经过非常科学的绘制流程后才能显示出来的。每一个视图的绘制过程都必须经历三个最主要的阶段，即onMeasure()、onLayout()和onDraw()，这也是我们最主要的介绍部分，但在开始之前我们应当先了解一下Android的窗口结构。</p><h2 id="2-Android的窗口结构"><a href="#2-Android的窗口结构" class="headerlink" title="2. Android的窗口结构"></a>2. Android的窗口结构</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>先来看一张图：</p><p><img src="/images/android窗口结构.png" alt="android窗口结构" style="zoom:50%;"></p><h4 id="Activity"><a href="#Activity" class="headerlink" title="Activity"></a>Activity</h4><ul><li>Activity并不负责视图控制（例如添加或者删除view），它只是控制生命周期和处理事件。</li><li>每一个Activity都包含一个根Window对象，Window才是真正代表一个窗口，Window对象通常由PhoneWindow实现</li><li>Activity更像一个控制器，统筹视图的添加与显示，以及通过其他回调方法，来与Window、以及View进行交互。</li></ul><h4 id="Window-PhoneWindow"><a href="#Window-PhoneWindow" class="headerlink" title="Window(PhoneWindow)"></a>Window(PhoneWindow)</h4><p>Window的唯一实现类为PhoneWindow，而DecorView为PhoneWindow的内部类，PhoneWindow持有该内部类对象mDecor，所以真正持有和控制视图的是PhoneWindow</p><h4 id="DecorView"><a href="#DecorView" class="headerlink" title="DecorView"></a>DecorView</h4><ul><li>DecorView是FrameLayout的子类</li><li>是当前activity中所有view的祖先，我们在activity中调用setVisible(boolean visiable)时，实际上就是设置DecorView的可见性</li><li>DecorView是FrameLayout的子类，它可以被认为是Android视图树的根节点视图。DecorView作为顶级View，一般情况下它内部包含一个竖直方向的LinearLayout，在这个LinearLayout里面有上下三个部分，上面是个ViewStub,延迟加载的视图（应该是设置ActionBar,根据Theme设置），中间的是标题栏(根据Theme设置，有的布局没有)，下面的是内容栏。</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">LinearLayout</span> <span class="attr">xmlns:android</span>=<span class="string">"http://schemas.android.com/apk/res/android"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">android:orientation</span>=<span class="string">"vertical"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">android:fitsSystemWindows</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Popout bar for action modes --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ViewStub</span> <span class="attr">android:id</span>=<span class="string">"@+id/action_mode_bar_stub"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:inflatedId</span>=<span class="string">"@+id/action_mode_bar"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:layout</span>=<span class="string">"@layout/action_mode_bar"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:layout_height</span>=<span class="string">"wrap_content"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:theme</span>=<span class="string">"?attr/actionBarTheme"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">FrameLayout</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_height</span>=<span class="string">"?android:attr/windowTitleSize"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">style</span>=<span class="string">"?android:attr/windowTitleBackgroundStyle"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">TextView</span> <span class="attr">android:id</span>=<span class="string">"@android:id/title"</span> </span></span><br><span class="line"><span class="tag">            <span class="attr">style</span>=<span class="string">"?android:attr/windowTitleStyle"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:background</span>=<span class="string">"@null"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:fadingEdge</span>=<span class="string">"horizontal"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:gravity</span>=<span class="string">"center_vertical"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:layout_height</span>=<span class="string">"match_parent"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">FrameLayout</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">FrameLayout</span> <span class="attr">android:id</span>=<span class="string">"@android:id/content"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_height</span>=<span class="string">"0dip"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_weight</span>=<span class="string">"1"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:foregroundGravity</span>=<span class="string">"fill_horizontal|top"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:foreground</span>=<span class="string">"?android:attr/windowContentOverlay"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">LinearLayout</span>&gt;</span></span><br></pre></td></tr></table></figure><p>我们在Activity中通过setContentView所设置的布局文件其实就是被加到内容栏之中的，成为其唯一子View，就是上面的id为content的FrameLayout中，在代码中可以通过content来得到对应加载的布局：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ViewGroup content = (ViewGroup)findViewById(android.R.id.content);</span><br><span class="line">ViewGroup rootView = (ViewGroup)content.getChildAt(<span class="number">0</span>);</span><br></pre></td></tr></table></figure><ul><li><p>还有一些其他功能：</p><ul><li><p>作为PhoneWindow与ViewRoot之间的桥梁，ViewRoot通过DecorView设置窗口属性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">View view = getWindow().getDecorView();</span><br></pre></td></tr></table></figure></li><li><p>分发ViewRoot分发来的key、touch、trackball等外部事件；</p></li></ul></li></ul><h4 id="ViewRootImpl"><a href="#ViewRootImpl" class="headerlink" title="ViewRootImpl"></a>ViewRootImpl</h4><p>ViewRootImpl可能听起来比较陌生，但他十分重要。所有View的绘制以及事件分发等交互都是通过它来执行或传递的。</p><p>但一定要注意，它不是View的子类或父类。对于结构而言，在大部分正常情况下，一颗ViewTree的根节点往往是DecorView，而DecorView的根则是PhoneWindow，跟ViewRoot(ViewRootImpl)真没什么关系。</p><blockquote><p>感兴趣的话，可以看一段代码（位于WIndowManagerGolobal.java中）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addView</span><span class="params">(View view, ViewGroup.LayoutParams params,</span></span></span><br><span class="line"><span class="function"><span class="params">&gt;         Display display, Window parentWindow)</span> </span>&#123;</span><br><span class="line">&gt; </span><br><span class="line">&gt; ......</span><br><span class="line">&gt;     </span><br><span class="line">&gt;     ViewRootImpl root;</span><br><span class="line">&gt;     View panelParentView = <span class="keyword">null</span>;</span><br><span class="line">&gt; </span><br><span class="line">&gt;     <span class="keyword">synchronized</span> (mLock) &#123;</span><br><span class="line">&gt;         <span class="comment">// Start watching for system property changes.</span></span><br><span class="line">&gt;         </span><br><span class="line">&gt;         ......</span><br><span class="line">&gt;                     </span><br><span class="line">&gt;        root = <span class="keyword">new</span> ViewRootImpl(view.getContext(), display);</span><br><span class="line">&gt;         view.setLayoutParams(wparams);</span><br><span class="line">&gt;       </span><br><span class="line">&gt;         mViews.add(view);</span><br><span class="line">&gt;         mRoots.add(root);</span><br><span class="line">&gt;         mParams.add(wparams);</span><br><span class="line">&gt;     &#125;</span><br><span class="line">&gt;     <span class="comment">// do this last because it fires off messages to start doing things</span></span><br><span class="line">&gt;     <span class="keyword">try</span> &#123;</span><br><span class="line">&gt;         root.setView(view, wparams, panelParentView);</span><br><span class="line">&gt;     &#125; <span class="keyword">catch</span> (RuntimeException e) &#123;</span><br><span class="line">&gt;         <span class="comment">// BadTokenException or InvalidDisplayException, clean up.</span></span><br><span class="line">&gt;         <span class="keyword">synchronized</span> (mLock) &#123;</span><br><span class="line">&gt;             <span class="keyword">final</span> <span class="keyword">int</span> index = findViewLocked(view, <span class="keyword">false</span>);</span><br><span class="line">&gt;             <span class="keyword">if</span> (index &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">&gt;                 removeViewLocked(index, <span class="keyword">true</span>);</span><br><span class="line">&gt;             &#125;</span><br><span class="line">&gt;         &#125;</span><br><span class="line">&gt;         <span class="keyword">throw</span> e;</span><br><span class="line">&gt;     &#125;</span><br><span class="line">&gt; &#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>&gt;</p><blockquote><p>可以发现，ViewRootImpl是在Framework层的WindowManagerGlobal中初始化的，其中包含了三个ArrayList（在旧版本中实现是数组），其中mViews代表DecorView，mRoots代表ViewRoot。</p><p>从这里可以看出，对于应用层来说，ViewRootImpl实际上和DecorView显然没有像ViewTree里父子节点那种包含关系。而后面的root.setView(view, wparams, panelParentView)，更是证明了</p></blockquote><p>实际上，ViewRoot的真正的作用其实是作为一个DecorView的“管理者”，它本身并不是一个视图节点，或许被叫作ViewTreeManager才更为合适，本质上是一个管理类。ViewRootImpl还要负责处理应用层与底层WindowManagerService交互事件</p><h2 id="3-从setContentView讲起"><a href="#3-从setContentView讲起" class="headerlink" title="3. 从setContentView讲起"></a>3. 从setContentView讲起</h2><p>接下我们就从一个常见的方法中去认知之前提到这些类之间的关系，那就是activity里面的setContentView，是我们平常把布局内容显示到界面上的一个方法：activity.setContentView()</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setContentView</span><span class="params">(@LayoutRes <span class="keyword">int</span> layoutResID)</span> </span>&#123;</span><br><span class="line">       getWindow().setContentView(layoutResID);</span><br><span class="line">       initWindowDecorActionBar();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>里面方法调用了getWindow().setContentView，而这个getWindow方法获取的就是Activity上的Window(phoneWindow)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Retrieve the current &#123;<span class="doctag">@link</span> android.view.Window&#125; for the activity.</span></span><br><span class="line"><span class="comment"> * This can be used to directly access parts of the Window API that</span></span><br><span class="line"><span class="comment"> * are not available through Activity/Screen.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> Window The current window, or null if the activity is not</span></span><br><span class="line"><span class="comment"> *         visual.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Window <span class="title">getWindow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> mWindow;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注释中说的很明确，可以看到如果当前mWindow为null的话，则表示当前Activity不在窗口上。之前的mWindow.setContentView，实际上调用到的是它的实现类方法phoneWindow.setContentView：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setContentView</span><span class="params">(<span class="keyword">int</span> layoutResID)</span> </span>&#123;</span><br><span class="line">       <span class="comment">// Note: FEATURE_CONTENT_TRANSITIONS may be set in the process of installing the window</span></span><br><span class="line">       <span class="comment">// decor, when theme attributes and the like are crystalized. Do not check the feature</span></span><br><span class="line">       <span class="comment">// before this happens.</span></span><br><span class="line">       <span class="keyword">if</span> (mContentParent == <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="comment">//创建DecorView，并添加到mContentParent上</span></span><br><span class="line">           installDecor();</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!hasFeature(FEATURE_CONTENT_TRANSITIONS)) &#123;</span><br><span class="line">           mContentParent.removeAllViews();</span><br><span class="line">       &#125;</span><br><span class="line"><span class="comment">// 转场动画</span></span><br><span class="line">       <span class="keyword">if</span> (hasFeature(FEATURE_CONTENT_TRANSITIONS)) &#123;</span><br><span class="line">           <span class="keyword">final</span> Scene newScene = Scene.getSceneForLayout(mContentParent, layoutResID,</span><br><span class="line">                   getContext());</span><br><span class="line">           transitionTo(newScene);</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">//将要加载的资源添加到mContentParent上</span></span><br><span class="line">           mLayoutInflater.inflate(layoutResID, mContentParent);</span><br><span class="line">       &#125;</span><br><span class="line">       mContentParent.requestApplyInsets();</span><br><span class="line">       <span class="keyword">final</span> Callback cb = getCallback();</span><br><span class="line">       <span class="keyword">if</span> (cb != <span class="keyword">null</span> &amp;&amp; !isDestroyed()) &#123;</span><br><span class="line">           <span class="comment">//回调通知表示完成界面加载</span></span><br><span class="line">           cb.onContentChanged();</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>如果当前内容还未放置到窗口，则此时mContentParent==null，也就是第一次调用的时候会调用installDecor方法。FEATURE_CONTENT_TRANSITIONS，则是标记当前内容加载有没有使用过渡（转场）动画。如果内容已经加载过，并且不需要动画，则会调用removeAllViews。</p><p>添加完Content后如有设置了FEATURE_CONTENT_TRANSITIONS则添加Scene来过度启动。否则mLayoutInflater.inflate(layoutResID, mContentParent)；将我们的资源文件通过LayoutInflater对象转换为View树，并且添加至mContentParent视图中。</p><p>既然第一次启动会调用到installDecor，从字面上看可以知道该方法用来添加DecorView:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">installDecor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mDecor == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//调用该方法创建new一个DecorView</span></span><br><span class="line">            mDecor = generateDecor();</span><br><span class="line">            mDecor.setDescendantFocusability(ViewGroup.FOCUS_AFTER_DESCENDANTS);</span><br><span class="line">            mDecor.setIsRootNamespace(<span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">if</span> (!mInvalidatePanelMenuPosted &amp;&amp; mInvalidatePanelMenuFeatures != <span class="number">0</span>) &#123;</span><br><span class="line">                mDecor.postOnAnimation(mInvalidatePanelMenuRunnable);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//一开始DecorView未加载到mContentParent，所以此时mContentParent=null</span></span><br><span class="line">        <span class="keyword">if</span> (mContentParent == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//该方法将mDecorView添加到Window上绑定布局</span></span><br><span class="line">            mContentParent = generateLayout(mDecor);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Set up decor part of UI to ignore fitsSystemWindows if appropriate.</span></span><br><span class="line">            mDecor.makeOptionalFitsSystemWindows();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> DecorContentParent decorContentParent = (DecorContentParent) mDecor.findViewById(</span><br><span class="line">                    R.id.decor_content_parent);</span><br><span class="line">                </span><br><span class="line">                ...<span class="comment">//添加其他资源</span></span><br><span class="line">                ...<span class="comment">//设置转场动画</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>所以过程大致是，先通过generateDecor创建DecorView：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> DecorView <span class="title">generateDecor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> DecorView(getContext(), -<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>创建完后再通过调用generateLayout将setContentView的内容赋值到mContentParent，这个方法有点长:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> ViewGroup <span class="title">generateLayout</span><span class="params">(DecorView decor)</span> </span>&#123;</span><br><span class="line">       <span class="comment">// Apply data from current theme.</span></span><br><span class="line">       <span class="comment">//根据当前设置的主题来加载默认布局</span></span><br><span class="line">       TypedArray a = getWindowStyle();</span><br><span class="line">       <span class="comment">//如果你在theme中设置了window_windowNoTitle，则这里会调用到，其他方法同理，</span></span><br><span class="line">       <span class="comment">//这里是根据你在theme中的设置去设置的</span></span><br><span class="line">       <span class="keyword">if</span> (a.getBoolean(R.styleable.Window_windowNoTitle, <span class="keyword">false</span>)) &#123;</span><br><span class="line">           requestFeature(FEATURE_NO_TITLE);</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (a.getBoolean(R.styleable.Window_windowActionBar, <span class="keyword">false</span>)) &#123;</span><br><span class="line">           <span class="comment">// Don't allow an action bar if there is no title.</span></span><br><span class="line">           requestFeature(FEATURE_ACTION_BAR);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//是否有设置全屏</span></span><br><span class="line">       <span class="keyword">if</span> (a.getBoolean(R.styleable.Window_windowFullscreen, <span class="keyword">false</span>)) &#123;</span><br><span class="line">           setFlags(FLAG_FULLSCREEN, FLAG_FULLSCREEN &amp; (~getForcedWindowFlags()));</span><br><span class="line">       &#125;</span><br><span class="line">       </span><br><span class="line">       ...<span class="comment">//省略其他加载资源</span></span><br><span class="line">       </span><br><span class="line">       <span class="comment">// 添加布局到DecorView，前面说到，DecorView是继承与FrameLayout，它本身也是一个ViewGroup，而我们前面创建它的时候，只是调用了new DecorView，此时里面并无什么东西。而下面的步骤则是根据用户设置的Feature来创建相应的默认布局主题。举个例子，如果我在setContentView之前调用了requestWindowFeature(Window.FEATURE_NO_TITLE)，这里则会通过getLocalFeatures来获取你设置的feature，进而选择加载对应的布局，此时则是加载没有标题栏的主题，对应的就是R.layout.screen_simple</span></span><br><span class="line"></span><br><span class="line">       <span class="keyword">int</span> layoutResource;</span><br><span class="line">       <span class="keyword">int</span> features = getLocalFeatures();</span><br><span class="line">       <span class="comment">// System.out.println("Features: 0x" + Integer.toHexString(features));</span></span><br><span class="line">       <span class="keyword">if</span> ((features &amp; (<span class="number">1</span> &lt;&lt; FEATURE_SWIPE_TO_DISMISS)) != <span class="number">0</span>) &#123;</span><br><span class="line">           layoutResource = R.layout.screen_swipe_dismiss;</span><br><span class="line">       &#125; ... <span class="comment">//省略其他判断方法</span></span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">// Embedded, so no decoration is needed.</span></span><br><span class="line">           layoutResource = R.layout.screen_simple;</span><br><span class="line">           <span class="comment">// System.out.println("Simple!");</span></span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       mDecor.startChanging();</span><br><span class="line">       <span class="comment">//选择对应布局创建添加到DecorView中</span></span><br><span class="line">       View in = mLayoutInflater.inflate(layoutResource, <span class="keyword">null</span>);</span><br><span class="line">       decor.addView(in, <span class="keyword">new</span> ViewGroup.LayoutParams(MATCH_PARENT, MATCH_PARENT));</span><br><span class="line">       mContentRoot = (ViewGroup) in;</span><br><span class="line"><span class="comment">// 设置contentParent</span></span><br><span class="line">       ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT);</span><br><span class="line">       ...</span><br><span class="line">       <span class="keyword">return</span> contentParent;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>总结起来就是，首先generateLayout会根据当前用户设置的主题去设置对应的Feature，接着根据对应的Feature来选择加载对应的布局文件，接下来通过getLocalFeatures来获取你设置的feature，进而选择加载对应的布局，这也就是为什么我们要在setContentView之前调用requesetFeature的原因。</p><p>正如我们之前给出的那个例子：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">LinearLayout</span> <span class="attr">xmlns:android</span>=<span class="string">"http://schemas.android.com/apk/res/android"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">android:orientation</span>=<span class="string">"vertical"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">android:fitsSystemWindows</span>=<span class="string">"true"</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Popout bar for action modes --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ViewStub</span> <span class="attr">android:id</span>=<span class="string">"@+id/action_mode_bar_stub"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:inflatedId</span>=<span class="string">"@+id/action_mode_bar"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:layout</span>=<span class="string">"@layout/action_mode_bar"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:layout_height</span>=<span class="string">"wrap_content"</span></span></span><br><span class="line"><span class="tag">              <span class="attr">android:theme</span>=<span class="string">"?attr/actionBarTheme"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">FrameLayout</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_height</span>=<span class="string">"?android:attr/windowTitleSize"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">style</span>=<span class="string">"?android:attr/windowTitleBackgroundStyle"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">TextView</span> <span class="attr">android:id</span>=<span class="string">"@android:id/title"</span> </span></span><br><span class="line"><span class="tag">            <span class="attr">style</span>=<span class="string">"?android:attr/windowTitleStyle"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:background</span>=<span class="string">"@null"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:fadingEdge</span>=<span class="string">"horizontal"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:gravity</span>=<span class="string">"center_vertical"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:layout_height</span>=<span class="string">"match_parent"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">FrameLayout</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">FrameLayout</span> <span class="attr">android:id</span>=<span class="string">"@android:id/content"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_width</span>=<span class="string">"match_parent"</span> </span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_height</span>=<span class="string">"0dip"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:layout_weight</span>=<span class="string">"1"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:foregroundGravity</span>=<span class="string">"fill_horizontal|top"</span></span></span><br><span class="line"><span class="tag">        <span class="attr">android:foreground</span>=<span class="string">"?android:attr/windowContentOverlay"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">LinearLayout</span>&gt;</span></span><br></pre></td></tr></table></figure><p>“DecorView只有一个子元素为LinearLayout，代表整个Window界面，包含通知栏、标题栏、内容显示栏三块区域。”要注意FrameLayout里面的id，@android:id/content ，我们setContentView的内容就是添加到这个FrameLayout中。</p><p>generateLayout的返回是contentParent，而它的获取则是ViewGroup contentParent = (ViewGroup)findViewById(ID_ANDROID_CONTENT);</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> ID_ANDROID_CONTENT = com.android.internal.R.id.content;</span><br></pre></td></tr></table></figure><p>正好对应id为content的FrameLayout，之后我们setContentView则是添加在mContentParent上面了。</p><p>我们再回到前面的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setContentView</span><span class="params">(<span class="keyword">int</span> layoutResID)</span> </span>&#123;</span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> (hasFeature(FEATURE_CONTENT_TRANSITIONS)) &#123;</span><br><span class="line">           <span class="keyword">final</span> Scene newScene = Scene.getSceneForLayout(mContentParent, layoutResID,</span><br><span class="line">                   getContext());</span><br><span class="line">           transitionTo(newScene);</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">//将要加载的资源添加到mContentParent上</span></span><br><span class="line">           mLayoutInflater.inflate(layoutResID, mContentParent);</span><br><span class="line">       &#125;</span><br><span class="line">       mContentParent.requestApplyInsets();</span><br><span class="line">       <span class="keyword">final</span> Callback cb = getCallback();</span><br><span class="line">       <span class="keyword">if</span> (cb != <span class="keyword">null</span> &amp;&amp; !isDestroyed()) &#123;</span><br><span class="line">           <span class="comment">//回调通知表示完成界面改变</span></span><br><span class="line">           cb.onContentChanged();</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>此时已经创建完DecorView并且获取到mContentParent，接着就是将你setContentView的内容添加到mContentParent中，也就是:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mLayoutInflater.inflate(layoutResID, mContentParent);</span><br><span class="line"><span class="comment">// 或者</span></span><br><span class="line">mContentParent.addView(view, params);</span><br><span class="line"><span class="comment">// 他们本质上是一样的</span></span><br></pre></td></tr></table></figure><p>最后调用Callback来通知界面发生改变。Callback是Window里面的一个接口，里面声明了当界面更改触摸时调用的各种方法。</p><p>这里的话，我们看下onContentChanged，虽然在PhoneWindow里面并没有看到onContentChanged的实现类，但我们知道Activity本身又是加载在Window上的，所以来看下Activity：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Activity</span> <span class="keyword">extends</span> <span class="title">ContextThemeWrapper</span></span></span><br><span class="line"><span class="class">        <span class="keyword">implements</span> <span class="title">LayoutInflater</span>.<span class="title">Factory2</span>,</span></span><br><span class="line"><span class="class">        <span class="title">Window</span>.<span class="title">Callback</span>, <span class="title">KeyEvent</span>.<span class="title">Callback</span>,</span></span><br><span class="line"><span class="class">        <span class="title">OnCreateContextMenuListener</span>, <span class="title">ComponentCallbacks2</span>,</span></span><br><span class="line"><span class="class">        <span class="title">Window</span>.<span class="title">OnWindowDismissedCallback</span> </span></span><br><span class="line"><span class="class">        </span>&#123;</span><br><span class="line">          ... </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>可以看到Activity里面实现了Window.Callback接口，并且</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onContentChanged</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>onContentChanged方法为空，所以我们可以通过重写该方法来监听布局内容的改变</p><p>总结起来就是，<strong>在调用setContentView()方法后，DecorView被初始化，用户视图也被挂载到DecorView上</strong></p><h2 id="4-DecorView的显示和ViewRootImpl"><a href="#4-DecorView的显示和ViewRootImpl" class="headerlink" title="4. DecorView的显示和ViewRootImpl"></a>4. DecorView的显示和ViewRootImpl</h2><p>经过上一部分的步骤，DecorView就已经被建立起来了。但大家应该都知道，界面虽然经过了setContentView()的设置，但要等到onResume()之后才对用户可见。</p><p>Activity的生命周期大家都已经学过，所以不做过多的介绍了。</p><p><img src="/images/Activity的生命周期.png" alt="Activity的生命周期" style="zoom:45%;"></p><p>（关于Activity启动和Window的绑定我放在了补充里，有兴趣的筒子们可以自行去查看，不然感觉实在太多了…）</p><p>在我们想要开启一个Activity的时候，ActivityThread的handleLaunchActivity()会在Handler中被调用，那我们就来看一看这个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleLaunchActivity</span><span class="params">(ActivityClientRecord r, Intent customIntent)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//就是在这里调用了Activity.attach()，接着调用了Activity.onCreate()和Activity.onStart()生命周期，但是由于只是初始化了mDecor，添加了布局文件，还没有把mDecor添加到负责UI显示的PhoneWindow中，所以这时候对用户来说，是不可见的</span></span><br><span class="line">    Activity a = performLaunchActivity(r, customIntent);</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (a != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">//这里面执行了Activity.onResume()</span></span><br><span class="line">    handleResumeActivity(r.token, <span class="keyword">false</span>, r.isForward,</span><br><span class="line">                    !r.activity.mFinished &amp;&amp; !r.startsNotResumed);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!r.activity.mFinished &amp;&amp; r.startsNotResumed) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">                    r.activity.mCalled = <span class="keyword">false</span>;</span><br><span class="line">                    <span class="comment">//执行Activity.onPause()</span></span><br><span class="line">                    mInstrumentation.callActivityOnPause(r.activity);</span><br><span class="line">                    &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们重点来看一下handleResumeActivity()做了什么：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">handleResumeActivity</span><span class="params">(IBinder token,</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">boolean</span> clearHide, <span class="keyword">boolean</span> isForward, <span class="keyword">boolean</span> reallyResume)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//此时Activity.onResume()已经被调用，但界面还是不可见的</span></span><br><span class="line">            ActivityClientRecord r = performResumeActivity(token, clearHide);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (r != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">final</span> Activity a = r.activity;</span><br><span class="line">                  <span class="keyword">if</span> (r.window == <span class="keyword">null</span> &amp;&amp; !a.mFinished &amp;&amp; willBeVisible) &#123;</span><br><span class="line">                r.window = r.activity.getWindow();</span><br><span class="line">                View decor = r.window.getDecorView();</span><br><span class="line">                <span class="comment">//decor对用户不可见</span></span><br><span class="line">                decor.setVisibility(View.INVISIBLE);</span><br><span class="line">                ViewManager wm = a.getWindowManager();</span><br><span class="line">                WindowManager.LayoutParams l = r.window.getAttributes();</span><br><span class="line">                a.mDecor = decor;</span><br><span class="line"><span class="comment">//WindowManager.LayoutParams的type为TYPE_BASE_APPLICATION</span></span><br><span class="line">                l.type = WindowManager.LayoutParams.TYPE_BASE_APPLICATION;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (a.mVisibleFromClient) &#123;</span><br><span class="line">                    a.mWindowAdded = <span class="keyword">true</span>;</span><br><span class="line">                    <span class="comment">//decor被添加进WindowManager了，但是这个时候还是不可见的</span></span><br><span class="line">                    wm.addView(decor, l);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (!r.activity.mFinished &amp;&amp; willBeVisible</span><br><span class="line">                    &amp;&amp; r.activity.mDecor != <span class="keyword">null</span> &amp;&amp; !r.hideForNow) &#123;</span><br><span class="line">                     <span class="comment">//在这里，划重点！</span></span><br><span class="line">                     <span class="keyword">if</span> (r.activity.mVisibleFromClient) &#123;</span><br><span class="line">                            r.activity.makeVisible();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><p>也就是说，其实在onResume()执行之后，界面还是不可见的，当我们执行了Activity.makeVisible()方法之后，界面才对我们是可见的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">makeVisible</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">if</span> (!mWindowAdded) &#123;</span><br><span class="line">            ViewManager wm = getWindowManager();</span><br><span class="line">     <span class="comment">// 将DecorView添加到WindowManager，此处十分重要</span></span><br><span class="line">            wm.addView(mDecor, getWindow().getAttributes());</span><br><span class="line">            mWindowAdded = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        mDecor.setVisibility(View.VISIBLE);<span class="comment">//DecorView可见</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>到此DecorView便可见，显示在屏幕中。但是在这其中,wm.addView(mDecor, getWindow().getAttributes())起到了重要的作用，因为其内部创建了一个ViewRootImpl对象，负责绘制显示各个子View。</p><p>下面我们具体来看addView()方法，因为WindowManager是个接口，具体是交给WindowManagerImpl来实现的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">WindowManagerImpl</span> <span class="keyword">implements</span> <span class="title">WindowManager</span> </span>&#123;    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> WindowManagerGlobal mGlobal = WindowManagerGlobal.getInstance();</span><br><span class="line">    ...</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addView</span><span class="params">(View view, ViewGroup.LayoutParams params)</span> </span>&#123;</span><br><span class="line">        mGlobal.addView(view, params, mDisplay, mParentWindow);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现，这里还是交给WindowManagerGlobal的addView()方法去实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addView</span><span class="params">(View view, ViewGroup.LayoutParams params,</span></span></span><br><span class="line"><span class="function"><span class="params">            Display display, Window parentWindow)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">              <span class="keyword">final</span> WindowManager.LayoutParams wparams = (WindowManager.LayoutParams)params;</span><br><span class="line">             ......</span><br><span class="line">                 <span class="keyword">synchronized</span> (mLock) &#123;</span><br><span class="line"></span><br><span class="line">                 ViewRootImpl root;</span><br><span class="line">                  <span class="comment">//实例化一个ViewRootImpl对象</span></span><br><span class="line">                 root = <span class="keyword">new</span> ViewRootImpl(view.getContext(), display);</span><br><span class="line">                 view.setLayoutParams(wparams);</span><br><span class="line"></span><br><span class="line">                mViews.add(view);</span><br><span class="line">                mRoots.add(root);</span><br><span class="line">                mParams.add(wparams);</span><br><span class="line">            &#125;</span><br><span class="line">             ......</span><br><span class="line"></span><br><span class="line">             <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">//将DecorView交给ViewRootImpl </span></span><br><span class="line">                root.setView(view, wparams, panelParentView);</span><br><span class="line">            &#125;<span class="keyword">catch</span> (RuntimeException e) &#123;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>记不记得我们之前说过，WindowManagerGlobal中包含了三个ArrayList，其中mViews代表DecorView，mRoots代表ViewRoot。正是这个root.setView(view, wparams, panelParentView)方法，经过一系列调用，最终调用了performTraversals()方法。</p><p>我们来看ViewRootImpl类中的addView方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setView</span><span class="params">(View view, WindowManager.LayoutParams attrs, View panelParentView)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (mView == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">//将顶层视图DecorView赋值给全局的mView</span></span><br><span class="line">                mView = view;</span><br><span class="line">            .............</span><br><span class="line">            <span class="comment">//标记已添加DecorView</span></span><br><span class="line">             mAdded = <span class="keyword">true</span>;</span><br><span class="line">            .............</span><br><span class="line">            <span class="comment">//请求布局</span></span><br><span class="line">            requestLayout();</span><br><span class="line">            .............     </span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>继续跟踪requestLayout()方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requestLayout</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!mHandlingLayoutInLayoutRequest) &#123;</span><br><span class="line">            checkThread();</span><br><span class="line">            mLayoutRequested = <span class="keyword">true</span>;</span><br><span class="line">            scheduleTraversals(); <span class="comment">// 再看这个</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">.......</span><br><span class="line">  </span><br><span class="line"><span class="keyword">final</span> TraversalRunnable mTraversalRunnable = <span class="keyword">new</span> TraversalRunnable(); <span class="comment">// 跟踪</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">scheduleTraversals</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!mTraversalScheduled) &#123;</span><br><span class="line">            mTraversalScheduled = <span class="keyword">true</span>;</span><br><span class="line">            mTraversalBarrier = mHandler.getLooper().postSyncBarrier();</span><br><span class="line">            mChoreographer.postCallback(</span><br><span class="line">               <span class="comment">// 这里传入将要执行遍历绘制的 runnable</span></span><br><span class="line">                    Choreographer.CALLBACK_TRAVERSAL, mTraversalRunnable, <span class="keyword">null</span>); </span><br><span class="line">            <span class="keyword">if</span> (!mUnbufferedInputDispatch) &#123;</span><br><span class="line">                scheduleConsumeBatchedInput();</span><br><span class="line">            &#125;</span><br><span class="line">            notifyRendererOfFramePending();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TraversalRunnable</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            doTraversal();  <span class="comment">// 继续跟踪</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">final</span> TraversalRunnable mTraversalRunnable = <span class="keyword">new</span> TraversalRunnable();</span><br><span class="line"></span><br><span class="line">...............</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">void</span> <span class="title">doTraversal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mTraversalScheduled) &#123;</span><br><span class="line">            mTraversalScheduled = <span class="keyword">false</span>;</span><br><span class="line">            mHandler.getLooper().removeSyncBarrier(mTraversalBarrier);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                performTraversals();   <span class="comment">// 终于找到你，还好我没放弃！！</span></span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                Trace.traceEnd(Trace.TRACE_TAG_VIEW);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">............</span><br></pre></td></tr></table></figure><p>经历千辛万苦，我们终于接近了View树的绘制流程。这个绘制流程就是从ViewRootImpl类的performTraversals()方法开始的，这个方法主要是根据之前设置的状态，判断是否重新计算视图大小(measure)、是否重新放置视图的位置(layout)、以及是否重绘 (draw)：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">performTraversals</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   ...</span><br><span class="line">   <span class="comment">//最外层的根视图的widthMeasureSpec和heightMeasureSpec由来</span></span><br><span class="line">   <span class="comment">//lp.width和lp.height在创建ViewGroup实例时等于MATCH_PARENT</span></span><br><span class="line">   <span class="keyword">int</span> childWidthMeasureSpec = getRootMeasureSpec(mWidth, lp.width);</span><br><span class="line">   <span class="keyword">int</span> childHeightMeasureSpec = getRootMeasureSpec(mHeight, lp.height);</span><br><span class="line">     </span><br><span class="line">   <span class="comment">// 执行测量操作</span></span><br><span class="line">   performMeasure(childWidthMeasureSpec, childHeightMeasureSpec);</span><br><span class="line">   ...</span><br><span class="line">   <span class="comment">//执行布局操作</span></span><br><span class="line">   performLayout(lp, desiredWindowWidth, desiredWindowHeight);</span><br><span class="line">   ...</span><br><span class="line">    <span class="comment">//执行绘制操作</span></span><br><span class="line">    performDraw();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>performTraversals()方法有700多行，实在是太长了，这里就先举一下最重要的三个。他会经过一系列复杂的调用，最终绘制出View，大体如下：</p><p><img src="/images/performTraversals介绍.png" alt="performTraversals介绍" style="zoom:60%;"></p><p>那么接下来，我们就来分三个阶段介绍</p><h2 id="5-第一阶段：Measure"><a href="#5-第一阶段：Measure" class="headerlink" title="5. 第一阶段：Measure"></a>5. 第一阶段：Measure</h2><h3 id="主体"><a href="#主体" class="headerlink" title="主体"></a>主体</h3><p>话不多说，我们先来看performMeasure方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">performMeasure</span><span class="params">(<span class="keyword">int</span> childWidthMeasureSpec, <span class="keyword">int</span> childHeightMeasureSpec)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (mView == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    Trace.traceBegin(Trace.TRACE_TAG_VIEW, <span class="string">"measure"</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 追踪这里</span></span><br><span class="line">        mView.measure(childWidthMeasureSpec, childHeightMeasureSpec);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        Trace.traceEnd(Trace.TRACE_TAG_VIEW);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之前我们介绍过，在handleResumeActivity中，已经将Window.mDecor(也就是DecorView）传入了进来。</p><p>所以，这里的mView就是该ViewRootImpl指依赖的Activity中的DecorView，也已经介绍过DecorView是整个View树的最顶层，可以认为是View树的根，因此可以通过调用mView来绘制一个Acitivity组件的UI。</p><p>可以发现，在performMeasure方法中我们传入了两个参数childWidthMeasureSpec和childHeightMeasureSpec：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> childWidthMeasureSpec = getRootMeasureSpec(mWidth, lp.width);</span><br><span class="line"><span class="keyword">int</span> childHeightMeasureSpec = getRootMeasureSpec(mHeight, lp.height);</span><br></pre></td></tr></table></figure><p>这里调用了getRootMeasureSpec()方法去获取widthMeasureSpec和heightMeasureSpec的值，注意方法中传入的参数，其中lp.width和lp.height在创建ViewGroup实例的时候就被赋值了，它们都等于MATCH_PARENT。然后看下getRootMeasureSpec()方法中的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">getRootMeasureSpec</span><span class="params">(<span class="keyword">int</span> windowSize, <span class="keyword">int</span> rootDimension)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> measureSpec;</span><br><span class="line">    <span class="keyword">switch</span> (rootDimension) &#123;</span><br><span class="line">    <span class="keyword">case</span> ViewGroup.LayoutParams.MATCH_PARENT:</span><br><span class="line">        measureSpec = MeasureSpec.makeMeasureSpec(windowSize, MeasureSpec.EXACTLY);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> ViewGroup.LayoutParams.WRAP_CONTENT:</span><br><span class="line">        measureSpec = MeasureSpec.makeMeasureSpec(windowSize, MeasureSpec.AT_MOST);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        measureSpec = MeasureSpec.makeMeasureSpec(rootDimension, MeasureSpec.EXACTLY);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> measureSpec;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，这里使用了MeasureSpec.makeMeasureSpec()方法来组装一个MeasureSpec，当rootDimension参数等于MATCH_PARENT的时候，MeasureSpec的specMode就等于EXACTLY，当rootDimension等于WRAP_CONTENT的时候，MeasureSpec的specMode就等于AT_MOST。并且MATCH_PARENT和WRAP_CONTENT时的specSize都是等于windowSize的，这也是为什么根视图总是会充满全屏的。</p><ul><li>UNSPECIFIED：父容器不对子View有限制，子View要多大给多大，这种一般我们不会接触到</li><li>EXACTLY: 表示精确模式，View的大小已经确认，为SpecSize所指定的值。</li><li>AT_MOST:表示子View的大小不确认，指定了该子View最大可以为多少。子View可以在该范围内设定自己的大小。</li></ul><p>介绍完参数，我们接下来来看view.measure()方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">measure</span><span class="params">(<span class="keyword">int</span> widthMeasureSpec, <span class="keyword">int</span> heightMeasureSpec)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ((mPrivateFlags &amp; FORCE_LAYOUT) == FORCE_LAYOUT ||</span><br><span class="line">            widthMeasureSpec != mOldWidthMeasureSpec ||</span><br><span class="line">            heightMeasureSpec != mOldHeightMeasureSpec) &#123;</span><br><span class="line">        mPrivateFlags &amp;= ~MEASURED_DIMENSION_SET;</span><br><span class="line">        <span class="keyword">if</span> (ViewDebug.TRACE_HIERARCHY) &#123;</span><br><span class="line">            ViewDebug.trace(<span class="keyword">this</span>, ViewDebug.HierarchyTraceType.ON_MEASURE);</span><br><span class="line">        &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// 调用onMeasure方法</span></span><br><span class="line">        onMeasure(widthMeasureSpec, heightMeasureSpec);</span><br><span class="line">        </span><br><span class="line">      <span class="keyword">if</span> ((mPrivateFlags &amp; MEASURED_DIMENSION_SET) != MEASURED_DIMENSION_SET) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"onMeasure() did not set the"</span></span><br><span class="line">                    + <span class="string">" measured dimension by calling"</span></span><br><span class="line">                    + <span class="string">" setMeasuredDimension()"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        mPrivateFlags |= LAYOUT_REQUIRED;</span><br><span class="line">    &#125;</span><br><span class="line">    mOldWidthMeasureSpec = widthMeasureSpec;</span><br><span class="line">    mOldHeightMeasureSpec = heightMeasureSpec;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意观察，measure()这个方法是final的，因此我们无法在子类中去重写这个方法，说明Android是不允许我们改变View的measure框架的。然后在第9行调用了onMeasure()方法，这里才是真正去测量并设置View大小的地方，默认会调用getDefaultSize()方法来获取视图的大小：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onMeasure</span><span class="params">(<span class="keyword">int</span> widthMeasureSpec, <span class="keyword">int</span> heightMeasureSpec)</span> </span>&#123;</span><br><span class="line">        setMeasuredDimension(getDefaultSize(getSuggestedMinimumWidth(), widthMeasureSpec),</span><br><span class="line">                getDefaultSize(getSuggestedMinimumHeight(), heightMeasureSpec));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getDefaultSize</span><span class="params">(<span class="keyword">int</span> size, <span class="keyword">int</span> measureSpec)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> result = size;</span><br><span class="line">    <span class="keyword">int</span> specMode = MeasureSpec.getMode(measureSpec);</span><br><span class="line">    <span class="keyword">int</span> specSize = MeasureSpec.getSize(measureSpec);</span><br><span class="line">    <span class="keyword">switch</span> (specMode) &#123;</span><br><span class="line">    <span class="keyword">case</span> MeasureSpec.UNSPECIFIED:</span><br><span class="line">        result = size;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> MeasureSpec.AT_MOST:</span><br><span class="line">    <span class="keyword">case</span> MeasureSpec.EXACTLY:</span><br><span class="line">        result = specSize;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 建议的最小宽度和高度都是由View的Background尺寸与通过设置View的miniXXX属性共同决定的</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">getSuggestedMinimumWidth</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (mBackground == <span class="keyword">null</span>) ? mMinWidth : max(mMinWidth, mBackground.getMinimumWidth());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">getSuggestedMinimumHeight</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (mBackground == <span class="keyword">null</span>) ? mMinHeight : max(mMinHeight, mBackground.getMinimumHeight());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里传入的measureSpec是一直从measure()方法中传递过来的。然后调用MeasureSpec.getMode()方法可以解析出specMode，调用MeasureSpec.getSize()方法可以解析出specSize。接下来进行判断，如果specMode等于AT_MOST或EXACTLY就返回specSize。</p><p>之后会在onMeasure()方法中调用setMeasuredDimension()方法来设定测量出的大小，这样一次measure过程就结束了。</p><p>当然，一个界面的展示可能会涉及到很多次的measure，因为一个布局中一般都会包含多个子视图，每个视图都需要经历一次measure过程。</p><p>ViewGroup中定义了一个measureChildren()方法来去测量子视图的大小，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">measureChildren</span><span class="params">(<span class="keyword">int</span> widthMeasureSpec, <span class="keyword">int</span> heightMeasureSpec)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> size = mChildrenCount;</span><br><span class="line">    <span class="keyword">final</span> View[] children = mChildren;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">        <span class="keyword">final</span> View child = children[i];</span><br><span class="line">        <span class="keyword">if</span> ((child.mViewFlags &amp; VISIBILITY_MASK) != GONE) &#123;</span><br><span class="line">    <span class="comment">// 这里首先会去遍历当前布局下的所有子视图，然后逐个调用measureChild()方法来测量相应子视图的大小</span></span><br><span class="line">            measureChild(child, widthMeasureSpec, heightMeasureSpec);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">measureChild</span><span class="params">(View child, <span class="keyword">int</span> parentWidthMeasureSpec,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> parentHeightMeasureSpec)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 获取布局文件中定义的多种属性</span></span><br><span class="line">    <span class="keyword">final</span> LayoutParams lp = child.getLayoutParams();</span><br><span class="line">  <span class="comment">// 计算子视图MeasureSpec</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec,</span><br><span class="line">            mPaddingLeft + mPaddingRight, lp.width);</span><br><span class="line">  <span class="comment">// 计算子视图MeasureSpec</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec,</span><br><span class="line">            mPaddingTop + mPaddingBottom, lp.height);</span><br><span class="line">    child.measure(childWidthMeasureSpec, childHeightMeasureSpec);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，在measureChild()又调用了getChildMeasureSpec()方法来去计算子视图的MeasureSpec，计算的依据就是布局文件中定义的MATCH_PARENT、WRAP_CONTENT等值</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getChildMeasureSpec</span><span class="params">(<span class="keyword">int</span> spec, <span class="keyword">int</span> padding, <span class="keyword">int</span> childDimension)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//获取当前Parent View的Mode和Size</span></span><br><span class="line">    <span class="keyword">int</span> specMode = MeasureSpec.getMode(spec);</span><br><span class="line">    <span class="keyword">int</span> specSize = MeasureSpec.getSize(spec);</span><br><span class="line">    <span class="comment">//获取Parent size与padding差值（也就是Parent剩余大小），若差值小于0直接返回0</span></span><br><span class="line">    <span class="keyword">int</span> size = Math.max(<span class="number">0</span>, specSize - padding);</span><br><span class="line">    <span class="comment">//定义返回值存储变量</span></span><br><span class="line">    <span class="keyword">int</span> resultSize = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> resultMode = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">//依据当前Parent的Mode进行switch分支逻辑</span></span><br><span class="line">    <span class="keyword">switch</span> (specMode) &#123;</span><br><span class="line">    <span class="comment">//默认Root View的Mode就是EXACTLY</span></span><br><span class="line">    <span class="keyword">case</span> MeasureSpec.EXACTLY:</span><br><span class="line">        <span class="keyword">if</span> (childDimension &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">//如果child的layout_wOrh属性在xml或者java中给予具体大于等于0的数值</span></span><br><span class="line">            <span class="comment">//设置child的size为真实layout_wOrh属性值，mode为EXACTLY</span></span><br><span class="line">            resultSize = childDimension;</span><br><span class="line">            resultMode = MeasureSpec.EXACTLY;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (childDimension == LayoutParams.MATCH_PARENT) &#123;</span><br><span class="line">            <span class="comment">//如果child的layout_wOrh属性在xml或者java中给予MATCH_PARENT</span></span><br><span class="line">            <span class="comment">//设置child的size为size，mode为EXACTLY</span></span><br><span class="line">            resultSize = size;</span><br><span class="line">            resultMode = MeasureSpec.EXACTLY;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (childDimension == LayoutParams.WRAP_CONTENT) &#123;</span><br><span class="line">            <span class="comment">//如果child的layout_wOrh属性在xml或者java中给予WRAP_CONTENT</span></span><br><span class="line">            <span class="comment">//设置child的size为size，mode为AT_MOST</span></span><br><span class="line">            resultSize = size;</span><br><span class="line">            resultMode = MeasureSpec.AT_MOST;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    ......</span><br><span class="line">    <span class="comment">//其他Mode大体分支类似</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将mode与size通过MeasureSpec方法整合为32位整数返回</span></span><br><span class="line">    <span class="keyword">return</span> MeasureSpec.makeMeasureSpec(resultSize, resultMode);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后在最后调用子视图的measure()方法，并把计算出的MeasureSpec传递进去，之后的流程就和前面所介绍的一样了。</p><p>由此可见，视图大小的控制是由父视图、布局文件、以及视图本身共同完成的，父视图会提供给子视图参考的大小，而开发人员可以在XML文件中指定视图的大小，然后视图本身会对最终的大小进行拍板。</p><p>到此为止，我们就把视图绘制流程的第一阶段分析完了。</p><h3 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h3><ul><li>MeasureSpec（View的内部类）测量规格为int型，值由高2位规格模式specMode和低30位具体尺寸specSize组成。其中specMode只有三种值：<ul><li>MeasureSpec.EXACTLY ：确定模式，父View希望子View的大小是确定的，由specSize决定；</li><li>MeasureSpec.AT_MOST ：最多模式，父View希望子View的大小最多是specSize指定的值；</li><li>MeasureSpec.UNSPECIFIED ：未指定模式，父View完全依据子View的设计值来决定；</li></ul></li><li>View的measure方法是final的，不允许重载，View子类只能重载onMeasure来完成自己的测量逻辑。</li><li>最顶层DecorView测量时的MeasureSpec是由ViewRootImpl中getRootMeasureSpec方法确定的（LayoutParams宽高参数均为MATCH_PARENT，specMode是EXACTLY，specSize为物理屏幕大小）。</li><li>ViewGroup类提供了measureChildren，measureChild和measureChildWithMargins方法，简化了父子View的尺寸计算。</li><li>只要是ViewGroup的子类就必须要求LayoutParams继承子MarginLayoutParams，否则无法使用layout_margin参数。</li><li>View的布局大小由父View和子View共同决定。</li><li>使用View的getMeasuredWidth()和getMeasuredHeight()方法来获取View测量的宽高，必须保证这两个方法在onMeasure流程之后被调用才能返回有效值。</li></ul><h3 id="小补充1：重写onMeasure"><a href="#小补充1：重写onMeasure" class="headerlink" title="小补充1：重写onMeasure"></a>小补充1：重写onMeasure</h3><p>之前我们提到了，measure方法是final的，所以我们无法通过重写他去修改测量方式，但onMeasure方法却是我们可以在子类中重写的，也就是说，如果你不想使用系统默认的测量方式，可以按照自己的意愿进行定制，比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyView</span> <span class="keyword">extends</span> <span class="title">View</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onMeasure</span><span class="params">(<span class="keyword">int</span> widthMeasureSpec, <span class="keyword">int</span> heightMeasureSpec)</span> </span>&#123;</span><br><span class="line">setMeasuredDimension(<span class="number">70</span>, <span class="number">70</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样的话就把View默认的测量流程覆盖掉了，不管在布局文件中定义MyView这个视图的大小是多少，最终在界面上显示的大小都将会是70*70。</p><h3 id="小补充2-测量带有margin的子视图"><a href="#小补充2-测量带有margin的子视图" class="headerlink" title="小补充2:测量带有margin的子视图"></a>小补充2:测量带有margin的子视图</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">measureChildWithMargins</span><span class="params">(View child,</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">int</span> parentWidthMeasureSpec, <span class="keyword">int</span> widthUsed,</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">int</span> parentHeightMeasureSpec, <span class="keyword">int</span> heightUsed)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//获取子视图的LayoutParams</span></span><br><span class="line">        <span class="keyword">final</span> MarginLayoutParams lp = (MarginLayoutParams) child.getLayoutParams();</span><br><span class="line">        <span class="comment">//调整MeasureSpec</span></span><br><span class="line">        <span class="comment">//通过这两个参数以及子视图本身的LayoutParams来共同决定子视图的测量规格</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> childWidthMeasureSpec = getChildMeasureSpec(parentWidthMeasureSpec,</span><br><span class="line">                mPaddingLeft + mPaddingRight + lp.leftMargin + lp.rightMargin</span><br><span class="line">                        + widthUsed, lp.width);</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> childHeightMeasureSpec = getChildMeasureSpec(parentHeightMeasureSpec,</span><br><span class="line">                mPaddingTop + mPaddingBottom + lp.topMargin + lp.bottomMargin</span><br><span class="line">                        + heightUsed, lp.height);</span><br><span class="line">        <span class="comment">//调运子View的measure方法，子View的measure中会回调子View的onMeasure方法</span></span><br><span class="line">        child.measure(childWidthMeasureSpec, childHeightMeasureSpec);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>其实也很简单</p><h2 id="6-第二阶段：Layout"><a href="#6-第二阶段：Layout" class="headerlink" title="6. 第二阶段：Layout"></a>6. 第二阶段：Layout</h2><h3 id="主体-1"><a href="#主体-1" class="headerlink" title="主体"></a>主体</h3><p>measure过程结束后，视图的大小就已经测量好了，接下来就是layout的过程了。正如其名字所描述的一样，这个方法是用于给视图进行布局的，也就是确定视图的位置。performLayout()中会调用View.layout()方法来执行这个过程：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">performLayout</span><span class="params">(WindowManager.LayoutParams lp, <span class="keyword">int</span> desiredWindowWidth,</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">int</span> desiredWindowHeight)</span> </span>&#123;</span><br><span class="line">  ......</span><br><span class="line">    host.layout(<span class="number">0</span>, <span class="number">0</span>, host.mMeasuredWidth, host.mMeasuredHeight);</span><br><span class="line">......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">layout</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> t, <span class="keyword">int</span> r, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> oldL = mLeft;</span><br><span class="line">    <span class="keyword">int</span> oldT = mTop;</span><br><span class="line">    <span class="keyword">int</span> oldB = mBottom;</span><br><span class="line">    <span class="keyword">int</span> oldR = mRight;</span><br><span class="line">  <span class="comment">// 判断视图大小是否变化</span></span><br><span class="line">    <span class="keyword">boolean</span> changed = setFrame(l, t, r, b);</span><br><span class="line">    <span class="comment">// 需要重新layout</span></span><br><span class="line">    <span class="keyword">if</span> (changed || (mPrivateFlags &amp; LAYOUT_REQUIRED) == LAYOUT_REQUIRED) &#123;</span><br><span class="line">        <span class="keyword">if</span> (ViewDebug.TRACE_HIERARCHY) &#123;</span><br><span class="line">            ViewDebug.trace(<span class="keyword">this</span>, ViewDebug.HierarchyTraceType.ON_LAYOUT);</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">// 跟踪      </span></span><br><span class="line">        onLayout(changed, l, t, r, b);</span><br><span class="line">        mPrivateFlags &amp;= ~LAYOUT_REQUIRED;</span><br><span class="line">        <span class="keyword">if</span> (mOnLayoutChangeListeners != <span class="keyword">null</span>) &#123;</span><br><span class="line">            ArrayList&lt;OnLayoutChangeListener&gt; listenersCopy =</span><br><span class="line">                    (ArrayList&lt;OnLayoutChangeListener&gt;) mOnLayoutChangeListeners.clone();</span><br><span class="line">            <span class="keyword">int</span> numListeners = listenersCopy.size();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numListeners; ++i) &#123;</span><br><span class="line">                listenersCopy.get(i).onLayoutChange(<span class="keyword">this</span>, l, t, r, b, oldL, oldT, oldR, oldB);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mPrivateFlags &amp;= ~FORCE_LAYOUT;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>layout()方法接收四个参数，分别代表着左、上、右、下的坐标，当然这个坐标是相对于当前视图的父视图而言的。可以看到，这里还把刚才测量出的宽度和高度传到了layout()方法中：</p><p>在layout()方法中，首先会调用setFrame()方法来判断视图的大小是否发生过变化，以确定有没有必要对当前的视图进行重绘，同时还会在这里把传递过来的四个参数分别赋值给mLeft、mTop、mRight和mBottom这几个变量。接下来会在调用onLayout()方法，正如onMeasure()方法中的默认行为一样，也许你已经迫不及待地想知道onLayout()方法中的默认行为是什么样的了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Called from layout when this view should</span></span><br><span class="line"><span class="comment"> * assign a size and position to each of its children.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Derived classes with children should override</span></span><br><span class="line"><span class="comment"> * this method and call layout on each of</span></span><br><span class="line"><span class="comment"> * their children.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> changed This is a new size or position for this view</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> left Left position, relative to parent</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> top Top position, relative to parent</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> right Right position, relative to parent</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> bottom Bottom position, relative to parent</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onLayout</span><span class="params">(<span class="keyword">boolean</span> changed, <span class="keyword">int</span> left, <span class="keyword">int</span> top, <span class="keyword">int</span> right, <span class="keyword">int</span> bottom)</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>居然是空的…</p><p>这是因为onLayout()过程是为了确定视图在布局中所在的位置，而这个操作应该是由布局来完成的，即父视图决定子视图的显示位置。所以我们应该看看ViewGroup中的onLayout()方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">onLayout</span><span class="params">(<span class="keyword">boolean</span> changed, <span class="keyword">int</span> l, <span class="keyword">int</span> t, <span class="keyword">int</span> r, <span class="keyword">int</span> b)</span></span>;</span><br></pre></td></tr></table></figure><p>可以看到，ViewGroup中的onLayout()方法竟然是一个抽象方法，这就意味着所有ViewGroup的子类都必须重写这个方法。像LinearLayout、RelativeLayout等布局，都是重写了这个方法，然后在内部按照各自的规则对子视图进行布局的。</p><p>这里我们用LinearLayout举个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinearLayout</span> <span class="keyword">extends</span> <span class="title">ViewGroup</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  ......</span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onLayout</span><span class="params">(<span class="keyword">boolean</span> changed, <span class="keyword">int</span> l, <span class="keyword">int</span> t, <span class="keyword">int</span> r, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (mOrientation == VERTICAL) &#123;</span><br><span class="line">            layoutVertical(l, t, r, b);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            layoutHorizontal(l, t, r, b);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原来还是分Vertical和Horizontal的，我们来简单看看Vertical了解一下吧：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">layoutVertical</span><span class="params">(<span class="keyword">int</span> left, <span class="keyword">int</span> top, <span class="keyword">int</span> right, <span class="keyword">int</span> bottom)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> paddingLeft = mPaddingLeft;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> childTop;</span><br><span class="line">    <span class="keyword">int</span> childLeft;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//计算父窗口推荐的子View宽度</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> width = right - left;</span><br><span class="line">    <span class="comment">//计算父窗口推荐的子View右侧位置</span></span><br><span class="line">    <span class="keyword">int</span> childRight = width - mPaddingRight;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//child可使用空间大小</span></span><br><span class="line">    <span class="keyword">int</span> childSpace = width - paddingLeft - mPaddingRight;</span><br><span class="line">    <span class="comment">//通过ViewGroup的getChildCount方法获取ViewGroup的子View个数</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> count = getVirtualChildCount();</span><br><span class="line">    <span class="comment">//获取Gravity属性设置</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> majorGravity = mGravity &amp; Gravity.VERTICAL_GRAVITY_MASK;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> minorGravity = mGravity &amp; Gravity.RELATIVE_HORIZONTAL_GRAVITY_MASK;</span><br><span class="line">    <span class="comment">//依据majorGravity计算childTop的位置值</span></span><br><span class="line">    <span class="keyword">switch</span> (majorGravity) &#123;</span><br><span class="line">       <span class="keyword">case</span> Gravity.BOTTOM:</span><br><span class="line">           <span class="comment">// mTotalLength contains the padding already</span></span><br><span class="line">           childTop = mPaddingTop + bottom - top - mTotalLength;</span><br><span class="line">           <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">           <span class="comment">// mTotalLength contains the padding already</span></span><br><span class="line">       <span class="keyword">case</span> Gravity.CENTER_VERTICAL:</span><br><span class="line">           childTop = mPaddingTop + (bottom - top - mTotalLength) / <span class="number">2</span>;</span><br><span class="line">           <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">case</span> Gravity.TOP:</span><br><span class="line">       <span class="keyword">default</span>:</span><br><span class="line">           childTop = mPaddingTop;</span><br><span class="line">           <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//开始遍历!</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; count; i++) &#123;</span><br><span class="line">        <span class="keyword">final</span> View child = getVirtualChildAt(i);</span><br><span class="line">        <span class="keyword">if</span> (child == <span class="keyword">null</span>) &#123;</span><br><span class="line">            childTop += measureNullChild(i);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (child.getVisibility() != GONE) &#123;</span><br><span class="line">            <span class="comment">//LinearLayout中其子视图显示的宽和高由measure过程来决定的，因此measure过程的意义就是为layout过程提供视图显示范围的参考值</span></span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> childWidth = child.getMeasuredWidth();</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> childHeight = child.getMeasuredHeight();</span><br><span class="line">            <span class="comment">//获取子View的LayoutParams</span></span><br><span class="line">            <span class="keyword">final</span> LinearLayout.LayoutParams lp =</span><br><span class="line">                    (LinearLayout.LayoutParams) child.getLayoutParams();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> gravity = lp.gravity;</span><br><span class="line">            <span class="keyword">if</span> (gravity &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                gravity = minorGravity;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> layoutDirection = getLayoutDirection();</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> absoluteGravity = Gravity.getAbsoluteGravity(gravity, layoutDirection);</span><br><span class="line">            <span class="comment">//依据不同的absoluteGravity计算childLeft位置</span></span><br><span class="line">            <span class="keyword">switch</span> (absoluteGravity &amp; Gravity.HORIZONTAL_GRAVITY_MASK) &#123;</span><br><span class="line">                <span class="keyword">case</span> Gravity.CENTER_HORIZONTAL:</span><br><span class="line">                    childLeft = paddingLeft + ((childSpace - childWidth) / <span class="number">2</span>)</span><br><span class="line">                            + lp.leftMargin - lp.rightMargin;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">case</span> Gravity.RIGHT:</span><br><span class="line">                    childLeft = childRight - childWidth - lp.rightMargin;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">case</span> Gravity.LEFT:</span><br><span class="line">                <span class="keyword">default</span>:</span><br><span class="line">                    childLeft = paddingLeft + lp.leftMargin;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (hasDividerBeforeChildAt(i)) &#123;</span><br><span class="line">                childTop += mDividerHeight;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            childTop += lp.topMargin;</span><br><span class="line">            <span class="comment">//通过垂直排列计算调运child的layout设置child的位置</span></span><br><span class="line">            setChildFrame(child, childLeft, childTop + getLocationOffset(child),</span><br><span class="line">                    childWidth, childHeight);</span><br><span class="line">            childTop += childHeight + lp.bottomMargin + getNextLocationOffset(child);</span><br><span class="line"></span><br><span class="line">            i += getChildrenSkipCount(child, i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不难看出，一般情况下layout过程会参考measure过程中计算得到的mMeasuredWidth和mMeasuredHeight来安排子View在父View中显示的位置，但这不是必须的，measure过程得到的结果可能完全没有实际用处，特别是对于一些自定义的ViewGroup，其子View的个数、位置和大小都是固定的，这时候我们可以忽略整个measure过程，只在layout函数中传入的4个参数来安排每个子View的具体位置。</p><p>到此为止，我们把视图绘制流程的第二阶段也分析完了。</p><h3 id="核心-1"><a href="#核心-1" class="headerlink" title="核心"></a>核心</h3><ul><li><p>View.layout方法可被重载，ViewGroup.layout为final的不可重载，ViewGroup.onLayout为abstract的，子类必须重载实现自己的位置逻辑。</p></li><li><p>measure操作完成后得到的是对每个View经测量过的measuredWidth和measuredHeight，layout操作完成之后得到的是对每个View进行位置分配后的mLeft、mTop、mRight、mBottom，这些值都是相对于父View来说的。</p></li><li><p>凡是layout_XXX的布局属性基本都针对的是包含子View的ViewGroup的，当对一个没有父容器的View设置相关layout_XXX属性是没有任何意义的。</p></li><li><p>使用View的getWidth()和getHeight()方法来获取View测量的宽高，必须保证这两个方法在onLayout流程之后被调用才能返回有效值。</p></li></ul><h2 id="7-第三阶段：Draw"><a href="#7-第三阶段：Draw" class="headerlink" title="7. 第三阶段：Draw"></a>7. 第三阶段：Draw</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>measure和layout的过程都结束后，接下来就进入到draw的过程了。同样，根据名字你就能够判断出，在这里才真正地开始对视图进行绘制。ViewRoot中的代码会继续执行并创建出一个Canvas对象，然后调用performDraw，通过调用View的draw()方法来执行具体的绘制工作：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">performTraversals</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">final</span> Rect dirty = mDirty;</span><br><span class="line">    ......</span><br><span class="line">    canvas = mSurface.lockCanvas(dirty);</span><br><span class="line">    ......</span><br><span class="line">    performDraw();</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">performDraw</span><span class="params">()</span></span>&#123;</span><br><span class="line">  ......</span><br><span class="line">  mView.draw(canvas);  </span><br><span class="line">  ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们来看一看重中之重的View.draw()（ViewGroup并没有重写View的draw方法）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">draw</span><span class="params">(Canvas canvas)</span> </span>&#123;</span><br><span class="line">    ......</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Draw traversal performs several drawing steps which must be executed</span></span><br><span class="line"><span class="comment">     * in the appropriate order:</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *      1. Draw the background</span></span><br><span class="line"><span class="comment">     *      2. If necessary, save the canvas' layers to prepare for fading</span></span><br><span class="line"><span class="comment">     *      3. Draw view's content</span></span><br><span class="line"><span class="comment">     *      4. Draw children</span></span><br><span class="line"><span class="comment">     *      5. If necessary, draw the fading edges and restore layers</span></span><br><span class="line"><span class="comment">     *      6. Draw decorations (scrollbars for instance)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 1, draw the background, if needed</span></span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">if</span> (!dirtyOpaque) &#123;</span><br><span class="line">        drawBackground(canvas);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// skip step 2 &amp; 5 if possible (common case)</span></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 2, save the canvas' layers</span></span><br><span class="line">    ......</span><br><span class="line">        <span class="keyword">if</span> (drawTop) &#123;</span><br><span class="line">            canvas.saveLayer(left, top, right, top + length, <span class="keyword">null</span>, flags);</span><br><span class="line">        &#125;</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 3, draw the content</span></span><br><span class="line">    <span class="keyword">if</span> (!dirtyOpaque) onDraw(canvas);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 4, draw the children</span></span><br><span class="line">    dispatchDraw(canvas);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 5, draw the fade effect and restore layers</span></span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">if</span> (drawTop) &#123;</span><br><span class="line">        matrix.setScale(<span class="number">1</span>, fadeHeight * topFadeStrength);</span><br><span class="line">        matrix.postTranslate(left, top);</span><br><span class="line">        fade.setLocalMatrix(matrix);</span><br><span class="line">        p.setShader(fade);</span><br><span class="line">        canvas.drawRect(left, top, right, top + length, p);</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Step 6, draw decorations (scrollbars)</span></span><br><span class="line">    onDrawScrollBars(canvas);</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>源码注释说（”skip step 2 &amp; 5 if possible (common case)”）第2和5步可以跳过，所以我们接下来重点剩余四步:</p><h3 id="第一步：绘制View的背景"><a href="#第一步：绘制View的背景" class="headerlink" title="第一步：绘制View的背景"></a>第一步：绘制View的背景</h3><p>我们来看drawBackground(canvas)：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">drawBackground</span><span class="params">(Canvas canvas)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//获取xml中通过android:background属性或者代码中setBackgroundColor()、setBackgroundResource()等方法进行赋值的背景Drawable</span></span><br><span class="line">    <span class="keyword">final</span> Drawable background = mBackground;</span><br><span class="line">    ......</span><br><span class="line">    <span class="comment">//根据layout过程确定的View位置来设置背景的绘制区域</span></span><br><span class="line">    <span class="keyword">if</span> (mBackgroundSizeChanged) &#123;</span><br><span class="line">        background.setBounds(<span class="number">0</span>, <span class="number">0</span>,  mRight - mLeft, mBottom - mTop);</span><br><span class="line">        mBackgroundSizeChanged = <span class="keyword">false</span>;</span><br><span class="line">        rebuildOutline();</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">        <span class="comment">//调用Drawable的draw()方法来完成背景的绘制工作</span></span><br><span class="line">        background.draw(canvas);</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="第三步：对View内容进行绘制"><a href="#第三步：对View内容进行绘制" class="headerlink" title="第三步：对View内容进行绘制"></a>第三步：对View内容进行绘制</h3><p>这里去调用了一下View的onDraw()方法（ViewGroup也没有重写该方法）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Implement this to do your drawing.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> canvas the canvas on which the background will be drawn</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onDraw</span><span class="params">(Canvas canvas)</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现，这里又是一个空方法。因为每个View的内容部分是不同的，所以需要由子类去实现具体的逻辑</p><h3 id="第四步：对当前View的所有子View进行绘制"><a href="#第四步：对当前View的所有子View进行绘制" class="headerlink" title="第四步：对当前View的所有子View进行绘制"></a>第四步：对当前View的所有子View进行绘制</h3><p>先来看dispatchDraw(canvas)方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Called by draw to draw the child views. This may be overridden</span></span><br><span class="line"><span class="comment"> * by derived classes to gain control just before its children are drawn</span></span><br><span class="line"><span class="comment"> * (but after its own view has been drawn).</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> canvas the canvas on which to draw the view</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">dispatchDraw</span><span class="params">(Canvas canvas)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于空方法已经看习惯了….其实他们的逻辑都差不多，一般都是因为具体实现要交给子类去完成。注释中还说到，如果View包含子View需要重写他，所以我们来看一看ViewGroup.dispatchDraw():</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">dispatchDraw</span><span class="params">(Canvas canvas)</span> </span>&#123;</span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> childrenCount = mChildrenCount;</span><br><span class="line">    <span class="keyword">final</span> View[] children = mChildren;</span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; childrenCount; i++) &#123;</span><br><span class="line">        ......</span><br><span class="line">     <span class="comment">// 这里在for循环中遍历了每一个子View，并通过drawChild方法绘制子View的内容</span></span><br><span class="line">        <span class="keyword">if</span> ((child.mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != <span class="keyword">null</span>) &#123;</span><br><span class="line">            more |= drawChild(canvas, child, drawingTime);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">    <span class="comment">// Draw any disappearing views that have animations</span></span><br><span class="line">    <span class="keyword">if</span> (mDisappearingChildren != <span class="keyword">null</span>) &#123;</span><br><span class="line">        ......</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = disappearingCount; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">            ......</span><br><span class="line">            more |= drawChild(canvas, child, drawingTime);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>drawChild:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ViewGroup.drawChild */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">drawChild</span><span class="params">(Canvas canvas, View child, <span class="keyword">long</span> drawingTime)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> child.draw(canvas, <span class="keyword">this</span>, drawingTime);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看见drawChild()方法调运了子View的draw()方法。所以说ViewGroup类已经为我们重写了dispatchDraw()的功能实现，我们一般不需要重写该方法，但可以重载父类函数实现具体的功能。</p><p>到此，draw过程就从父View传递到了子View，并重复此过程直到到达View树的叶子节点。</p><h3 id="第六步：绘制装饰（如滑动条）"><a href="#第六步：绘制装饰（如滑动条）" class="headerlink" title="第六步：绘制装饰（如滑动条）"></a>第六步：绘制装饰（如滑动条）</h3><p>可以看到，这里去调用了一下View的onDrawScrollBars()方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;Request the drawing of the horizontal and the vertical scrollbar. The</span></span><br><span class="line"><span class="comment"> * scrollbars are painted only if they have been awakened first.&lt;/p&gt;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> canvas the canvas on which to draw the scrollbars</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@see</span> #awakenScrollBars(int)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">onDrawScrollBars</span><span class="params">(Canvas canvas)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//绘制ScrollBars分析不是我们这篇的重点，所以暂时不做分析</span></span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实不管是Button也好，TextView也好，任何一个视图都是有滚动条的，只是一般情况下我们都没有让它显示出来而已。绘制滚动条的代码逻辑也比较复杂，这里就不再贴出来了，因为我们的重点是第三步过程。</p><p>通过以上流程分析，相信大家已经发现，View是不会帮我们绘制内容部分的，因此需要每个视图根据想要展示的内容来自行绘制。如果你去观察TextView、ImageView等类的源码，你会发现它们都有重写onDraw()这个方法，并且在里面执行了相当不少的绘制逻辑。绘制的方式主要是借助Canvas这个类，它会作为参数传入到onDraw()方法中，供给每个视图使用。</p><p>到此为止，三个阶段全部完成。</p><h3 id="核心-2"><a href="#核心-2" class="headerlink" title="核心"></a>核心</h3><ul><li><p>如果该View是一个ViewGroup，则需要递归绘制其所包含的所有子View。</p></li><li><p>View默认不会绘制任何内容，真正的绘制都需要自己在子类中实现。</p></li><li><p>View的绘制是借助onDraw方法传入的Canvas类来进行的。</p></li><li><p>区分View动画和ViewGroup布局动画，前者指的是View自身的动画，可以通过setAnimation添加，后者是专门针对ViewGroup显示内部子视图时设置的动画，可以在xml布局文件中对ViewGroup设置layoutAnimation属性（譬如对LinearLayout设置子View在显示时出现逐行、随机、下等显示等不同动画效果）。</p></li><li><p>在获取画布剪切区（每个View的draw中传入的Canvas）时会自动处理掉padding，子View获取Canvas不用关注这些逻辑，只用关心如何绘制即可。</p></li><li><p>默认情况下子View的ViewGroup.drawChild绘制顺序和子View被添加的顺序一致，但是你也可以重载ViewGroup.getChildDrawingOrder()方法提供不同顺序。</p></li></ul><h3 id="小补充：View的requestLayout"><a href="#小补充：View的requestLayout" class="headerlink" title="小补充：View的requestLayout"></a>小补充：View的requestLayout</h3><p>其实在上面分析View绘制流程时或多或少都调运到了这个方法，而且这个方法对于View来说也比较重要，所以我们接下来分析一下他：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requestLayout</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">if</span> (mParent != <span class="keyword">null</span> &amp;&amp; !mParent.isLayoutRequested()) &#123;</span><br><span class="line">        <span class="comment">//由此向ViewParent请求布局</span></span><br><span class="line">        <span class="comment">//从这个View开始向上一直requestLayout，最终到达ViewRootImpl的requestLayout</span></span><br><span class="line">        mParent.requestLayout();</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当我们触发View的requestLayout时其实质就是层层向上传递，直到ViewRootImpl为止，然后触发我们之前提到的ViewRootImpl的requestLayout方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">requestLayout</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!mHandlingLayoutInLayoutRequest) &#123;</span><br><span class="line">        checkThread();</span><br><span class="line">        mLayoutRequested = <span class="keyword">true</span>;</span><br><span class="line">        <span class="comment">//View调运requestLayout最终层层上传到ViewRootImpl后最终触发了该方法</span></span><br><span class="line">        scheduleTraversals();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="8-补充：Activity启动与WindowManager"><a href="#8-补充：Activity启动与WindowManager" class="headerlink" title="8. 补充：Activity启动与WindowManager"></a>8. 补充：Activity启动与WindowManager</h2><p>对于Activity的启动过程，是有两种，一种是点击程序进入启动的Activity，另一种而是在已有的Activity中调用startActivity，启动期间通过Binder驱动ActivityWindowService，ActivityThread，ApplicationThread，ActivityStack ，Activity之间进行通信，为当前Activity创建进程分配任务栈后启动Activity。</p><p>这里就跳过前面很多步骤，直接到了ActivityThread.handleLaunchActivity去查看Activity的创建：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleLaunchActivity</span><span class="params">(ActivityClientRecord r, Intent customIntent)</span> </span>&#123;</span><br><span class="line">       ...</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Initialize before creating the activity</span></span><br><span class="line">        WindowManagerGlobal.initialize();</span><br><span class="line"></span><br><span class="line">        Activity a = performLaunchActivity(r, customIntent);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (a != <span class="keyword">null</span>) &#123;</span><br><span class="line">            r.createdConfig = <span class="keyword">new</span> Configuration(mConfiguration);</span><br><span class="line">            Bundle oldState = r.state;</span><br><span class="line">            handleResumeActivity(r.token, <span class="keyword">false</span>, r.isForward,</span><br><span class="line">            ...</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>可以看到 WindowManagerGlobal.initialize()通过WindowManagerGlobal创建了WindowManagerServer，接下来调用了performLaunchActivity：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Activity <span class="title">performLaunchActivity</span><span class="params">(ActivityClientRecord r, Intent customIntent)</span> </span>&#123;</span><br><span class="line">        ...</span><br><span class="line">        Activity activity = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123; <span class="comment">//Activity通过ClassLoader创建出来</span></span><br><span class="line">            java.lang.ClassLoader cl = r.packageInfo.getClassLoader();</span><br><span class="line">            activity = mInstrumentation.newActivity(</span><br><span class="line">                    cl, component.getClassName(), r.intent);  </span><br><span class="line">        &#125; ...</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//创建Application</span></span><br><span class="line">            Application app = r.packageInfo.makeApplication(<span class="keyword">false</span>, mInstrumentation);</span><br><span class="line">            ...</span><br><span class="line">            <span class="keyword">if</span> (activity != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">//创建Activity所需的Context</span></span><br><span class="line">                Context appContext = createBaseContextForActivity(r, activity);</span><br><span class="line">                ...</span><br><span class="line">                <span class="comment">//将Context与Activity进行绑定</span></span><br><span class="line">                activity.attach(appContext, <span class="keyword">this</span>, getInstrumentation(), r.token,</span><br><span class="line">                        r.ident, app, r.intent, r.activityInfo, title, r.pareånt,</span><br><span class="line">                        r.embeddedID, r.lastNonConfigurationInstances, config,</span><br><span class="line">                        r.referrer, r.voiceInteractor);</span><br><span class="line">                ...</span><br><span class="line">                    <span class="comment">//调用activity.oncreate</span></span><br><span class="line">                    mInstrumentation.callActivityOnCreate(activity, r.state, r.persistentState);</span><br><span class="line">                ...</span><br><span class="line">                     <span class="comment">//调用Activity的onstart方法</span></span><br><span class="line">                     activity.performStart();</span><br><span class="line">                           <span class="comment">//调用activitu的OnRestoreInstanceState方法进行Window数据恢复 </span></span><br><span class="line">             mInstrumentation.callActivityOnRestoreInstanceState(activity, r.state,</span><br><span class="line">                                    r.persistentState);</span><br><span class="line">                ...</span><br><span class="line">        <span class="keyword">return</span> activity;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>先通过调用 activity = mInstrumentation.newActivity创建Activity，可以看到里面是通过ClassLoader来加载的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Activity <span class="title">newActivity</span><span class="params">(ClassLoader cl, String className,</span></span></span><br><span class="line"><span class="function"><span class="params">            Intent intent)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> InstantiationException, IllegalAccessException,</span></span><br><span class="line"><span class="function">            ClassNotFoundException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (Activity)cl.loadClass(className).newInstance();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>接着创建Activity所需的Application和Context，再调用到activity.attach：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">attach</span><span class="params">(Context context, ActivityThread aThread,</span></span></span><br><span class="line"><span class="function"><span class="params">            Instrumentation instr, IBinder token, <span class="keyword">int</span> ident,</span></span></span><br><span class="line"><span class="function"><span class="params">            Application application, Intent intent, ActivityInfo info,</span></span></span><br><span class="line"><span class="function"><span class="params">            CharSequence title, Activity parent, String id,</span></span></span><br><span class="line"><span class="function"><span class="params">            NonConfigurationInstances lastNonConfigurationInstances,</span></span></span><br><span class="line"><span class="function"><span class="params">            Configuration config, String referrer, IVoiceInteractor voiceInteractor)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//ContextImpl的绑定</span></span><br><span class="line">        attachBaseContext(context);</span><br><span class="line">        <span class="comment">//在当前Activity创建Window</span></span><br><span class="line">        mWindow = <span class="keyword">new</span> PhoneWindow(<span class="keyword">this</span>);</span><br><span class="line">        mWindow.setCallback(<span class="keyword">this</span>);</span><br><span class="line">        mWindow.setOnWindowDismissedCallback(<span class="keyword">this</span>);</span><br><span class="line">        mWindow.getLayoutInflater().setPrivateFactory(<span class="keyword">this</span>);</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">//为Window设置WindowManager</span></span><br><span class="line">        mWindow.setWindowManager(</span><br><span class="line">                (WindowManager)context.getSystemService(Context.WINDOW_SERVICE),</span><br><span class="line">                mToken, mComponent.flattenToString(),</span><br><span class="line">                (info.flags &amp; ActivityInfo.FLAG_HARDWARE_ACCELERATED) != <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (mParent != <span class="keyword">null</span>) &#123;</span><br><span class="line">            mWindow.setContainer(mParent.getWindow());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//创建完后通过getWindowManager就可以得到WindowManager实例</span></span><br><span class="line">        mWindowManager = mWindow.getWindowManager();</span><br><span class="line">        mCurrentConfig = config;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>可以看到对应的Window窗口也被创建起来，而且Window也与WindowManager绑定。而mWindow，和mWindowManager则是Activity的成员变量。可以看到这里WindiwManager的创建是context.getSystemService(Context.WINDOW_SERVICE)</p><p>接着创建WindowManager的实现类，我们平时在Activity中使用getWindow（）和getWindowManager，就是返回对应这两个成员变量:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setWindowManager</span><span class="params">(WindowManager wm, IBinder appToken, String appName,</span></span></span><br><span class="line"><span class="function"><span class="params">          <span class="keyword">boolean</span> hardwareAccelerated)</span> </span>&#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">if</span> (wm == <span class="keyword">null</span>) &#123;</span><br><span class="line">          wm = (WindowManager)mContext.getSystemService(Context.WINDOW_SERVICE);</span><br><span class="line">      &#125;</span><br><span class="line">      mWindowManager = ((WindowManagerImpl)wm).createLocalWindowManager(<span class="keyword">this</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>在调用了activity.attach后创建了Window和WindowManager，之后调用了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">callActivityOnCreate</span><span class="params">(Activity activity, Bundle icicle)</span> </span>&#123;</span><br><span class="line">        prePerformCreate(activity);</span><br><span class="line">        activity.performCreate(icicle);</span><br><span class="line">        postPerformCreate(activity);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可以看到里面调用了performCreate</span></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">performCreate</span><span class="params">(Bundle icicle)</span> </span>&#123;</span><br><span class="line">        onCreate(icicle);</span><br><span class="line">        mActivityTransitionState.readState(icicle);</span><br><span class="line">        performCreateCommon();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>然后就算是进入到Activiy的生命周期了….</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>以下都是我在学习和写文档时候参考的文章，对于一些知识点的讲解可能更加详细：</p><p><a href="https://www.jianshu.com/p/8766babc40e0" target="_blank" rel="noopener">简析Window、Activity、DecorView以及ViewRoot之间的错综关系</a></p><p><a href="https://blog.csdn.net/guolin_blog/article/details/16330267" target="_blank" rel="noopener">Android视图绘制流程完全解析，带你一步步深入了解View</a></p><p><a href="https://www.jianshu.com/p/40a9c93b5a8d" target="_blank" rel="noopener">Android窗口机制系列</a></p><p><a href="https://blog.csdn.net/yanbober/article/details/46128379" target="_blank" rel="noopener">Android应用层View绘制流程与源码分析</a></p>]]></content>
    
    <summary type="html">
    
      关于Android中View绘制的一篇详解
    
    </summary>
    
      <category term="Android开发" scheme="http://yoursite.com/categories/Android%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="Android" scheme="http://yoursite.com/tags/Android/"/>
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
      <category term="开发" scheme="http://yoursite.com/tags/%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>从感知机到神经网络</title>
    <link href="http://yoursite.com/2019/08/31/%E4%BB%8E%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%88%B0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2019/08/31/从感知机到神经网络/</id>
    <published>2019-08-30T23:29:02.000Z</published>
    <updated>2020-08-12T02:10:58.569Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、感知机"><a href="#一、感知机" class="headerlink" title="一、感知机"></a>一、感知机</h2><h3 id="1-概念"><a href="#1-概念" class="headerlink" title="1.概念"></a>1.概念</h3><p>感知机(perceptron)是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别。</p><p>听起来复杂，但其实很简单，我们先来看一个感知机的例子：</p><p><img src="/images/1.png" alt="img" style="zoom:67%;"></p><p>本例中的感知机有三个输入信号：$x_1, x_2, x_3$（当然，它可以有更多或者更少的输入），他们分别有一个权重: $w_1, w_2, w_3$ , 图中的⚪被称为神经元或节点，输入信号被送往神经元时会被分别乘以固定的权重。神经元的输出是0还是1，由加权和  是否小于或者大于某一个阈值（threshold）决定的，这也被称为“神经元被激活”。</p><p>感知机的各个信号都有其固有的权重，这些权重来表示各个输入对于输出的重要程度，权重越大，对应权重信号的重要性就越高。</p><p>利用单个感知机，我们可以轻松的模拟，与 和 或 两种运算，但对于异或运算，我们似乎束手无策。</p><h3 id="2-单层感知机的局限性"><a href="#2-单层感知机的局限性" class="headerlink" title="2.单层感知机的局限性"></a>2.单层感知机的局限性</h3><p>异或运算：</p><p><img src="/images/感知机到神经网络3.png" alt="img" style="zoom: 40%;"></p><p>思考一下，有没有办法使用单个感知机进行异或运算呢？</p><p>好像真的不行….</p><p>但这是为什么呢，我们先来看看或运算的数学图像：</p><p><img src="/images/感知机到神经网络4.png" alt="img" style="zoom:25%;"></p><p>这是这个或门数学公式的图像化表示，阴影区域代表输出0，非阴影区域代表输出1，三角和圆圈分别代表和。</p><p>但我们要是用数学图像表示异或运算呢？</p><p><img src="/images/感知机到神经网络6.png" alt="img" style="zoom:25%;"></p><p>通过异或门的图像化表示，我们发现，这些结果并不按套路出牌，它们的位置无法用一条直线分割成两类。</p><p>也可以说：异或运算是非线性的（线性与非线性在机器学习领域很常见）。</p><p>通过观察感知机的数学公式，我们知道上面的感知机只能被画成直线；但要想正确把异或门的结果分开，必须使用曲线。</p><p>上过计组的大家一定都知道，其实仅使用与门和或门是可以实现所有电路的，所以：</p><p><img src="/images/感知机到神经网络5.png" alt="img" style="zoom:33%;"></p><p>没错，这就是异或门，不信咱们用真值表验证一下：</p><p><img src="/images/感知机到神经网络7.png" alt="img" style="zoom:35%;"></p><p>所以，异或对应的多层感知机已经呼之欲出：</p><p><img src="/images/感知机到神经网络8.png" alt="img" style="zoom:33%;"></p><p>图中的感知机总共由3层构成，但是因为拥有权重的层实际上只有2层（第0层和第1层之间，第1层和第2层之间）所以被称为“2层感知机”，不过也有人称其为“3层感知机”。</p><p>通过这样的双层结构，感知机得以实现异或门，这可以解释为“单层感知机无法解决的问题， 可以通过增加一层感知机来解决”。也就是说，通过叠加层（加深层），感知机能进行更加灵活的表示。</p><h3 id="3-多层感知机"><a href="#3-多层感知机" class="headerlink" title="3.多层感知机"></a>3.多层感知机</h3><p>多层感知机可以实现比之前见到的电路更复杂的电路，比如进行加法运算的加法器也可以使用感知机实现（如计组实现过的那样），编码器等也可以通过感知机实现，其实，用感知机甚至可以表现计算机。</p><p>综上，多层感知机可以进行复杂的表示，甚至可以构建计算机。理论上，可以说2层感知机就能构建计算机。这是因为，亦有研究证明，2层感知机（严格地说是激活函数使用了非线性的sigmoid函数的感知机，会在后面提到）可以表示任意函数。但是，使用2层感知机的构造，通过设定合适的权重来制造计算机还是非常复杂，但只要记住，感知机通过叠加层能够进行非线性的表示，理论上还可以表示计算机进行的处理即可。</p><h3 id="4-小结"><a href="#4-小结" class="headerlink" title="4.小结"></a>4.小结</h3><p>可以说，感知机是神经网络的基础，所以，对于感知机的理解十分重要。</p><h2 id="二、神经网络"><a href="#二、神经网络" class="headerlink" title="二、神经网络"></a>二、神经网络</h2><h3 id="1-基础"><a href="#1-基础" class="headerlink" title="1.基础"></a>1.基础</h3><p>通过对感知机的学习，我们知道，即便对于复杂的函数，感知机也隐含着能够表示他的可能性，但是，设定权重的工作，即确定合适的、能符合预期的输入与输出的权重，还是由人工进行的。</p><p>神经网络和感知机有很多的共同点，我们先以他们的差异为中心，来介绍神经网络的结构：</p><p><img src="/images/感知机到神经网络9.png" alt="img" style="zoom:33%;"></p><p>图中就是一个简单的神经网络，其中的“中间层”有时也被称为“隐藏层”。我们也可以用第0层代表输入层，第1层代表中间层（隐藏层），第2层代表输出层。</p><p>再进一步深入以前，我们先再简单回顾一下感知机：</p><p>对于一个简单的双输入感知机，存在公式</p><script type="math/tex; mode=display">\begin{eqnarray} \mbox{output} & = & \left\{ \begin{array}{ll} 0 & \mbox{if } \ w_1*x_1 + w_2*x_2 + b  \leq \mbox{ 0} \\ 1 & \mbox{if } \ w_1*x_1 + w_2*x_2 + b >  \mbox{ 0} \end{array} \right. \end{eqnarray}</script><p>b就是阈值，也可以称为偏置的参数，用于控制神经元被激活的容易程度；是表示各个信号重要程度的参数，用于控制各个信号的重要性。</p><p>在之前的感知机图像中，我们并没有将b明确的画出来，如果想要表示它，我们可以这样做：</p><p><img src="/images/gzj10.png" alt="img" style="zoom:40%;"></p><p>对于之前的公式，我们可引入新函数，将其改写为：</p><script type="math/tex; mode=display">y = h * (b + w_1 * x_1 + w_2 * x_ 2)</script><script type="math/tex; mode=display">\begin{eqnarray} \mbox{h(x)} & = & \left\{ \begin{array}{ll} 0 & \mbox{if } \ x \leq \mbox{0} \\ 1 & \mbox{if} \ \ x  >  \mbox{0} \end{array} \right. \end{eqnarray}</script><h3 id="2-激活函数"><a href="#2-激活函数" class="headerlink" title="2.激活函数"></a>2.激活函数</h3><p>刚刚出现的函数会将输入信号的加权综合转换为输出信号，这种函数一般被称为<strong>激活函数</strong>，激活函数的作用在于决定如何来激活输入信号的总和。</p><p>在之前已经认识了激活函数家族的第一个成员：像实现与门或门的函数这样的，以阈值为界，一旦输入超过阈值，就切换输出的函数被称为“阶跃函数”。</p><p>因此，可以说感知机中使用了阶跃函数作为激活函数，那么，如果感知机使用其他函数作为激活函数的话会怎么样呢？实际上，如果将激活函数从阶跃函数换成其他函数，就可以进入神经网络的世界了。</p><p>就像下面这样：</p><p><img src="/images/gzj1.png" alt="img" style="zoom:40%;"></p><p>如图2-3所示，表示神经元的⚪中明确显示了激活函数的计算过程，即信号的加权总和为节点a，然后节点a被激活函数 转换成节点y，这里，我们称a和y为“节点”，其实它和之前所说的“神经元”含义相同。</p><h4 id="2-1-sigmoid函数"><a href="#2-1-sigmoid函数" class="headerlink" title="2.1 sigmoid函数"></a>2.1 sigmoid函数</h4><p>神经网络中经常使用的一个激活函数就是sigmoid函数 。</p><script type="math/tex; mode=display">$h(x) = \frac{1}{1 + e^{-x}}</script><p>（e是自然常数2.7182…）</p><p>神经网络中用sigmoid函数作为激活函数，进行信号的转换，转换后的信号被传送给下一个神经元。感知机和接下来要介绍的神经网络的主要区别就在于这个激活函数。其他方面，比如神经元的多层连接的构造、信号的传递方法等，基本上和感知机是一样的。</p><p>我们先看看阶跃函数的图像：</p><p><img src="/images/gzj12.png" alt="img" style="zoom:25%;"></p><p>如图所示，阶跃函数以0为界，输出从0切换为1（或者从1切换为0）。 它的值呈阶梯式变化，所以称为阶跃函数。</p><h4 id="2-2-sigmoid函数和阶跃函数的比较"><a href="#2-2-sigmoid函数和阶跃函数的比较" class="headerlink" title="2.2 sigmoid函数和阶跃函数的比较"></a>2.2 sigmoid函数和阶跃函数的比较</h4><p>现在我们来比较一下sigmoid 函数和阶跃函数，把他们重合在一起：</p><p><img src="/images/gzj13.png" alt="img" style="zoom:25%;"></p><p>可以明显观察到，他们的平滑性不同，sigmoid函数是一条平滑的曲线，输出随着输入发生连续性的变化。而阶跃函数以0为界，输出发生急剧性的变化，sigmoid函数的平滑性对神经网络的学习具有重要意义。</p><p>另一个不同点是，相对于阶跃函数只能返回0或1，而sigmoid函数可以返回0到1之间的任意实数，也就是说，感 知机中神经元之间流动的是0或1的二元信号，而神经网络中流动的是连续 的实数值信号。</p><p>而他们的共同性质是：如果从宏观视角看图2-5，可以发现它们 具有相似的形状。实际上，两者的结构均是“输入小时，输出接近0（为 0）； 随着输入增大，输出向1靠近（变成1）”。也就是说，当输入信号为重要信息时， 阶跃函数和sigmoid函数都会输出较大的值；当输入信号为不重要的信息时， 两者都输出较小的值。还有一个共同点是，不管输入信号有多小，或者有多大，输出信号的值都在0到1之间。</p><p>还有一点就是：两者均为非线性函数。 sigmoid函数是一条曲线，阶跃函数是一条像阶梯一样的折线，两者都属于<strong>非线性</strong>的函数。</p><h4 id="2-3-非线性函数"><a href="#2-3-非线性函数" class="headerlink" title="2.3 非线性函数"></a>2.3 非线性函数</h4><p>神经网络的激活函数必须使用非线性函数，如果使用线性函数的话，加深神 经网络的层数就没有意义了。</p><p>这是为什么呢？</p><p>线性函数的问题在于，不管如何加深层数，总是存在与之等效的“无隐藏层的神经网络”。</p><p>为了具体地理解这一点，我们来思考下面这个简单的例子。</p><p>假如把线性函数  作为激活函数，把    的运算对应3层神经网络A。这个运算会进行  的乘法运算，但是同样的处理可以由 这一次乘法运算（即没有隐藏层的神经网络）来表示。</p><p>如本例所示， 使用线性函数时，无法发挥多层网络带来的优势，是一种“浪费”。因此，为了发挥叠加层所带来的优势，激活函数必须使用非线性函数。</p><h4 id="2-4-ReLu函数"><a href="#2-4-ReLu函数" class="headerlink" title="2.4 ReLu函数"></a>2.4 ReLu函数</h4><p>可以说，到目前为止，sigmoid函数和ReLu函数是最常用的两种激活函数。</p><p>ReLU函数在输入大于0时，直接输出该值；在输入小于等于0时，输出0：</p><script type="math/tex; mode=display">\begin{eqnarray} \mbox{h(x)} & = & \left\{ \begin{array}{ll} 0 & \mbox{if } \ x  \leq \mbox{ 0} \\ x & \mbox{if } \ x >  \mbox{ 0} \end{array} \right. \end{eqnarray}</script><p><img src="/images/gzj14.png" alt="img" style="zoom:25%;"></p><h4 id="3-多维数组的运算"><a href="#3-多维数组的运算" class="headerlink" title="3.多维数组的运算"></a>3.多维数组的运算</h4><p>这里一些十分基础的矩阵运算就不再提及了， 毕竟大家都已经学过线性代数了。</p><p>所以我们来直接看一看他在神经网络中是如何进行的：</p><p><img src="/images/gzj15.png" alt="img" style="zoom:33%;"></p><p>信号在各层之间的传递：</p><p><img src="/images/gzj16.png" alt="img" style="zoom:25%;"></p><p>图2-8中增加了表示偏置的神经元“1”。请注意，偏置的右下角的索引号只有一个。这是因为前一层的偏置神经元（神经元“1”）只有一个。</p><p>为了确认前面的内容，现在用数学式表示，通过加权信号和偏置的和按如下方式进行计算：</p><script type="math/tex; mode=display">a_1^{(1)}  =  w_{11}^{(1)} * x_1+ w_{12}^{(1)} * x_2 + b_1^{(1)}</script><p>如果使用矩阵的乘法运算，则可以将第1层的加权和表示成下面的式子：</p><script type="math/tex; mode=display">A^{(1)} = XW^{(1)} + B^{(1)}</script><p><img src="/images/gzj17.png" alt="img" style="zoom:33%;"></p><p>在我们加入激活函数后向后传递：</p><p><img src="/images/gzj18.png" alt="img" style="zoom:25%;"></p><p>当神经网络进行到最后一层（输出层）时，为了和之前的流程保持一致，我们对输出层也增加一个激活函数，即恒等函数。恒等函数会将输入按原样输出，输出层的激活函数用σ()表示，不同于隐 藏层的激活函数h()。</p><blockquote><p>Tip ：输出层所用的激活函数，要根据求解问题的性质决定。一般地，回 归问题可以使用恒等函数，二元分类问题可以使用sigmoid函数， 多元分类问题可以使用softmax函数（会在后面介绍）。</p></blockquote><h4 id="4-恒等函数和softmax函数"><a href="#4-恒等函数和softmax函数" class="headerlink" title="4.恒等函数和softmax函数"></a>4.恒等函数和softmax函数</h4><p>恒等函数会将输入按原样输出，对于输入的信息，不加以任何改动地直接输出。</p><p>而在分类问题中使用的softmax函数可以如下表示：</p><script type="math/tex; mode=display">y_k = \frac{e^{a_k}}{  \sum_{i = 1}^n  {e^{a_i}}}</script><p>如图所示， softmax函数的输出通过箭头与所有的输入信号相连，输出层的各个神经元都受到所有输入信号的影响。</p><p><img src="/images/gzj19.png" alt="img" style="zoom:35%;"></p><h4 id="4-1-softmax函数的特征"><a href="#4-1-softmax函数的特征" class="headerlink" title="4.1 softmax函数的特征"></a>4.1 softmax函数的特征</h4><p>softmax函数的输出是0.0到1.0之间的实数。并且，softmax 函数的输出值的总和是1。输出总和为1是softmax函数的一个重要性质。正因为有了这个性质，我们才可以把softmax函数的输出解释为“概率”。</p><p>假设上图的结果， $y_1$是0.245（24.5 %）， $y_2$是0.737（73.7%）。从概率的结果来看，我们可以说“因为第2个元素的概率最高，所以答案是第2个类别”，通过使用softmax函数，我们可以用概率的（统 计的）方法处理问题。</p><p>显然，各输出之间的大小关系也不会发生改变，一般而言，神经网络只把输出值最大的神经元所对应的类别作为识别结果。</p><h4 id="4-2-输出层神经元的数量"><a href="#4-2-输出层神经元的数量" class="headerlink" title="4.2 输出层神经元的数量"></a>4.2 输出层神经元的数量</h4><p>输出层的神经元数量需要根据待解决的问题来决定。对于分类问题，输出层的神经元数量一般设定为类别的数量。</p><blockquote><p>求解机器学习问题的步骤可以分为“学习” 和“推理”两个阶段。首先，在学习阶段进行模型的学习B，然后，在推理阶段，用学到的 模型对未知的数据进行推理（分类）。如前所述，推理阶段一般会省 略输出层的softmax函数。在输出层使用softmax函数是因为它和神经网络的学习有关（后面会提到）。</p></blockquote><h4 id="4-3-批处理"><a href="#4-3-批处理" class="headerlink" title="4.3 批处理"></a>4.3 批处理</h4><p>批处理对计算机的运算大有利处，可以大幅缩短每张图像的处理时间。这是因为大多数处理 数值计算的库都进行了能够高效处理大型数组运算的最优化。</p><p>并且，在神经网络的运算中，当数据传送成为瓶颈时，批处理可以减轻数 据总线的负荷（严格地讲，相对于数据读入，可以将更多的时间用在计算上）。也就是说，批处理一次性计算大型数组要比分开逐步计算各个小型数组速度更快。</p><p>一般通过设置batch_size来设置批数量。</p><h2 id="三、神经网络的学习"><a href="#三、神经网络的学习" class="headerlink" title="三、神经网络的学习"></a>三、神经网络的学习</h2><p>神经网络的特征就是可以从数据中学习。所谓“从数据中学习”，是指 可以由数据自动决定权重参数的值。</p><p>在感知机的例子中，我们对照着真值表，人工设定了参数的值，但是那时的参数只有3个。 而在实际的神经网络中，参数的数量成千上万，在层数更深的深度学习中， 参数的数量甚至可以上亿，想要人工决定这些参数的值是不可能的</p><p>机器学习的方法中，由机器从收集到的数据中找出规律性。与从零开始 想出算法相比，这种方法可以更高效地解决问题，也能减轻人的负担。但是 需要注意的是，将图像转换为向量时使用的特征量仍是由人设计的。对于不同的问题，必须使用合适的特征量（必须设计专门的特征量），才能得到好的结果。</p><p>比如，识别动物和识别数字，显然需要使用不同的特征量。</p><p>到这里，我们介绍了两种针对机器学习任务的方法。将这两种方法用图来表示，。图中还展示了神经网络（深度学习）的方法，可以看出该方法不存在人为介入，神经网络直接学习图像本身。而在第2个方法，即利用特征量和机器学习的方法中，特征量仍是由人工设计的，但在神经网络中，连图像中包含的重要特征量也都是由机器来学习的。</p><p><img src="/images/gzj20.png" alt="img" style="zoom:33%;"></p><p>神经网络的优点是对所有的问题都可以用同样的流程来解决。比如，不管要求解的问题是识别数字，还是识别动物或是识别人脸，神经网络都是通过不断地学习所提供的数据，尝试发现待求解的问题的模式。也就是说，与待处理的问题无关，神经网络可以将数据直接作为原始数据，进行“端对端”的学习，这也正是神经网络强大的地方。</p><h3 id="1-基础-1"><a href="#1-基础-1" class="headerlink" title="1.基础"></a>1.基础</h3><p>机器学习中，一般将数据分为<strong>训练数据</strong>和<strong>测试数据</strong>两部分来进行学习和 实验等。首先，使用训练数据进行学习，寻找最优的参数；然后，使用测试 数据评价训练得到的模型的实际能力。</p><p>为什么需要将数据分为训练数据和测试数据呢？因为我们追求的是模型的泛化能力。为了正确评价模型的<strong>泛化能力</strong>，就必须划分训练数据和测试数据。另外，训练数据也可以称为<strong>监督数据</strong>。</p><p>泛化能力是指处理未被观察过的数据（不包含在训练数据中的数据）的 能力。获得泛化能力是机器学习的最终目标，如果系统 只能正确识别已有的训练数据，那有可能是只学习到了训练数据中的个人的习惯写法。</p><p>因此，仅仅用一个数据集去学习和评价参数，是无法进行正确评价的。 这样会导致可以顺利地处理某个数据集，但无法处理其他数据集的情况。只对某个数据集过度拟合的状态称为<strong>过拟合</strong>避免过拟合也是机器学习的一个重要课题。</p><h3 id="2-损失函数"><a href="#2-损失函数" class="headerlink" title="2.损失函数"></a>2.损失函数</h3><p>损失函数是表示神经网络性能的“恶劣程度”的指标，即当前的神经网络对监督数据在多大程度上不拟合，在多大程度上不一致。</p><h4 id="2-1-均方误差"><a href="#2-1-均方误差" class="headerlink" title="2.1 均方误差"></a>2.1 均方误差</h4><p>可以用作损失函数的函数有很多，其中最有名的是均方误差（mean squared error）。均方误差如下式所示：</p><script type="math/tex; mode=display">E = \frac{1}{2}\sum\nolimits_{k} {(y_k - t_k)} ^ 2</script><p>这里，<img src="https://math.jianshu.com/math?formula=y_k" alt="y_k">是表示神经网络的输出，<img src="https://math.jianshu.com/math?formula=t_k" alt="t_k">表示监督数据，k表示数据的维数。</p><h4 id="2-2-交叉熵误差"><a href="#2-2-交叉熵误差" class="headerlink" title="2.2 交叉熵误差"></a>2.2 交叉熵误差</h4><p>除了均方误差之外，交叉熵误差（cross entropy error）也经常被用作损 失函数。交叉熵误差如下式所示：</p><script type="math/tex; mode=display">E = -\sum_{k} t_k \ln y_k</script><p>实际上只计算对应正确解标签的输出的自然对数。比如，假设正确解标签的索引是“2”，与之对应的神经网络的输出是0.6，则交叉熵误差是−log 0.6 = 0.51；若“ 2”对应的输出是0.1，则交叉熵误差为−log0.1 = 2.30。 也就是说，交叉熵误差的值是由正确解标签所对应的输出结果决定的。</p><h4 id="2-3-mini-batch学习"><a href="#2-3-mini-batch学习" class="headerlink" title="2.3 mini-batch学习"></a>2.3 mini-batch学习</h4><p>机器学习使用训练数据进行学习。使用训练数据进行学习，严格来说， 就是针对训练数据计算损失函数的值，找出使该值尽可能小的参数。因此，计算损失函数时必须将所有的训练数据作为对象。也就是说，如果训练数据有100个的话，我们就要把这100个损失函数的总和作为学习的指标，以交叉熵误差为例，可以写成下面的式子：</p><script type="math/tex; mode=display">E = -\frac{1}{N} \sum_{n} \sum_{k} t_{nk} \ln y_{nk}</script><p>这里,假设数据有N个，<img src="https://math.jianshu.com/math?formula=t_%7Bnk%7D%0A" alt="t_{nk}">表示第n个数据的第k个元素的值。</p><p>如果遇到大数据， 数据量会有几百万、几千万之多，这种情况下以全部数据为对象计算损失函 数是不现实的。因此，我们从全部数据中选出一部分，作为全部数据的“近 似”。神经网络的学习也是从训练数据中选出一批数据（称为mini-batch,小 批量），然后对每个mini-batch进行学习。比如，从60000个训练数据中随机 选择100笔，再用这100笔数据进行学习。这种学习方式称为<strong>mini-batch学习</strong>。</p><h3 id="3-数值微分"><a href="#3-数值微分" class="headerlink" title="3.数值微分"></a>3.数值微分</h3><h4 id="3-1-导数"><a href="#3-1-导数" class="headerlink" title="3.1 导数"></a>3.1 导数</h4><p>这个大家显然都学过，物理意义和数学意义就不在这里多讲了</p><h4 id="3-2-数值微分的实现"><a href="#3-2-数值微分的实现" class="headerlink" title="3.2 数值微分的实现"></a>3.2 数值微分的实现</h4><p>利用微小的差分求导数的过程称为数值微分（numerical  differentiation）。而基于数学式的推导求导数的过程，则用“解析性”（analytic）一词，称为“解析性求解”或者“解析性求导”。比如， y = x2的导数，可以通过解析性地求解出来。因此，当x = 2时， y的导数为4。解析性求导得到的导数是不含误差的“真的导数”。</p><p><img src="/images/gzj21.png" alt="img" style="zoom:20%;"></p><h4 id="3-3-偏导数"><a href="#3-3-偏导数" class="headerlink" title="3.3 偏导数"></a>3.3 偏导数</h4><p>偏导数和单变量的导数一样，都是求某个地方的斜率。不过， 偏导数需要将多个变量中的某一个变量定为目标变量，并将其他变量固定为某个值。在上例的代码中，为了将目标变量以外的变量固定到某些特定的值 上，我们定义了新函数。然后，对新定义的函数应用了之前的求数值微分的 函数，得到偏导数。</p><h3 id="4-梯度"><a href="#4-梯度" class="headerlink" title="4.梯度"></a>4.梯度</h3><p>在刚才的例子中，我们按变量分别计算了<img src="https://math.jianshu.com/math?formula=x_0%0A" alt="x_0">和<img src="https://math.jianshu.com/math?formula=x_1%0A" alt="x_1">的偏导数。现在，我们希望一起计算$x_1$和$x_1$的偏导数。比如，我们来考虑求 $x_0$= 3,$x_1$ = 4时(x0,x 1) 的偏导数 ，由全部变量的偏导数汇总而成的向量称为梯度（gradient）。</p><p>如图所示$f(x_0 + x_1) = x_0^2 + x_1^2$的梯度呈现为有向向量（箭头），我们发现梯度指向函数的“最低处”（最小值），就像指南针 一样，所有的箭头都指向同一点。其次，我们发现离“最低处”越远，箭头越大。</p><p><img src="/images/gzj22.png" alt="img" style="zoom:23%;"></p><p>虽然图4-9中的梯度指向了最低处，但并非任何时候都这样。实际上， 梯度会指向各点处的函数值降低的方向。更严格地讲，梯度指示的方向 是各点处的函数值减小最多的方向。</p><h4 id="4-1-梯度法"><a href="#4-1-梯度法" class="headerlink" title="4.1 梯度法"></a>4.1 梯度法</h4><p>机器学习的主要任务是在学习时寻找最优参数。同样地，神经网络也必须在学习时找到最优参数（权重和偏置）。这里所说的最优参数是指损失函数取最小值时的参数。但是，一般而言，损失函数很复杂，参数空间庞大，我们不知道它在何处能取得最小值。而通过巧妙地使用梯度来寻找函数最小值 （或者尽可能小的值）的方法就是梯度法。</p><p>梯度表示的是各点处的函数值减小最多的方向。因此，无法保证梯度所指的方向就是函数的最小值或者真正应该前进的方向。实际上，在复杂的函数中，梯度指示的方向基本上都不是函数值最小处。</p><blockquote><p>函数的极小值、最小值以及被称为鞍点的地方， 梯度为0。极小值是局部最小值，也就是限定在某个范围内的最 小值。鞍点是从某个方向上看是极大值，从另一个方向上看则是极小值的点。</p><p>虽然梯度法是要寻找梯度为0的地方，但是那个地方不一定就是最小值（也有可能是极小值或者鞍点）。此外，当函数很复杂且呈扁平状时，学习可能会进入一个（几乎）平坦的地区， 陷入被称为“学习高原”的无法前进的停滞期。 </p></blockquote><p>虽然梯度的方向并不一定指向最小值，但沿着它的方向能够最大限度地 减小函数的值，在梯度法中，函数的取值从当前位置沿着梯 度方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度方向前进， 如此反复，不断地沿梯度方向前进。</p><p>严格地讲， 寻找最小值的梯度法称为<strong>梯度下降法</strong> ， 寻找最大值的梯度法称为<strong>梯度上升法，</strong>但是通过反转损失函数的符号，求最小值的问题和求最大值的问题会变成相同的问题。</p><script type="math/tex; mode=display">x_0 = x_0 - \eta \frac{\vartheta f}{\vartheta x_0}</script><script type="math/tex; mode=display">x_1 = x_1 - \eta \frac{\vartheta f}{\vartheta x_1}</script><p>η表示更新量，在神经网络的学习中，称为学习率。学习率决定在一次学习中，应该学习多少，以及在多大程度上更新参数。这个步骤会反复执行，也就是说，每 一步都按式（4.7）更新变量的值，通过反复执行此步骤，逐渐减小函数值。 </p><p>学习率需要事先确定为某个值，比如0.01或0.001。一般而言，这个值过大或过小，都无法抵达一个“好的位置”。在神经网络的学习中，一般会 一边改变学习率的值，一边确认学习是否正确进行了。</p><h4 id="4-2-神经网络的梯度"><a href="#4-2-神经网络的梯度" class="headerlink" title="4.2 神经网络的梯度"></a>4.2 神经网络的梯度</h4><p>神经网络的学习也要求梯度，这里所说的梯度是指损失函数关于权重参数的梯度。比如，有一个只有一个形状为2×3的权重W的神经网络，损失函数用L表示。此时，梯度可以用$\frac{\vartheta L}{\vartheta w} $表示。</p><p><img src="/images/gzj23.png" alt="img" style="zoom:33%;"></p><p>然后我们用学习率乘以在相应位置上的梯度，更新权重。</p><p>相比数值微分法求梯度， 使用误差反向传播法精度更高，和解析法是一致的。误差反向传播法是通过计算图实现的，假如有时间可以另行介绍。</p><h3 id="5-深度学习算法的实现"><a href="#5-深度学习算法的实现" class="headerlink" title="5.深度学习算法的实现"></a>5.深度学习算法的实现</h3><p>关于神经网络学习的基础知识，到这里就全部介绍完了。“损失函数”，“ mini-batch”，“梯度”，“梯度下降法”等关键词已经悉数登场，接下来我们来确认一下神经网络的学习步骤：</p><p><strong>前提</strong>         <strong>神经网络存在合适的权重和偏置，调整权重和偏置以便拟合训练数据的 过程称为“学习”。神经网络的学习分成下面4个步骤。</strong></p><p><strong>步骤1</strong>    <strong>（mini-batch） 从训练数据中随机选出一部分数据，这部分数据称为mini-batch。我们 的目标是减小mini-batch的损失函数的值。</strong></p><p><strong>步骤2</strong>    <strong>（计算梯度） 为了减小mini-batch的损失函数的值，需要求出各个权重参数的梯度。 梯度表示损失函数的值减小最多的方向。</strong></p><p><strong>步骤3</strong>    <strong>（更新参数） 将权重参数沿梯度方向进行微小更新。</strong></p><p><strong>步骤4</strong>    <strong>（重复） 重复步骤1、步骤2、步骤3。</strong></p><p>神经网络的学习按照上面4个步骤进行。这个方法通过梯度下降法更新参数，不过因为这里使用的数据是随机选择的mini batch数据，所以又称为<strong>随机梯度下降法（SGD）</strong>。“随机”指的是“随机选择的” 的意思，因此，随机梯度下降法是“对随机选择的数据进行的梯度下降法”。 深度学习的很多框架中，随机梯度下降法一般由一个名为SGD的函数来实现。 SGD来源于随机梯度下降法的英文名称的首字母。 </p><h2 id="三、学习的技巧"><a href="#三、学习的技巧" class="headerlink" title="三、学习的技巧"></a>三、学习的技巧</h2><p>将会介绍神经网络的学习中的一些重要观点，主题涉及寻找最优权重参数的最优化方法、权重参数的初始值、超参数的设定方法等。此外，为了应对过拟合，还将介绍权值衰减、Dropout等正则化方法， 最后将对近年来众多研究中使用的Batch Normalization方法进行简单的介绍。</p><h3 id="1-参数的更新"><a href="#1-参数的更新" class="headerlink" title="1.参数的更新"></a>1.参数的更新</h3><p>神经网络的学习的目的是找到使损失函数的值尽可能小的参数。这是寻 找最优参数的问题，解决这个问题的过程称为最优化（optimization）。</p><p>在之前，为了找到最优参数，我们将参数的梯度（导数）作为了线索。 使用参数的梯度，沿梯度方向更新参数，并重复这个步骤多次，从而逐渐靠 近最优参数，这个过程称为随机梯度下降法<strong>（SGD）。</strong>SGD是一个简单的方法，不过比起胡乱地搜索参数空间，也算是“聪 明”的方法。但是，根据不同的问题，也存在比SGD更加聪明的方法。</p><h4 id="1-1-SGD"><a href="#1-1-SGD" class="headerlink" title="1.1 SGD"></a>1.1 SGD</h4><script type="math/tex; mode=display">W \leftarrow  W - \eta \frac{\vartheta L}{\vartheta W}</script><p>这里把需要更新的权重参数记为W，把损失函数关于W的梯度记为$\frac{\vartheta L}{\vartheta W} $。 η表示学习率，实际上会取0.01或0.001这些事先决定好的值。</p><p>虽然SGD简单，并且容易实现，但是在解决某些问题时可能没有效率。 这里，在指出SGD的缺点之际，我们来思考一下求下面这个函数的最小值的问题:</p><script type="math/tex; mode=display">f(x, y) = \frac{1}{20}x^2 + y^2</script><p><img src="/images/gzj24.png" alt="img" style="zoom:33%;"></p><p>现在看一下这个函数的梯度。如果用图表示梯度的话，则如图所示，这个梯度的特征是，y轴方向上大，x轴方向上小。换句话说， 就是y轴方向的坡度大，而x轴方向的坡度小。这里需要注意的是，虽然式 （6.2）的最小值在(x,y) = (0, 0)处，但是图中的梯度在很多地方并没有指 向(0, 0)。</p><p><img src="/images/gzj25.png" alt="img" style="zoom:25%;"></p><p>如果我们对这种形状的函数应用SGD，明显会呈现“之”字形移动这种非常低效的路径，所以，SGD的缺点是，如果函数的形状非均向（anisotropic），比如呈延伸状，搜索 的路径就会非常低效。</p><p><img src="/images/gzj26.png" alt="img" style="zoom:25%;"></p><p>所以接下来我们介绍几种优化后的方法，很多原理都比较复杂，大家可以自行查阅论文，这里主要是介绍。</p><h4 id="1-2-Momentum"><a href="#1-2-Momentum" class="headerlink" title="1.2 Momentum"></a>1.2 Momentum</h4><p>Momentum是“动量”的意思，和物理有关。用数学式表示Momentum方 法，如下所示：</p><script type="math/tex; mode=display">W \leftarrow  \alpha \nu  - \eta \frac{\vartheta L}{\vartheta W}</script><p>和前面的SGD一样，W表示要更新的权重参数， $\frac{\vartheta L}{\vartheta W} $表示损失函数关 于W的梯度，η表示学习率。这里新出现了一个变量v，对应物理上的速度。这个公式表示了物体在梯度方向上的受力，在这个力的作用下，物体的速度增加这一物理法则。其中中有 αv这一项。在物体不受任何力时，该项承担使物体逐渐减速的任务（α设定为0.9之类的值），对应物理上的地面摩擦或空气阻力。</p><p><img src="/images/gzj27.png" alt="img" style="zoom:25%;"></p><p>可以看到，当我们使用momentum优化时，更新路径就像小球在碗中滚动一样。和SGD相比，我们发现 “之”字形的“程度”减轻了。这是因为虽然x轴方向上受到的力非常小，但是因为一直在同一方向上受力，所以朝同一个方向会有一定的加速。反过来，虽然y轴方向上受到的力很大，但是因为交互地受到正方向和反方向的力，它们会互相抵消，所以y轴方向上的速度不稳定。</p><h4 id="1-3-AdaGrad"><a href="#1-3-AdaGrad" class="headerlink" title="1.3 AdaGrad"></a>1.3 AdaGrad</h4><p>在神经网络的学习中，学习率（数学式中记为η）的值很重要。学习率过小， 会导致学习花费过多时间；反过来，学习率过大，则会导致学习发散而不能 正确进行。 </p><p>在关于学习率的有效技巧中，有一种被称为学习率衰减（learning rate decay）的方法，即随着学习的进行，使学习率逐渐减小。实际上，一开始“多” 学，然后逐渐“少”学的方法，在神经网络的学习中经常被使用。 逐渐减小学习率的想法，相当于将“全体”参数的学习率值一起降低。 </p><p>而AdaGrad 进一步发展了这个想法，针对“一个一个”的参数，赋予其“定制”的值。 AdaGrad会为参数的每个元素适当地调整学习率，与此同时进行学习 。下面，让我们用数学式表示AdaGrad的更新方法。</p><script type="math/tex; mode=display">h \leftarrow  h - \eta \frac{\vartheta L}{\vartheta W}  \odot \frac{\vartheta L}{\vartheta W}</script><script type="math/tex; mode=display">W \leftarrow  W - \eta \frac{1}{\sqrt{h} } \frac{\vartheta L}{\vartheta W}</script><p>和前面的SGD一样，W表示要更新的权重参数， $ \frac{\vartheta L}{\vartheta W} $表示损失函数关 于W的梯度，η表示学习率。这里新出现了变量h，它保存了以前的所有梯度值的平方和, $\odot$表示对应矩阵元素的乘法。 然后，在更新参数时，通过乘以$ \frac{1}{\sqrt{h} }$ ，就可以调整学习的尺度。这意味着， 参数的元素中变动较大（被大幅更新）的元素的学习率将变小。也就是说， 可以按参数的元素进行学习率衰减，使变动大的参数的学习率逐渐减小。</p><blockquote><p>AdaGrad会记录过去所有梯度的平方和。因此，学习越深入，更新的幅度就越小。实际上，如果无止境地学习，更新量就会变为0， 完全不再更新。为了改善这个问题，可以使用<strong>RMSProp</strong>方法。 RMSProp方法并不是将过去所有的梯度一视同仁地相加，而是逐渐 地遗忘过去的梯度，在做加法运算时将新梯度的信息更多地反映出来。 这种操作从专业上讲，称为“指数移动平均”，呈指数函数式地减小 过去的梯度的尺度。</p></blockquote><p><img src="/images/gzj28.png" alt="img" style="zoom:25%;"></p><p>函数的取值高效地向着最小值移动。由于y轴方向上的梯度较大，因此刚开始变动较大，但是后面会根据这个较大的变动按 比例进行调整，减小更新的步伐。因此，y轴方向上的更新程度被减弱，“之” 字形的变动程度明显减弱。</p><h4 id="1-4-Adam"><a href="#1-4-Adam" class="headerlink" title="1.4 Adam"></a>1.4 Adam</h4><p>Momentum参照小球在碗中滚动的物理规则进行移动，AdaGrad为参 数的每个元素适当地调整更新步伐。如果将这两个方法融合在一起会怎么样呢？这就是Adam的基本思路。</p><p>Adam是2015年提出的新方法。它的理论有些复杂，简单地讲，就是融 合了Momentum和AdaGrad的方法。通过组合前面两个方法的优点，有望实现参数空间的高效搜索。此外，进行超参数（后面会提到）的“偏置校正”也是Adam的特征。 这里不再进行过多的说明，详细内容请参考原作者的论文。</p><blockquote><p>Adam会设置3个超参数。一个是学习率（论文中以α出现），另外两 个是一次momentum系数β1和二次momentum系数β2。根据论文， 标准的设定值是β1为0.9，β2 为0.999。设置了这些值后，大多数情 况下都能顺利运行。</p></blockquote><p><img src="/images/gzj29.png" alt="img" style="zoom:25%;"></p><p>基于Adam的更新过程就像小球在碗中滚动一样。虽然 Momentun也有类似的移动，但是相比之下，Adam的小球左右摇晃的程度 有所减轻。这得益于学习的更新程度被适当地调整了。</p><p>上面我们介绍了SGD、Momentum、AdaGrad、Adam这4种方法，那么用哪种方法好呢？</p><p>非常遗憾，目前并不存在能在所有问题中都表现良好 的方法。这4种方法各有各的特点，都有各自擅长解决的问题和不擅长解决的问题。 很多研究中至今仍在使用SGD。Momentum和AdaGrad也是值得一试的方法，最近也很多研究人员和技术人员都喜欢用Adam。</p><h3 id="2-权重的初始值"><a href="#2-权重的初始值" class="headerlink" title="2. 权重的初始值"></a>2. 权重的初始值</h3><p>在神经网络的学习中，权重的初始值特别重要。实际上，设定什么样的 权重初始值，经常关系到神经网络的学习能否成功。</p><p>后面我们会介绍抑制过拟合、提高泛化能力的技巧——权值衰减（weight decay）。简单地说，权值衰减就是一种以减小权重参数的值为目的进行学习的方法。通过减小权重参数的值来抑制过拟合的发生。 </p><p>如果想减小权重的值，一开始就将初始值设为较小的值才是正途。实际上， 在这之前的权重初始值都是像$0.01 * np.random.randn(10, 100)$这样，使用由高斯分布生成的值乘以0.01后得到的值（标准差为0.01的高斯分布）。</p><p>如果我们把权重初始值全部设为0以减小权重的值，会怎么样呢？从结论来说，将权重初始值设为0不是一个好主意。事实上，将权重初始值设为0的话，将无法正确进行学习。</p><p>这是因为在误差反向传播法中，所有的权重值都会进行相同的更新。比如，在2层神经网络中，假设第1层和第2层的权重为0。这样一来，正向传播时，因为输入层的权重为0，所以第2层的神经元全部会被传递相同的值。第2层的神经元中全部输入相同的值，这意味着反向传播时第2层的权重全部都会进行相同的更新。因此，权重被更新为相同的值，并拥有了重复的值。 这使得神经网络拥有许多不同的权重的意义丧失了。为了防止“权重均一化” ，必须随机生成初始值。</p><p>接下来我们来看看权重的初值是如何影响隐藏层的激活值的分布的：</p><p>当我们使用标准差为1的高斯分布作为权重初始值时各层的激活值偏向0和1分布，假如使用sigmoid函数，随着输出不断靠近0或1，他的导数值不断接近于0。因此，偏向0和1的数据分布会造成反向传播中梯度的值不断变小，最后消失。这个问题称为<strong>梯度消失</strong>。层次加深的深度学习中，梯度消失的问题可能会更加严重。</p><p><img src="/images/gzj30.png" alt="img" style="zoom:67%;"></p><p>而使用标准差为0.01的高斯分布时，如图所示：</p><p><img src="/images/gzj31.png" alt="img" style="zoom:67%;"></p><p>这次呈集中在0.5附近的分布，因为不像刚才的例子那样偏向0和1，所以不会发生梯度消失的问题。但是，激活值的分布有所偏向，说明在表现力 上会有很大问题。为什么这么说呢？</p><p>因为如果有多个神经元都输出几乎相同 的值，那它们就没有存在的意义了。比如，如果100个神经元都输出几乎相同的值，那么也可以由1个神经元来表达基本相同的事情。因此，激活值在 分布上有所偏向会出现“表现力受限”的问题。</p><h4 id="2-1-Xavier初始值"><a href="#2-1-Xavier初始值" class="headerlink" title="2.1 Xavier初始值"></a>2.1 Xavier初始值</h4><p>Xavier的论文中，为了使各层的激活值呈现出具有相同广度的分布，推导了合适的权重尺度。推导出的结论是，如果前一层的节点数为n，则初始 值使用标准差为$\frac{1}{\sqrt{n} } $的分布。使用Xavier初始值后，前一层的节点数越多，要设定为目标节点的初始值的权重尺度就越小。</p><p><img src="/images/gzj32.png" alt="img" style="zoom:67%;"></p><p>使用Xavier初始值后的结果如图6-13所示。从这个结果可知，越是后面的层，图像变得越歪斜，但是呈现了比之前更有广度的分布。因为各层间传递的数据有适当的广度，所以sigmoid函数的表现力不受限制，有望进行高效的学习。</p><p>想了解Xavier初始值是如何推导的，可以看我在网上看到的这篇文章：<a href="https://www.cnblogs.com/hejunlin1992/p/8723816.html" target="_blank" rel="noopener">深度学习中Xavier初始化</a></p><h4 id="2-2-ReLu初始值"><a href="#2-2-ReLu初始值" class="headerlink" title="2.2 ReLu初始值"></a>2.2 ReLu初始值</h4><p>Xavier初始值是以激活函数是线性函数为前提而推导出来的。因为 sigmoid函数和tanh函数左右对称，且中央附近可以视作斜率为1的线性函数，所以适用于Xavier函数。</p><p>但当激活函数使用ReLu时，一般推荐使用“He初始值”，即当前一层的节点数为n时，He初始值使用标准差为$ \frac{2}{\sqrt {n}} $的高斯分布。当 Xavier初始值是 时，（直观上）可以解释为，因为ReLU的负值区域的值 为0，为了使它更有广度，所以需要2倍的系数。</p><p>接下来我们看看三种情况下的实验结果：</p><p><img src="/images/gzj33.png" alt="img" style="zoom:67%;"></p><p>观察实验结果可知，当“std = 0.01”时，各层的激活值非常小。神经网络上传递的是非常小的值，说明逆向传播时权重的梯度也同样很小，学习基本没有进展。</p><p>接下来是初始值为Xavier初始值时的结果。在这种情况下，随着层的加深， 偏向一点点变大。实际上，层加深后，随着激活值的偏向变大，学习时会出现梯度消失的问题。</p><p>而当初始值为He初始值时，各层中分布的广度相同。由于即便层加深，数据的广度也能保持不变，因此逆向传播时，也会传递合适的值。</p><h3 id="3-Batch-Normalization-批量标准化"><a href="#3-Batch-Normalization-批量标准化" class="headerlink" title="3. Batch Normalization 批量标准化"></a>3. Batch Normalization 批量标准化</h3><p>Batch Normalization（下文简称Batch Norm）是 2015年提出的方法。 Batch Norm虽然是一个问世不久的新方法，但已经被很多研究人员和技术 人员广泛使用。</p><p>Batch Norm有以下优点：</p><p>• 可以使学习快速进行（可以增大学习率）。</p><p>• 不那么依赖初始值（对于初始值不用那么纠结）。 </p><p>• 抑制过拟合（降低<strong>Dropout（一种避免过拟合的方法，后面会提到）</strong>等的必要性）。</p><p>Batch Norm的思路是调整各层的激活值分布使其拥有适当 的广度。为此，要向神经网络中插入对数据分布进行正规化的层，即Batch Normalization层。</p><p><img src="/images/gzj34.png" alt="img" style="zoom:67%;"></p><p>Batch Norm，顾名思义，以进行学习时的mini-batch为单位，按mini-batch进行正规化。具体而言，就是进行使数据分布的均值为0、方差为1的正规化。用数学式表示的话，如下所示:</p><script type="math/tex; mode=display">\mu _B \leftarrow  \frac {1} {m} \sum_{i=1}^m x_i$$         $${\sigma _B}^2 \leftarrow \frac {1}{m} \sum_{i = 1}^m {(x_i - \mu _B)}^2$$)    $$\hat{x} _i \leftarrow \frac{x_i - \mu_B}{\sqrt{\sigma_B ^2 + \varepsilon }}</script><p>这里对mini-batch的m个输入数据的集合B ={x1,x2,…,xm}求均值 $\mu _B$和方差${\sigma _B}^2 $ 。然后，对输入数据进行均值为0、方差为1（合适的分布）的正规化。式子中的<img src="https://math.jianshu.com/math?formula=%5Cvarepsilon%20" alt="\varepsilon ">是一个微小值（比如，10e-7等），它是为了防止出现除以0的情况。</p><p>接着，Batch Norm层会对正规化后的数据进行缩放和平移的变换，用数学式可以如下表示：</p><script type="math/tex; mode=display">y_i= \gamma \hat{x} _i + \beta</script><p>这里，$\gamma $和$\beta$是参数。一开始$\gamma$ = 1，$\beta$ = 0，然后再通过学习调整到合适的值。 </p><p><img src="/images/干着急5.png" alt="img" style="zoom:67%;"></p><p>几乎所有的情况下都是使用Batch Norm时学习进行得更快。 同时也可以发现，在不使用Batch Norm的情况下，如果不赋予一个尺度好的初始值，学习将完全无法进行。通过使用Batch Norm，可以推动学习的进行；并且，神经网络对权重初始值变得健壮。</p><h3 id="4-正则化"><a href="#4-正则化" class="headerlink" title="4.正则化"></a>4.正则化</h3><p>机器学习的问题中，<strong>过拟合</strong>是一个很常见的问题。过拟合指的是只能拟合训练数据，但不能很好地拟合不包含在训练数据中的其他数据的状态。所以，抑制过拟合的技巧很重要。</p><p>发生过拟合的原因，主要有以下两个：</p><p>• 模型拥有大量参数、表现力强。</p><p> • 训练数据少。</p><p><img src="/images/gzj36.png" alt="img" style="zoom: 50%;"></p><h4 id="4-1-权值衰减"><a href="#4-1-权值衰减" class="headerlink" title="4.1 权值衰减"></a>4.1 权值衰减</h4><p>权值衰减是一直以来经常被使用的一种抑制过拟合的方法。该方法通过在学习的过程中对大的权重进行惩罚，来抑制过拟合。很多过拟合原本就是因为权重参数取值过大才发生的。 </p><p>神经网络的学习目的是减小损失函数的值。这时，例如为损失函数加上权重的平方范数（L2范数）。这样一来，就可以抑制权重变大。 用符号表示的话，如果将权重记为$W$，L2范数的权值衰减就是$\frac{1}{2}\lambda W^2$ ，然 后将这个$\frac{1}{2}\lambda W^2$加到损失函数上。这里，λ是控制正则化强度的超参数。λ 设置得越大，对大的权重施加的惩罚就越重。此外，$\frac{1}{2}\lambda W^2$开头的$\frac{1}{2}$是用于将$\frac{1}{2}\lambda W^2$的求导结果变成$\lambda W$的调整用常量。 对于所有权重，权值衰减方法都会为损失函数加上 。因此，在求权 重梯度的计算中，要为之前的误差反向传播法的结果加上正则化项的导数$\lambda W$。</p><blockquote><p>L2范数相当于各个元素的平方和。用数学式表示的话，假设有权重 $W = （w_1, w_2 … , w_n)$，则L2范数可用$L_2 = \sqrt {w_1^2 + w_2^2 + …. + w_n^2}$计算出来。</p></blockquote><p><img src="/images/gzj37.png" alt="img" style="zoom: 50%;"></p><h4 id="4-2-Dropout"><a href="#4-2-Dropout" class="headerlink" title="4.2 Dropout"></a>4.2 Dropout</h4><p>作为抑制过拟合的方法，前面我们介绍了为损失函数加上权重的L2范数的权值衰减方法。该方法可以简单地实现，在某种程度上能够抑制过拟合。但是，如果网络的模型变得很复杂，只用权值衰减就难以应对了。</p><p>在这种情 况下，我们经常会使用Dropout方法。 Dropout是一种在学习的过程中随机删除神经元的方法。训练时，随机选出隐藏层的神经元，然使其暂时失效。被删除的神经元不再进行信号的传递。训练时，每传递一次数据，就会随机选择要失效的神经元。 </p><p><img src="/images/gzj38.png" alt="img" style="zoom:67%;"></p><p>通过使用Dropout，训练数据和测试数据的识别精度的差距 变小了。并且，训练数据也没有到达100%的识别精度。像这样，通过使用 Dropout，即便是表现力强的网络，也可以抑制过拟合。</p><p><img src="/images/gzj39.png" alt="img" style="zoom:67%;"></p><blockquote><p>机器学习中经常使用集成学习。所谓集成学习，就是让多个模型单 独进行学习，推理时再取多个模型的输出的平均值。实验告诉我们，通过进行集成学习，神经网络的识别精度可以提高好几个百分点。这个集成学习与Dropout有密切的关系。</p><p>这是因为可以将Dropout 理解为，通过在学习过程中随机删除神经元，从而每一次都让不同的模型进行学习。并且，推理时，通过对神经元的输出乘以删除比例（比如，0.5等），可以取得模型的平均值。也就是说，可以理解成， Dropout将集成学习的效果通过一个网络实现了。</p></blockquote><h4 id="4-3-超参数验证"><a href="#4-3-超参数验证" class="headerlink" title="4.3 超参数验证"></a>4.3 超参数验证</h4><p>神经网络中，除了权重和偏置等参数，超参数（hyper-parameter）也经常出现。这里所说的超参数是指，比如各层的神经元数量、batch大小、参数更新时的学习率或权值衰减等。如果这些超参数没有设置合适的值，模型的性能就会很差。</p><p>之前我们使用的数据集分成了训练数据和测试数据，训练数据用于学习， 测试数据用于评估泛化能力。调整超参数时，必须使用超参数专用的确认数据。用于调整超参数的数据，一般称为验证数据（validation data）。我们使用这个验证数据来 评估超参数的好坏。</p><p>进行超参数的最优化时，逐渐缩小超参数的“好值”的存在范围非常重要。 所谓逐渐缩小范围，是指一开始先大致设定一个范围，从这个范围中随机选 出一个超参数（采样），用这个采样到的值进行识别精度的评估；然后，多次重复该操作，观察识别精度的结果，根据这个结果缩小超参数的“好值”的范围。 通过重复这一操作，就可以逐渐确定超参数的合适范围。</p><p>超参数的范围只要“大致地指定”就可以了，也就是像0.001（$10^{-3}$）到 1000（$10^{3}$）这样，以“ 10的阶乘”的尺度指定范围。 </p><p>在超参数的最优化中，要注意的是深度学习需要很长时间（比如，几天或几周）。因此，在超参数的搜索中，需要尽早放弃那些不符合逻辑的超参数。 在最优化中，减少学习的epoch，缩短一次评估所需的时间 是一个不错的办法。 简单归纳一下，如下所示:</p><p><strong>步骤0</strong>     <strong>设定超参数的范围。</strong></p><p><strong>步骤1</strong>     <strong>从设定的超参数范围中随机采样。</strong></p><p><strong>步骤2</strong>     <strong>使用步骤1中采样到的超参数的值进行学习，通过验证数据评估识别精度（但是要将epoch设置得很小）。</strong></p><p><strong>步骤3</strong>     <strong>重复步骤1和步骤2（100次等），根据它们的识别精度的结果，缩小超参数的范围。</strong></p><p>反复进行上述操作，不断缩小超参数的范围，在缩小到一定程度时，从该范围中选出一个超参数的值。这就是进行超参数的最优化的一种方法。</p>]]></content>
    
    <summary type="html">
    
      可以帮助理解为什么会出现神经网络和其中的一些重要概念，以及他们是如何起作用的
    
    </summary>
    
      <category term="人工智能" scheme="http://yoursite.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="神经网络" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Python入门</title>
    <link href="http://yoursite.com/2019/08/30/Python%E5%85%A5%E9%97%A8/"/>
    <id>http://yoursite.com/2019/08/30/Python入门/</id>
    <published>2019-08-30T14:55:58.000Z</published>
    <updated>2020-04-10T12:33:43.821Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Python环境搭建"><a href="#1-Python环境搭建" class="headerlink" title="1.Python环境搭建"></a>1.Python环境搭建</h2><p><strong>以下为Windows系统（相信Linux大佬一定是会装的）</strong></p><ul><li>打开Web浏览器，访问Python安装包官网下载地址：<a href="https://link.jianshu.com/?t=https://www.python.org/downloads/" target="_blank" rel="noopener">https://www.python.org/downloads/</a></li><li>双击安装，一路next，在【选择路径】的步骤，把选好的路径复制黏贴下来，后面的配置要用到。</li><li>配置环境变量<br>(1) 【计算机】-【属性】-【高级系统设置】-【高级】-【环境变量】-【系统变量】-【Path】<br>(2)  编辑【Path】变量：把刚才复制的安装路径，加到它的结尾，要用英文分号和前面已有的内容隔开。<br>(3)  一路【确定】，完成。</li><li>检查是否安装成功<br>(1) 按键【Win】+【R】- 输入cmd - 打开命令行窗口<br>(2) 输入python - 【Enter】，显示Python版本信息，即安装成功。</li></ul><h2 id="2-Python中的基本数据类型"><a href="#2-Python中的基本数据类型" class="headerlink" title="2.Python中的基本数据类型"></a>2.Python中的基本数据类型</h2><h3 id="一、number类型"><a href="#一、number类型" class="headerlink" title="一、number类型"></a>一、number类型</h3><p>Python3 支持 <code>int</code>、<code>float</code>、<code>bool</code>、<code>complex</code>（复数）。</p><p>在Python 3里，只有一种整数类型 <code>int</code>，表示为长整型(-2^63-2^63)，没有 python2 中的 <code>Long</code></p><h4 id="1-int类型"><a href="#1-int类型" class="headerlink" title="1. int类型"></a>1. int类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">int</span><span class="params">(object)</span></span></span><br><span class="line"><span class="class"> |  <span class="title">int</span><span class="params">([x])</span> -&gt; integer</span></span><br><span class="line"><span class="class"> |  int(x, base=10) -&gt; integer</span></span><br><span class="line"><span class="class"> |  </span></span><br><span class="line"><span class="class"> |  Convert a number or string to an integer, or return 0 if no arguments</span></span><br><span class="line"><span class="class"> |  are given.  If x is a number, return x.__int__().  For floating point</span></span><br><span class="line"><span class="class"> |  numbers, this truncates towards zero.</span></span><br><span class="line"><span class="class"> |  </span></span><br><span class="line"><span class="class"> |  If x is not a number or if base is given, then x must be a string,</span></span><br><span class="line"><span class="class"> |  bytes, or bytearray instance representing an integer literal in the</span></span><br><span class="line"><span class="class"> |  given base.  The literal can be preceded by '+' or '-' and be surrounded</span></span><br><span class="line"><span class="class"> |  by whitespace.  The base defaults to 10.  Valid bases are 0 and 2-36.</span></span><br><span class="line"><span class="class"> |  Base 0 means to interpret the base from the string as an integer literal.</span></span><br><span class="line"><span class="class"> |  &gt;&gt;&gt; int('0b100', base=0)</span></span><br><span class="line"><span class="class"> |  4</span></span><br><span class="line"><span class="class">    .....</span></span><br></pre></td></tr></table></figure><p>可知，创建 <code>int</code> 值有两种方式：</p><ul><li>直接赋予变量整数值</li><li>使用构造器 <code>int()</code> 创建 <code>int</code> 类型实例</li></ul><p>针对第二种方式，如果没有任何输入参数，那么创建 <code>int</code> 实例值为 <code>0</code></p><p>如果仅输入单个对象，可以输入一个数字，或者一个数字字符串</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>int()</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="number">3</span>)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(‘<span class="number">122</span>’)</span><br><span class="line"><span class="number">122</span></span><br></pre></td></tr></table></figure><p>int()函数可以把实数类型转换为整数，并且是向下取整，也就是在数轴上向左取整</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="number">3.6</span>)</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="number">3.4</span>)</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure><p>可选参数 <code>base</code> 表示第一个参数值所属进制，默认为 <code>10</code>，表示输入值为十进制数，取值范围为 <code>0</code> 和 <code>[2, 36]</code></p><p>如果输入多个对象，即需要定义输入值的进制时，输入值类型应该为字符串 <code>str</code></p><p>在所有的进制中，<code>2-进制</code>，<code>8-进制</code> 和 <code>16-进制</code> 可以通过添加前缀 <code>0b/0B, 0o/0O，0x/0X</code> 的方式进行转换：</p><p>假如你想要通过调用init来进行有前缀的进制转换，则必须将<code>base</code>设置为0</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="string">'3333'</span>)</span><br><span class="line"><span class="number">3333</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="string">'3333'</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">3333</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="string">'0o333'</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">219</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="string">'0x3333'</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">13107</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#假如不将base设置为0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="string">'0x3333'</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">ValueError: invalid literal <span class="keyword">for</span> int() <span class="keyword">with</span> base <span class="number">10</span>: <span class="string">'0x3333'</span></span><br><span class="line">        </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>int(<span class="string">'0x2676'</span>,<span class="number">8</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">ValueError: invalid literal <span class="keyword">for</span> int() <span class="keyword">with</span> base <span class="number">8</span>: <span class="string">'0x2676'</span></span><br></pre></td></tr></table></figure><h4 id="2-float类型"><a href="#2-float类型" class="headerlink" title="2.float类型"></a>2.float类型</h4><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">float</span><span class="params">(object)</span></span></span><br><span class="line"><span class="class"> |  <span class="title">float</span><span class="params">(x=<span class="number">0</span>, /)</span></span></span><br><span class="line"><span class="class"> |</span></span><br><span class="line"> |  Convert a string or number to a floating point number, if possible.</span><br></pre></td></tr></table></figure><p>浮点型（<code>float</code>）等同于 C 语言中的 <code>double</code> 类型</p><p>创建 <code>float</code> 值有两种方式：</p><ul><li><p>直接赋予变量整数值</p></li><li><p>使用构造器 float() 创建 <code>float</code> 类型实例</p><p>使用第一种方式，如果该数值没有小数，需要添加后缀 .0，否则，解释器会认为这是 int 类型数值，示例如下：</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = <span class="number">33</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(a)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">int</span>'&gt;</span></span><br><span class="line">&gt;&gt;&gt; a = 33.0</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(a)</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">float</span>'&gt;</span></span><br></pre></td></tr></table></figure><p>使用第二种方式，如果没有任何输入参数，那么创建 <code>float</code> 实例值为 <code>0.0</code></p><p>也可以输入单个参数，一个数值或者一个数字字符串，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>float()</span><br><span class="line"><span class="number">0.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = float(<span class="number">33</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line"><span class="number">33.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = float(<span class="string">'222.3'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c</span><br><span class="line"><span class="number">222.3</span></span><br></pre></td></tr></table></figure><p><strong>使用 float() 构造器还可以定义无穷大（Infinity 或者 inf）和无穷小</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = float(<span class="string">"inf"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = float(<span class="string">"-inf"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">inf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">-inf</span><br></pre></td></tr></table></figure><p>为了测试这些值的存在，使用 <code>math.isinf()</code> 进行判断：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> math</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>math.isinf(a)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>math.isinf(b)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p><strong>无穷大数在执行数学计算的时候会传播</strong></p><p>这个就类似于数学中讲述的，无穷大加上一个常数还是无穷大，无穷大与无穷大相等：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = float(<span class="string">'inf'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a + <span class="number">45</span></span><br><span class="line">inf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a * <span class="number">10</span></span><br><span class="line">inf</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">10</span> / a</span><br><span class="line"><span class="number">0.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>float(<span class="string">"inf"</span>) == float(<span class="string">"inf"</span>)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p>无穷大在比较中比任何一个数都要大。</p><p><em>问题：但如果我们将无穷大与无穷小相加呢？</em></p><p>有些操作时未定义的并会返回一个 <code>NaN</code> 结果:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = float(<span class="string">'inf'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a/a</span><br><span class="line">nan</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = float(<span class="string">'-inf'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a + b</span><br><span class="line">nan</span><br></pre></td></tr></table></figure><p><code>nan</code> 值在所有操作中也会传播，并且不会产生异常：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = float(<span class="string">'nan'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c + <span class="number">23</span></span><br><span class="line">nan</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c / <span class="number">2</span></span><br><span class="line">nan</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c * <span class="number">2</span></span><br><span class="line">nan</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>math.sqrt(c)</span><br><span class="line">nan</span><br></pre></td></tr></table></figure><p>使用 <code>math.isnan()</code> 可以判断值是否是 <code>NaN</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>math.isnan(c)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><p><code>nan</code> 值的任何比较操作都是返回 <code>False</code> ：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>float(<span class="string">"nan"</span>) == float(<span class="string">"nan"</span>)</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c &gt; <span class="number">3</span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><p><strong>更安全的类型转换</strong></p><p>由于无穷的存在，因此字符串装浮点数就存在的一些例外，并且这个转换过程不会抛出异常。如果程序员们想改变 python 的默认行为，可以使用 <code>fpectl</code> 模块，但是它在标准的Python 构建中并没有被启用。还有一个比较简单的转换，就是加一个 <code>isdigit()</code> 判断（用于检测字符串是否仅有数字组成）:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">str2float</span><span class="params">(ss)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ss.isdigit():</span><br><span class="line">        <span class="keyword">raise</span> ValueError</span><br><span class="line">    <span class="keyword">return</span> float(ss)</span><br><span class="line">    </span><br><span class="line">sss = <span class="string">"inf"</span></span><br><span class="line"></span><br><span class="line">a = str2float(sss)</span><br></pre></td></tr></table></figure><h4 id="3-bool类型"><a href="#3-bool类型" class="headerlink" title="3.bool类型"></a>3.bool类型</h4><p>Python中的布尔类型有两个常量True和False表示。</p><h6 id="布尔值转化"><a href="#布尔值转化" class="headerlink" title="布尔值转化"></a>布尔值转化</h6><p>Python中的布尔值是可以转化为数值的，True表示1，而False表示0，可以对其进行数值运算，但不建议这么做，会引起代码的混乱。</p><h6 id="真值测试"><a href="#真值测试" class="headerlink" title="真值测试"></a>真值测试</h6><p>在Python中所有的对象都可以进行真值测试，下面罗列一下判断为假的情况：</p><ul><li>None</li><li>False</li><li>数值中的零，包括0，0.0，0j（虚数）</li><li>空序列，包括空字符串(”)，空元组(())，空列表([])</li><li>空的字典{}</li><li>自定义的对象的实例，该对象的<strong>bool</strong>方法返回False或者<strong>len</strong>方法返回0</li><li>除了以上的情况外，所有的对象在if或者while语句中的表现都为真。</li></ul><h6 id="布尔操作"><a href="#布尔操作" class="headerlink" title="布尔操作"></a>布尔操作</h6><p>在Python中布尔值可以进行或、且、否三种操作，与很多语言不同的是，Python中不是用符号，而是用英文单词来表示，分别是or、and和not。</p><p>需要注意的是or和and都支持短路操作，如果or的左边返回True，则右边就不会判断；同理如果and左边返回False，右边也不会进行判断。</p><p>not的优先级很低，not a == b表示的是not (a == b)，而表达式a == not b会直接报错，需要加括号a == (not b)。</p><h6 id="比较操作"><a href="#比较操作" class="headerlink" title="比较操作"></a>比较操作</h6><p>通过比较操作会返回布尔类型的值。除了普通的比较操作外，Python还支持is操作来判断两个对象是否是同一个对象，下面是Python支持的所有的比较操作：</p><div class="table-container"><table><thead><tr><th>操作符</th><th>解释</th></tr></thead><tbody><tr><td>&lt;</td><td>小于</td></tr><tr><td>&lt;=</td><td>小于等于</td></tr><tr><td>&gt;</td><td>大于</td></tr><tr><td>&gt;=</td><td>大于等于</td></tr><tr><td>==</td><td>等于</td></tr><tr><td>!=</td><td>不等于</td></tr><tr><td>is</td><td>是相同对象</td></tr><tr><td>is not</td><td>是不同对象</td></tr></tbody></table></div><p>其他操作比较常见，给出一些is的用法示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="literal">None</span></span><br><span class="line">b = <span class="literal">None</span></span><br><span class="line"><span class="comment"># True，因为None只有唯一实例</span></span><br><span class="line">r = a <span class="keyword">is</span> b</span><br><span class="line"></span><br><span class="line">a = <span class="string">"22"</span></span><br><span class="line">b = <span class="string">"22"</span></span><br><span class="line"><span class="comment"># True，直接声明的相同字符串也会指向同一个实例</span></span><br><span class="line">r = a <span class="keyword">is</span> b</span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>]</span><br><span class="line">b = [<span class="number">1</span>]</span><br><span class="line"><span class="comment"># False，相等但不是同一个实例</span></span><br><span class="line">r = a <span class="keyword">is</span> b</span><br><span class="line"></span><br><span class="line">a = [<span class="number">1</span>]</span><br><span class="line">b = a</span><br><span class="line">c = a</span><br><span class="line"><span class="comment"># True，指向同一个实例</span></span><br><span class="line">r = b <span class="keyword">is</span> c</span><br></pre></td></tr></table></figure><h4 id="4-complex类型"><a href="#4-complex类型" class="headerlink" title="4.complex类型"></a>4.complex类型</h4><p>Python还支持复数，复数由实数部分和虚数部分构成，可以用a + bj,或者complex(a,b)表示， 复数的实部a和虚部b都是浮点型</p><h4 id="5-运算符"><a href="#5-运算符" class="headerlink" title="5.运算符"></a>5.运算符</h4><div class="table-container"><table><thead><tr><th style="text-align:left">算术运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left">+</td><td style="text-align:left">加 - 两个对象相加</td><td style="text-align:left">a + b 输出结果 30</td></tr><tr><td style="text-align:left">-</td><td style="text-align:left">减 - 得到负数或是一个数减去另一个数</td><td style="text-align:left">a - b 输出结果 -10</td></tr><tr><td style="text-align:left">*</td><td style="text-align:left">乘 - 两个数相乘或是返回一个被重复若干次的字符串</td><td style="text-align:left">a * b 输出结果 200</td></tr><tr><td style="text-align:left">/</td><td style="text-align:left">除 - x除以y</td><td style="text-align:left">b / a 输出结果 2</td></tr><tr><td style="text-align:left">%</td><td style="text-align:left">取模 - 返回除法的余数</td><td style="text-align:left">b % a 输出结果 0</td></tr><tr><td style="text-align:left">**</td><td style="text-align:left">幂 - 返回x的y次幂</td><td style="text-align:left">a**b 为10的20次方， 输出结果 100000000000000000000</td></tr><tr><td style="text-align:left">//</td><td style="text-align:left">取整除 - 返回商的整数部分（<strong>向下取整</strong>）</td><td style="text-align:left">&gt;&gt;&gt; 9//2 4 &gt;&gt;&gt; -9//2 -5</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">比较运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left">==</td><td style="text-align:left">等于 - 比较对象是否相等</td><td style="text-align:left">(a == b) 返回 False。</td></tr><tr><td style="text-align:left">!=</td><td style="text-align:left">不等于 - 比较两个对象是否不相等</td><td style="text-align:left">(a != b) 返回 true.</td></tr><tr><td style="text-align:left">&lt;&gt;</td><td style="text-align:left">不等于 - 比较两个对象是否不相等</td><td style="text-align:left">(a &lt;&gt; b) 返回 true。这个运算符类似 != 。</td></tr><tr><td style="text-align:left">&gt;</td><td style="text-align:left">大于 - 返回x是否大于y</td><td style="text-align:left">(a &gt; b) 返回 False。</td></tr><tr><td style="text-align:left">&lt;</td><td style="text-align:left">小于 - 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量True和False等价。</td><td style="text-align:left">(a &lt; b) 返回 true。</td></tr><tr><td style="text-align:left">&gt;=</td><td style="text-align:left">大于等于    - 返回x是否大于等于y。</td><td style="text-align:left">(a &gt;= b) 返回 False。</td></tr><tr><td style="text-align:left">&lt;=</td><td style="text-align:left">小于等于 -    返回x是否小于等于y。</td><td style="text-align:left">(a &lt;= b) 返回 true。</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">赋值运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left">=</td><td style="text-align:left">简单的赋值运算符</td><td style="text-align:left">c = a + b 将 a + b 的运算结果赋值为 c</td></tr><tr><td style="text-align:left">+=</td><td style="text-align:left">加法赋值运算符</td><td style="text-align:left">c += a 等效于 c = c + a</td></tr><tr><td style="text-align:left">-=</td><td style="text-align:left">减法赋值运算符</td><td style="text-align:left">c -= a 等效于 c = c - a</td></tr><tr><td style="text-align:left">*=</td><td style="text-align:left">乘法赋值运算符</td><td style="text-align:left">c <em>= a 等效于 c = c </em> a</td></tr><tr><td style="text-align:left">/=</td><td style="text-align:left">除法赋值运算符</td><td style="text-align:left">c /= a 等效于 c = c / a</td></tr><tr><td style="text-align:left">%=</td><td style="text-align:left">取模赋值运算符</td><td style="text-align:left">c %= a 等效于 c = c % a</td></tr><tr><td style="text-align:left">**=</td><td style="text-align:left">幂赋值运算符</td><td style="text-align:left">c *<em>= a 等效于 c = c *</em> a</td></tr><tr><td style="text-align:left">//=</td><td style="text-align:left">取整除赋值运算符</td><td style="text-align:left">c //= a 等效于 c = c // a</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">位运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left">&amp;</td><td style="text-align:left">按位与运算符：参与运算的两个值,如果两个相应位都为1,则该位的结果为1,否则为0</td><td style="text-align:left">(a &amp; b) 输出结果 12 ，二进制解释： 0000 1100</td></tr><tr><td style="text-align:left">\</td><td style="text-align:left"></td><td style="text-align:left">按位或运算符：只要对应的二个二进位有一个为1时，结果位就为1。</td><td>(a \</td><td>b) 输出结果 61 ，二进制解释： 0011 1101</td></tr><tr><td style="text-align:left">^</td><td style="text-align:left">按位异或运算符：当两对应的二进位相异时，结果为1</td><td style="text-align:left">(a ^ b) 输出结果 49 ，二进制解释： 0011 0001</td></tr><tr><td style="text-align:left">~</td><td style="text-align:left">按位取反运算符：对数据的每个二进制位取反,即把1变为0,把0变为1 。<strong>~x</strong> 类似于 <strong>-x-1</strong></td><td style="text-align:left">(~a ) 输出结果 -61 ，二进制解释： 1100 0011，在一个有符号二进制数的补码形式。</td></tr><tr><td style="text-align:left">&lt;&lt;</td><td style="text-align:left">左移动运算符：运算数的各二进位全部左移若干位，由 <strong>&lt;&lt;</strong> 右边的数字指定了移动的位数，高位丢弃，低位补0。</td><td style="text-align:left">a &lt;&lt; 2 输出结果 240 ，二进制解释： 1111 0000</td></tr><tr><td style="text-align:left">&gt;&gt;</td><td style="text-align:left">右移动运算符：把”&gt;&gt;”左边的运算数的各二进位全部右移若干位，<strong>&gt;&gt;</strong> 右边的数字指定了移动的位数</td><td style="text-align:left">a &gt;&gt; 2 输出结果 15 ，二进制解释： 0000 1111</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th style="text-align:left">赋值运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left">=</td><td style="text-align:left">简单的赋值运算符</td><td style="text-align:left">c = a + b 将 a + b 的运算结果赋值为 c</td></tr><tr><td style="text-align:left">+=</td><td style="text-align:left">加法赋值运算符</td><td style="text-align:left">c += a 等效于 c = c + a</td></tr><tr><td style="text-align:left">-=</td><td style="text-align:left">减法赋值运算符</td><td style="text-align:left">c -= a 等效于 c = c - a</td></tr><tr><td style="text-align:left">*=</td><td style="text-align:left">乘法赋值运算符</td><td style="text-align:left">c <em>= a 等效于 c = c </em> a</td></tr><tr><td style="text-align:left">/=</td><td style="text-align:left">除法赋值运算符</td><td style="text-align:left">c /= a 等效于 c = c / a</td></tr><tr><td style="text-align:left">%=</td><td style="text-align:left">取模赋值运算符</td><td style="text-align:left">c %= a 等效于 c = c % a</td></tr><tr><td style="text-align:left">**=</td><td style="text-align:left">幂赋值运算符</td><td style="text-align:left">c <strong>= a 等效于 c = c </strong> a</td></tr><tr><td style="text-align:left">//=</td><td style="text-align:left">取整除赋值运算符</td><td style="text-align:left">c //= a 等效于 c = c // a</td></tr></tbody></table></div><h3 id="二、字符串类型"><a href="#二、字符串类型" class="headerlink" title="二、字符串类型"></a>二、字符串类型</h3><h4 id="1-字符串拼接"><a href="#1-字符串拼接" class="headerlink" title="1.字符串拼接"></a>1.字符串拼接</h4><h6 id="1、来自C语言的-方式"><a href="#1、来自C语言的-方式" class="headerlink" title="1、来自C语言的%方式"></a>1、来自C语言的%方式</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'%s %s'</span> % (<span class="string">'Hello'</span>, <span class="string">'world'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Hello world</span><br></pre></td></tr></table></figure><p>%号格式化字符串的方式继承自古老的C语言，这在很多编程语言都有类似的实现。上例的%s是一个占位符，它仅代表一段字符串，并不是拼接的实际内容。实际的拼接内容在一个单独的%号后面，放在一个元组里。</p><p>类似的占位符还有：%d（代表一个整数）、%f（代表一个浮点数）、%x（代表一个16进制数），等等。%占位符既是这种拼接方式的特点，同时也是其限制，因为每种占位符都有特定意义，实际使用起来太麻烦了。</p><h6 id="2、format-拼接方式"><a href="#2、format-拼接方式" class="headerlink" title="2、format()拼接方式"></a>2、format()拼接方式</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简洁版</span></span><br><span class="line">s1 = <span class="string">'Hello &#123;&#125;! My name is &#123;&#125;.'</span>.format(<span class="string">'World'</span>, <span class="string">'Python猫'</span>)</span><br><span class="line">print(s1)</span><br><span class="line">&gt;&gt;&gt;Hello World! My name <span class="keyword">is</span> Python猫.</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对号入座版</span></span><br><span class="line">s2 = <span class="string">'Hello &#123;0&#125;! My name is &#123;1&#125;.'</span>.format(<span class="string">'World'</span>, <span class="string">'Python猫'</span>)</span><br><span class="line">s3 = <span class="string">'Hello &#123;name1&#125;! My name is &#123;name2&#125;.'</span>.format(name1=<span class="string">'World'</span>, name2=<span class="string">'Python猫'</span>)</span><br><span class="line">print(s2)</span><br><span class="line">&gt;&gt;&gt;Hello World! My name <span class="keyword">is</span> Python猫.</span><br><span class="line">print(s3)</span><br><span class="line">&gt;&gt;&gt;Hello World! My name <span class="keyword">is</span> Python猫.</span><br></pre></td></tr></table></figure><p>这种方式使用花括号{}做占位符，在format方法中再转入实际的拼接值。容易看出，它实际上是对%号拼接方式的改进。这种方式在Python2.6中开始引入。</p><p>上例中，简洁版的花括号中无内容，缺点是容易弄错次序。对号入座版主要有两种，一种传入序列号，一种则使用key-value的方式，更加直观。</p><h6 id="3、直接拼接"><a href="#3、直接拼接" class="headerlink" title="3、直接拼接"></a>3、直接拼接</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">s_tuple = (<span class="string">'Hello'</span>, <span class="string">' '</span>, <span class="string">'world'</span>)</span><br><span class="line">s_like_tuple = (<span class="string">'Hello'</span> <span class="string">' '</span> <span class="string">'world'</span>)</span><br><span class="line"></span><br><span class="line">print(s_tuple) </span><br><span class="line">&gt;&gt;&gt;(<span class="string">'Hello'</span>, <span class="string">' '</span>, <span class="string">'world'</span>)</span><br><span class="line">print(s_like_tuple) </span><br><span class="line">&gt;&gt;&gt;Hello world</span><br><span class="line"></span><br><span class="line">type(s_like_tuple) &gt;&gt;&gt;str</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多元素时，不支持有变量</span></span><br><span class="line">str_1 = <span class="string">'Hello'</span></span><br><span class="line">str_2 = (str_1 <span class="string">'world'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>SyntaxError: invalid syntax</span><br><span class="line">str_3 = (str_1 str_1)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>SyntaxError: invalid syntax</span><br><span class="line"><span class="comment"># 但是下面写法不会报错</span></span><br><span class="line">str_4 = (str_1)</span><br></pre></td></tr></table></figure><h6 id="4、面向对象模板拼接"><a href="#4、面向对象模板拼接" class="headerlink" title="4、面向对象模板拼接"></a>4、面向对象模板拼接</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> string <span class="keyword">import</span> Template</span><br><span class="line">s = Template(<span class="string">'$&#123;s1&#125; $&#123;s2&#125;!'</span>) </span><br><span class="line">print(s.safe_substitute(s1=<span class="string">'Hello'</span>,s2=<span class="string">'world'</span>)) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Hello world!</span><br></pre></td></tr></table></figure><p>这种方法就十分麻烦且不优雅了</p><h6 id="5、常用的-号方式"><a href="#5、常用的-号方式" class="headerlink" title="5、常用的+号方式"></a>5、常用的+号方式</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">str_1 = <span class="string">'Hello world！ '</span> </span><br><span class="line">str_2 = <span class="string">'My name is Python猫.'</span></span><br><span class="line">print(str_1 + str_2)</span><br><span class="line">&gt;&gt;&gt;Hello world！ My name <span class="keyword">is</span> Python猫.</span><br><span class="line">print(str_1)</span><br><span class="line">&gt;&gt;&gt;Hello world！</span><br></pre></td></tr></table></figure><p>这种方式最常用、直观、易懂，是入门级的实现方式。但是，它也存在两处让人容易犯错的地方。</p><p>字符串是不可变类型，新的字符串会独占一块新的内存，而原来的字符串保持不变。上例中，拼接前有两段字符串，拼接后实际有三段字符串。</p><p>有种说法是当拼接次数不超过3时，使用+号连接符就会比其它方式快（ps：不少Python教程都是如此建议），但这没有任何合理根据。</p><p>事实上，在拼接短的字面值时，由于CPython中的 <code>常数折叠</code> （constant folding）功能，这些字面值会被转换成更短的形式，例如’a’+’b’+’c’ 被转换成’abc’，’hello’+’world’也会被转换成’hello world’。这种转换是在编译期完成的，而到了运行期时就不会再发生任何拼接操作，因此会加快整体计算的速度。</p><p>常数折叠优化有一个限度，它要求拼接结果的长度不超过20。所以，<strong>当拼接的最终字符串长度不超过20时，+号操作符的方式，会比后面提到的join等方式快得多，这与+号的使用次数无关。</strong></p><h6 id="6、join-拼接方式"><a href="#6、join-拼接方式" class="headerlink" title="6、join()拼接方式"></a>6、join()拼接方式</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">str_list = [<span class="string">'Hello'</span>, <span class="string">'world'</span>]</span><br><span class="line">str_join1 = <span class="string">' '</span>.join(str_list)</span><br><span class="line">str_join2 = <span class="string">'-'</span>.join(str_list)</span><br><span class="line">print(str_join1) &gt;&gt;&gt;Hello world</span><br><span class="line">print(str_join2) &gt;&gt;&gt;Hello-world</span><br></pre></td></tr></table></figure><p>str对象自带的join()方法，接受一个序列参数，可以实现拼接。拼接时，元素若不是字符串，需要先转换一下。可以看出，这种方法比较适用于连接序列对象中（例如列表）的元素，并设置统一的间隔符。</p><p>当拼接长度超过20时，这种方式基本上是首选。不过，它的缺点就是，不适合进行零散片段的、不处于序列集合的元素拼接。</p><h6 id="7、f-string方式"><a href="#7、f-string方式" class="headerlink" title="7、f-string方式"></a>7、f-string方式</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'world'</span></span><br><span class="line">myname = <span class="string">'python_cat'</span></span><br><span class="line">words = <span class="string">f'Hello <span class="subst">&#123;name&#125;</span>. My name is <span class="subst">&#123;myname&#125;</span>.'</span></span><br><span class="line">print(words)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Hello world. My name <span class="keyword">is</span> python_cat.</span><br></pre></td></tr></table></figure><p>f-string方式出自PEP 498<code>Literal String Interpolation</code>，从Python3.6版本引入。其特点是在字符串前加 f 标识，字符串中间则用花括号{}包裹其它字符串变量。</p><p>这种方式在可读性上秒杀format()方式，处理长字符串的拼接时，速度与join()方法相当。</p><p>总结一下，我们前面说的“字符串拼接”，其实是从结果上理解。若从实现原理上划分的话，我们可以将这些方法划分出三种类型：</p><ul><li>格式化类：%、format()、template</li><li>拼接类：+、()、join()</li><li>插值类：f-string</li></ul><h4 id="2-切片"><a href="#2-切片" class="headerlink" title="2.切片"></a>2.切片</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str[beg:end]</span></span><br><span class="line"><span class="comment"># （下标从 0 开始）从下标为beg开始算起，切取到下标为 end-1 的元素，切取的区间为 [beg, end)</span></span><br><span class="line">str = <span class="string">' python str '</span></span><br><span class="line"><span class="keyword">print</span> str[<span class="number">3</span>:<span class="number">6</span>]    <span class="comment"># tho</span></span><br><span class="line"><span class="comment"># str[beg:end:step]</span></span><br><span class="line"><span class="comment"># 取 [beg, end) 之间的元素，每隔 step 个取一个</span></span><br><span class="line"><span class="keyword">print</span> str[<span class="number">2</span>:<span class="number">7</span>:<span class="number">2</span>]  <span class="comment"># yhn</span></span><br></pre></td></tr></table></figure><h4 id="3-原始字符串"><a href="#3-原始字符串" class="headerlink" title="3.原始字符串"></a>3.原始字符串</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在字符串前加 r/R</span></span><br><span class="line"><span class="comment"># 所有的字符串都是直接按照字面的意思来使用，没有转义特殊或不能打印的字符</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">r'\n'</span>   <span class="comment"># \n</span></span><br></pre></td></tr></table></figure><h4 id="4-字符串重复"><a href="#4-字符串重复" class="headerlink" title="4.字符串重复"></a>4.字符串重复</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str * n, n * str</span></span><br><span class="line"><span class="comment"># n 为一个 int 数字</span></span><br><span class="line">str = <span class="string">"hi"</span></span><br><span class="line"><span class="keyword">print</span> str*<span class="number">2</span>   <span class="comment"># hihi</span></span><br><span class="line"><span class="keyword">print</span> <span class="number">2</span>*str   <span class="comment"># hihi</span></span><br></pre></td></tr></table></figure><h4 id="5-in"><a href="#5-in" class="headerlink" title="5.in"></a>5.in</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">str = <span class="string">' python'</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'p'</span> <span class="keyword">in</span> str    <span class="comment"># True</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'py'</span> <span class="keyword">in</span> str   <span class="comment"># True</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'py'</span> <span class="keyword">not</span> <span class="keyword">in</span> str <span class="comment"># False</span></span><br></pre></td></tr></table></figure><h4 id="6-字符串常用函数"><a href="#6-字符串常用函数" class="headerlink" title="6.字符串常用函数"></a>6.字符串常用函数</h4><h5 id="去空格"><a href="#去空格" class="headerlink" title="去空格"></a>去空格</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">str = <span class="string">' python str '</span></span><br><span class="line"><span class="keyword">print</span> str</span><br><span class="line"><span class="comment"># 去首尾空格</span></span><br><span class="line"><span class="keyword">print</span> str.strip()</span><br><span class="line"><span class="comment"># 去左侧空格</span></span><br><span class="line"><span class="keyword">print</span> str.lstrip()</span><br><span class="line"><span class="comment"># 去右侧空格</span></span><br><span class="line"><span class="keyword">print</span> str.rstrip()</span><br></pre></td></tr></table></figure><h5 id="分隔字符串"><a href="#分隔字符串" class="headerlink" title="分隔字符串"></a>分隔字符串</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">str = <span class="string">' 1 , 2 , 3 , 4 , 5 , '</span></span><br><span class="line"><span class="comment"># 默认使用空格分隔</span></span><br><span class="line"><span class="keyword">print</span> str.split()   <span class="comment"># ['1', ',', '2', ',', '3', ',', '4', ',', '5', ',']</span></span><br><span class="line"><span class="comment"># 指定使用空格进行分隔，首尾如果有空格，则会出现在结果中</span></span><br><span class="line"><span class="keyword">print</span> str.split(<span class="string">' '</span>) <span class="comment"># ['', '1', ',', '2', ',', '3', ',', '4', ',', '5', ',', '']</span></span><br><span class="line"><span class="comment"># 指定其他字符串进行分隔</span></span><br><span class="line"><span class="keyword">print</span> str.split(<span class="string">','</span>) <span class="comment"># [' 1 ', ' 2 ', ' 3 ', ' 4 ', ' 5 ', ' ']</span></span><br><span class="line"><span class="keyword">print</span> str.split(<span class="string">'3 ,'</span>) <span class="comment"># [' 1 , 2 , ', ' 4 , 5 , ']</span></span><br><span class="line">str = <span class="string">'mississippi'</span></span><br><span class="line"><span class="keyword">print</span> str.rstrip(<span class="string">'ip'</span>)</span><br><span class="line"><span class="comment"># 取行, python 中把 "\r"，"\n"，"\r\n"，作为行分隔符</span></span><br><span class="line">str = <span class="string">'ab c\n\nde fg\rkl\r\n'</span></span><br><span class="line"><span class="keyword">print</span> str.splitlines()      <span class="comment"># ['ab c', '', 'de fg', 'kl']</span></span><br><span class="line"><span class="keyword">print</span> str.splitlines(<span class="literal">True</span>)  <span class="comment"># ['ab c\n', '\n', 'de fg\r', 'kl\r\n']</span></span><br></pre></td></tr></table></figure><h5 id="拼接字符串"><a href="#拼接字符串" class="headerlink" title="拼接字符串"></a>拼接字符串</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str.join()方法用于将序列中的元素以指定的字符连接生成一个新的字符串。</span></span><br><span class="line">str = <span class="string">'-'</span></span><br><span class="line">seq = (<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>); <span class="comment"># 字符串序列</span></span><br><span class="line"><span class="keyword">print</span> str.join(seq)  <span class="comment"># 'a-b-c'</span></span><br></pre></td></tr></table></figure><h5 id="统计字符串里某个字符出现的次数"><a href="#统计字符串里某个字符出现的次数" class="headerlink" title="统计字符串里某个字符出现的次数"></a>统计字符串里某个字符出现的次数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str.count(sub, start= 0,end=len(string))</span></span><br><span class="line">str = <span class="string">"thing example....wow!!!"</span></span><br><span class="line"><span class="keyword">print</span> str.count(<span class="string">'i'</span>, <span class="number">0</span>, <span class="number">5</span>)  <span class="comment"># 1</span></span><br><span class="line"><span class="keyword">print</span> str.count(<span class="string">'e'</span>)  <span class="comment"># 2</span></span><br></pre></td></tr></table></figure><h5 id="检测字符串中是否包含子字符串"><a href="#检测字符串中是否包含子字符串" class="headerlink" title="检测字符串中是否包含子字符串"></a>检测字符串中是否包含子字符串</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str.find(str, beg=0, end=len(string))</span></span><br><span class="line"><span class="comment"># 如果包含子字符串返回开始的索引值，否则返回-1。</span></span><br><span class="line">str1 = <span class="string">"this is string example....wow!!!"</span></span><br><span class="line">str2 = <span class="string">"exam"</span></span><br><span class="line"><span class="keyword">print</span> str1.find(str2)      <span class="comment"># 15</span></span><br><span class="line"><span class="keyword">print</span> str1.find(str2, <span class="number">10</span>)  <span class="comment"># 15</span></span><br><span class="line"><span class="keyword">print</span> str1.find(str2, <span class="number">40</span>)  <span class="comment"># -1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># str.index(str, beg=0, end=len(string))</span></span><br><span class="line"><span class="comment"># 如果包含子字符串返回开始的索引值，否则抛出异常。</span></span><br><span class="line"><span class="keyword">print</span> str1.index(str2)     <span class="comment"># 15</span></span><br><span class="line"><span class="keyword">print</span> str1.index(str2, <span class="number">10</span>) <span class="comment"># 15</span></span><br><span class="line"><span class="keyword">print</span> str1.index(str2, <span class="number">40</span>)</span><br><span class="line"><span class="comment"># Traceback (most recent call last):</span></span><br><span class="line"><span class="comment">#   File "test.py", line 8, in</span></span><br><span class="line"><span class="comment">#   print str1.index(str2, 40);</span></span><br><span class="line"><span class="comment">#   ValueError: substring not found</span></span><br><span class="line"><span class="comment"># shell returned 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># str.rfind(str, beg=0, end=len(string))</span></span><br><span class="line"><span class="comment"># str.rindex(str, beg=0, end=len(string))</span></span><br></pre></td></tr></table></figure><h5 id="判断字符串是否以指定前缀、后缀结尾"><a href="#判断字符串是否以指定前缀、后缀结尾" class="headerlink" title="判断字符串是否以指定前缀、后缀结尾"></a>判断字符串是否以指定前缀、后缀结尾</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str.startswith(str, beg=0,end=len(string))</span></span><br><span class="line"><span class="comment"># 检查字符串以指定子字符串开头，如果是则返回 True，否则返回 False</span></span><br><span class="line">str = <span class="string">"this is string example....wow!!!"</span></span><br><span class="line"><span class="keyword">print</span> str.startswith( <span class="string">'this'</span> );       <span class="comment"># True</span></span><br><span class="line"><span class="keyword">print</span> str.startswith( <span class="string">'is'</span>, <span class="number">2</span>, <span class="number">4</span> )    <span class="comment"># True</span></span><br><span class="line"><span class="keyword">print</span> str.startswith( <span class="string">'this'</span>, <span class="number">2</span>, <span class="number">4</span> )  <span class="comment"># False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># str.endswith(suffix[, start[, end]])</span></span><br><span class="line"><span class="comment"># 以指定后缀结尾返回True，否则返回False</span></span><br><span class="line">suffix = <span class="string">"wow!!!"</span></span><br><span class="line"><span class="keyword">print</span> str.endswith(suffix);         <span class="comment"># True</span></span><br><span class="line"><span class="keyword">print</span> str.endswith(suffix,<span class="number">20</span>);      <span class="comment"># True</span></span><br><span class="line">suffix = <span class="string">"is"</span>;</span><br><span class="line"><span class="keyword">print</span> str.endswith(suffix, <span class="number">2</span>, <span class="number">4</span>);   <span class="comment"># True</span></span><br><span class="line"><span class="keyword">print</span> str.endswith(suffix, <span class="number">2</span>, <span class="number">6</span>);   <span class="comment"># False</span></span><br></pre></td></tr></table></figure><h5 id="根据指定的分隔符将字符串进行分割"><a href="#根据指定的分隔符将字符串进行分割" class="headerlink" title="根据指定的分隔符将字符串进行分割"></a>根据指定的分隔符将字符串进行分割</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str.partition(del)</span></span><br><span class="line"><span class="comment"># 返回一个3元的元组，第一个为分隔符左边的子串，第二个为分隔符本身，第三个为分隔符右边的子串。</span></span><br><span class="line">str = <span class="string">"http://www.baidu.com/"</span></span><br><span class="line"><span class="keyword">print</span> str.partition(<span class="string">"://"</span>)   <span class="comment"># ('http', '://', 'www.baidu.com/')</span></span><br><span class="line"><span class="comment"># string.rpartition(str)   从右边开始</span></span><br></pre></td></tr></table></figure><h5 id="替换字符串"><a href="#替换字符串" class="headerlink" title="替换字符串"></a>替换字符串</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str.replace(old, new[, max])</span></span><br><span class="line"><span class="comment"># 字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。</span></span><br><span class="line">str = <span class="string">"thing example....wow!!! thisslly string"</span>;</span><br><span class="line"><span class="keyword">print</span> str.replace(<span class="string">"is"</span>, <span class="string">"was"</span>);     <span class="comment"># thwas was string example....wow!!! thwas was really string</span></span><br><span class="line"><span class="keyword">print</span> str.replace(<span class="string">"is"</span>, <span class="string">"was"</span>, <span class="number">3</span>);  <span class="comment"># thwas was string example....wow!!! thwas is really string</span></span><br><span class="line"><span class="comment"># str.expandtabs(tabsize=8)</span></span><br><span class="line"><span class="comment"># 把字符串中的 tab 符号('\t')转为空格，tab 符号('\t')默认的空格数是 8</span></span><br></pre></td></tr></table></figure><h5 id="检测字符串组成"><a href="#检测字符串组成" class="headerlink" title="检测字符串组成"></a>检测字符串组成</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检测数字</span></span><br><span class="line">str.isdigit()    <span class="comment"># 检测字符串是否只由数字组成</span></span><br><span class="line">str.isnumeric()  <span class="comment"># 检测字符串是否只由数字组成,这种方法是只针对unicode对象</span></span><br><span class="line">str.isdecimal()  <span class="comment"># 检查字符串是否只包含十进制字符。这种方法只存在于unicode对象</span></span><br><span class="line"><span class="comment"># 检测字母</span></span><br><span class="line">str.isalpha()   <span class="comment"># 检测字符串是否只由字母组成</span></span><br><span class="line"><span class="comment"># 检测字母和数字</span></span><br><span class="line">str.isalnum()   <span class="comment"># 检测字符串是否由字母和数字组成</span></span><br><span class="line"><span class="comment"># 检测其他</span></span><br><span class="line">str.isspace()   <span class="comment"># 检测字符串是否只由空格组成</span></span><br><span class="line">str.islower()   <span class="comment"># 检测字符串是否由小写字母组成</span></span><br><span class="line">str.isupper()   <span class="comment"># 检测字符串中所有的字母是否都为大写</span></span><br><span class="line">str.istitle()   <span class="comment"># 检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写</span></span><br></pre></td></tr></table></figure><h5 id="字符串处理"><a href="#字符串处理" class="headerlink" title="字符串处理"></a>字符串处理</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">str.capitalize()   <span class="comment"># 将字符串的第一个字母变成大写,其他字母变小写</span></span><br><span class="line">str.lower()        <span class="comment"># 转换字符串中所有大写字符为小写</span></span><br><span class="line">str.upper()        <span class="comment"># 将字符串中的小写字母转为大写字母</span></span><br><span class="line">str.swapcase()     <span class="comment"># 对字符串的大小写字母进行转换</span></span><br><span class="line">max(str)    <span class="comment"># 返回字符串 str 中最大的字母</span></span><br><span class="line">min(str)    <span class="comment"># 返回字符串 str 中最小的字母</span></span><br><span class="line">len(str)    <span class="comment"># 返回字符串的长度</span></span><br><span class="line">str(arg) <span class="comment"># 将 arg 转换为 string</span></span><br></pre></td></tr></table></figure><h4 id="7-格式化输出"><a href="#7-格式化输出" class="headerlink" title="7.格式化输出"></a>7.格式化输出</h4><h5 id="居中填充"><a href="#居中填充" class="headerlink" title="居中填充"></a>居中填充</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str.center(width[, fillchar])</span></span><br><span class="line"><span class="comment"># 返回一个原字符串居中,并使用空格填充至长度 width 的新字符串。默认填充字符为空格</span></span><br><span class="line">str = <span class="string">"this is string example....wow!!!"</span></span><br><span class="line"><span class="keyword">print</span> str.center(<span class="number">40</span>, <span class="string">'a'</span>)   <span class="comment"># aaaathis is string  example....wow!!!aaaa</span></span><br></pre></td></tr></table></figure><h5 id="靠右填充"><a href="#靠右填充" class="headerlink" title="靠右填充"></a>靠右填充</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str.zfill(width)</span></span><br><span class="line"><span class="comment"># 返回指定长度的字符串，原字符串右对齐，前面填充0</span></span><br><span class="line">str = <span class="string">"this is string example....wow!!!"</span></span><br><span class="line"><span class="keyword">print</span> str.zfill(<span class="number">40</span>)   <span class="comment"># 00000000this is string example....wow!!!</span></span><br></pre></td></tr></table></figure><h5 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> <span class="string">"My name is %s and weight is %d kg!"</span> % (<span class="string">'Zara'</span>, <span class="number">21</span>)</span><br><span class="line"><span class="comment"># My name is Zara and weight is 21 kg!</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'%(language)s has %(number)03d quote types.'</span> % &#123;<span class="string">"language"</span>: <span class="string">"Python"</span>, <span class="string">"number"</span>: <span class="number">2</span>&#125;</span><br><span class="line"><span class="comment"># Python has 002 quote types.</span></span><br><span class="line"><span class="comment"># str.format(*args, **kwargs)</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'&#123;0&#125;, &#123;1&#125;, &#123;2&#125;'</span>.format(<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>)  <span class="comment"># a, b, c</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'&#123;1&#125;, &#123;0&#125;, &#123;2&#125;'</span>.format(<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>)  <span class="comment"># b, a, c</span></span><br></pre></td></tr></table></figure><h2 id="3-一些小Tips"><a href="#3-一些小Tips" class="headerlink" title="3.一些小Tips"></a>3.一些小Tips</h2><h4 id="1-共用内存的对象"><a href="#1-共用内存的对象" class="headerlink" title="1.共用内存的对象"></a>1.共用内存的对象</h4><p>每个对象被创建出来的时候，就会确定其Id标识，也就是给它分配内存地址。通常来说，新对象的内存地址也是新的，会从未分配的可用地址中取。</p><p>但是，为了提高内存利用效率，对于一些常用的对象，如一些数值较小的数字对象、布尔值对象、None对象、较短的字符串对象等等，python采取共用对象内存的分配策略。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新分配内存地址的例子</span></span><br><span class="line">ww=[<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">ee=[<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line">id(ww)==id(ee) &gt;&gt;&gt;<span class="literal">False</span></span><br><span class="line">a=<span class="number">2018</span></span><br><span class="line">b=<span class="number">2018</span></span><br><span class="line">id(a)==id(b) &gt;&gt;&gt;<span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 共用内存地址的例子</span></span><br><span class="line">a=<span class="number">100</span></span><br><span class="line">b=<span class="number">100</span></span><br><span class="line">id(a)==id(b) &gt;&gt;&gt;<span class="literal">True</span></span><br><span class="line">f1=<span class="literal">True</span></span><br><span class="line">f2=<span class="literal">True</span></span><br><span class="line">id(f1)==id(f2) &gt;&gt;&gt;<span class="literal">True</span></span><br><span class="line">n1=<span class="literal">None</span></span><br><span class="line">n2=<span class="literal">None</span></span><br><span class="line">id(n1)==id(n2) &gt;&gt;&gt;<span class="literal">True</span></span><br><span class="line">s=<span class="string">"python_cat"</span></span><br><span class="line">t=<span class="string">"python_cat"</span></span><br><span class="line">id(s)==id(t) &gt;&gt;&gt;<span class="literal">True</span></span><br></pre></td></tr></table></figure><p>这就意味着，有一些变量，运行环境早早就为它们分配好了内存地址，一旦要创建新的对象时，先去已有的查找，有Type和Value相等的对象，则新对象不分配新的内存空间，而是指向已有对象。使得我们不需要频繁创建这些对象，既能提高已分配内存的使用率，又减少了创建对象、分配新内存的损耗。</p><blockquote><p>Python中，对于整数对象，如果其值处于[-5,256]的闭区间内（小整数池），则值相同的对象是同一个对象。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译对字符串拼接的影响</span></span><br><span class="line">s1 = <span class="string">"hell"</span></span><br><span class="line">s2 = <span class="string">"hello"</span></span><br><span class="line"><span class="string">"hell"</span> + <span class="string">"o"</span> <span class="keyword">is</span> s2 &gt;&gt;&gt;<span class="literal">True</span></span><br><span class="line">s1 + <span class="string">"o"</span> <span class="keyword">is</span> s2 &gt;&gt;&gt;<span class="literal">False</span></span><br><span class="line"><span class="comment"># "hell" + "o"在编译时变成了"hello"，</span></span><br><span class="line"><span class="comment"># 而s1+"o"因为s1是一个变量，在运行时才拼接，所以没有被intern</span></span><br></pre></td></tr></table></figure><blockquote><p>Python中，字符串使用Intern机制实现内存地址共用，长度不超过20，且仅包括下划线、数字、字母的字符串才会被intern；涉及字符串拼接时，编译期优化结果会与运行期计算结果不同。</p></blockquote><h4 id="2-isinstance-和-type-的区别："><a href="#2-isinstance-和-type-的区别：" class="headerlink" title="2.isinstance 和 type 的区别："></a>2.isinstance 和 type 的区别：</h4><ul><li>type()不会认为子类是一种父类类型。</li><li>isinstance()会认为子类是一种父类类型。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span></span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(A)</span>:</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span></span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(A(), A)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(A()) == A </span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>isinstance(B(), A)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(B()) == A</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><h4 id="3-大整数对象池"><a href="#3-大整数对象池" class="headerlink" title="3.大整数对象池"></a>3.大整数对象池</h4><p>在交互式终端环境中，每次创建大型数时都是去申请新的内存空间。但是在编写Python文件时每次运行都把代码加载到内存中，整个项目代码都属于一个整体。这时就是大型整数对象池发挥作用的时候了，它把处于相同代码块的所有等值的大型整数变量都处理为一个对象。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span><span class="params">(object)</span>:</span></span><br><span class="line">    a = <span class="number">100</span></span><br><span class="line">    b = <span class="number">100</span></span><br><span class="line">    c = <span class="number">1000</span></span><br><span class="line">    d = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(object)</span>:</span></span><br><span class="line">    a = <span class="number">100</span></span><br><span class="line">    b = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(A.a <span class="keyword">is</span> A.b)  <span class="comment"># True</span></span><br><span class="line">print(A.a <span class="keyword">is</span> B.a)  <span class="comment"># True</span></span><br><span class="line">print(A.c <span class="keyword">is</span> A.d)  <span class="comment"># True</span></span><br><span class="line">print(A.b <span class="keyword">is</span> B.b)  <span class="comment"># False</span></span><br></pre></td></tr></table></figure><h4 id="4-内存管理"><a href="#4-内存管理" class="headerlink" title="4.内存管理"></a>4.内存管理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>id([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]) == id([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(id(a), id(b))</span><br><span class="line"><span class="number">2037326252488</span> <span class="number">2037326229256</span></span><br></pre></td></tr></table></figure><p>Python会实时销毁没有引用计数的对象。一旦在内存中创建了一个对象但是没有为其添加引用计数，该段代码执行完后就会回收地址，在这个例子中计算完[1,2,3]的id后list被销毁，计算右边的id时list实时创建，复用了左边list用过的内存。</p>]]></content>
    
    <summary type="html">
    
      关于Python基本数据类型的入门级介绍
    
    </summary>
    
      <category term="人工智能" scheme="http://yoursite.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
</feed>
